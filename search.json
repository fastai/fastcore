[
  {
    "objectID": "style.html",
    "href": "style.html",
    "title": "Style",
    "section": "",
    "text": "Note\n\n\n\nStyled outputs don’t show in Quarto documentation. Please use a notebook editor to correctly view this page.\n\n\n\nsource\n\nStyleCode\n\n StyleCode (name, code, typ)\n\nAn escape sequence for styling terminal text.\nThe primary building block of the S API.\n\nprint(str(StyleCode('blue', 34, 'fg')) + 'hello' + str(StyleCode('default', 39, 'fg')) + ' world')\n\nhello world\n\n\n\nsource\n\n\nStyle\n\n Style (codes=None)\n\nA minimal terminal text styler.\nThe main way to use it is via the exported S object.\n\n\nExported source\nS = Style()\n\n\nWe start with an empty style:\n\nS\n\n&lt;Style: none&gt;\n\n\nDefine a new style by chaining attributes:\n\ns = S.blue.bold.underline\ns\n\n&lt;Style: blue bold underline&gt;\n\n\nYou can see a full list of available styles with auto-complete by typing S . Tab.\nApply a style by calling it with a string:\n\ns('hello world')\n\n'\\x1b[34m\\x1b[1m\\x1b[4mhello world\\x1b[22m\\x1b[24m\\x1b[39m'\n\n\nThat’s a raw string with the underlying escape sequences that tell the terminal how to format text. To see the styled version we have to print it:\n\nprint(s('hello world'))\n\nhello world\n\n\nYou can also nest styles:\n\nprint(S.bold(S.blue('key') + ' = value ') + S.light_gray(' ' + S.underline('# With a comment')) + ' and unstyled text')\n\nkey = value  # With a comment and unstyled text\n\n\n\nprint(S.blue('this '+S.bold('is')+' a test'))\n\nthis is a test\n\n\n\nsource\n\n\ndemo\n\n demo ()\n\nDemonstrate all available styles and their codes.\n\ndemo()\n\n 30    black           \n 31    red             \n 32    green           \n 33    yellow          \n 34    blue            \n 35    magenta         \n 36    cyan            \n 37    light_gray      \n 39    default         \n 90    dark_gray       \n 91    light_red       \n 92    light_green     \n 93    light_yellow    \n 94    light_blue      \n 95    light_magenta   \n 96    light_cyan      \n 97    white           \n 40    black_bg        \n 41    red_bg          \n 42    green_bg        \n 43    yellow_bg       \n 44    blue_bg         \n 45    magenta_bg      \n 46    cyan_bg         \n 47    light_gray_bg   \n 49    default_bg      \n100    dark_gray_bg    \n101    light_red_bg    \n102    light_green_bg  \n103    light_yellow_bg \n104    light_blue_bg   \n105    light_magenta_bg\n106    light_cyan_bg   \n107    white_bg        \n  1    bold            \n  2    dim             \n  3    italic          \n  4    underline       \n  5    blink           \n  7    invert          \n  8    hidden          \n  9    strikethrough   \n 22    reset_bold      \n 22    reset_dim       \n 23    reset_italic    \n 24    reset_underline \n 25    reset_blink     \n 27    reset_invert    \n 28    reset_hidden    \n 29    reset_strikethrough\n  0    reset",
    "crumbs": [
      "Style"
    ]
  },
  {
    "objectID": "xtras.html",
    "href": "xtras.html",
    "title": "Utility functions",
    "section": "",
    "text": "Utilities (other than extensions to Pathlib.Path) for dealing with IO.\n\nsource\n\n\n\n walk (path:pathlib.Path|str, symlinks:bool=True, keep_file:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_true&gt;, keep_folder:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_true&gt;, skip_folder:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_false&gt;, func:&lt;built-\n       infunctioncallable&gt;=&lt;function join&gt;, ret_folders:bool=False)\n\nGenerator version of os.walk, using functions to filter files and folders\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\npathlib.Path | str\n\npath to start searching\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nkeep_file\ncallable\nret_true\nfunction that returns True for wanted files\n\n\nkeep_folder\ncallable\nret_true\nfunction that returns True for folders to enter\n\n\nskip_folder\ncallable\nret_false\nfunction that returns True for folders to skip\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\n\n\nsource\n\n\n\n\n globtastic (path:pathlib.Path|str, recursive:bool=True,\n             symlinks:bool=True, file_glob:str=None, file_re:str=None,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str=None, skip_folder_re:str=None, func:&lt;built-\n             infunctioncallable&gt;=&lt;function join&gt;, ret_folders:bool=False)\n\nA more powerful glob, including regex matches, symlink handling, and skip parameters\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\npathlib.Path | str\n\npath to start searching\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\nNone\nSkip folders matching regex,\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\nReturns\nL\n\nPaths to matched files\n\n\n\n\nglobtastic('.', skip_folder_re='^[_.]', folder_re='core', file_glob='*.*py*', file_re='c')\n\n(#5) ['./fastcore/docments.py','./fastcore/dispatch.py','./fastcore/basics.py','./fastcore/docscrape.py','./fastcore/script.py']\n\n\n\nsource\n\n\n\n\n maybe_open (f, mode='r', **kwargs)\n\nContext manager: open f if it is a path (and close on exit)\nThis is useful for functions where you want to accept a path or file. maybe_open will not close your file handle if you pass one in.\n\ndef _f(fn):\n    with maybe_open(fn) as f: return f.encoding\n\nfname = '00_test.ipynb'\nsys_encoding = 'cp1252' if sys.platform == 'win32' else 'UTF-8'\ntest_eq(_f(fname), sys_encoding)\nwith open(fname) as fh: test_eq(_f(fh), sys_encoding)\n\nFor example, we can use this to reimplement imghdr.what from the Python standard library, which is written in Python 3.9 as:\n\nfrom fastcore import imghdr\n\n\ndef what(file, h=None):\n    f = None\n    try:\n        if h is None:\n            if isinstance(file, (str,os.PathLike)):\n                f = open(file, 'rb')\n                h = f.read(32)\n            else:\n                location = file.tell()\n                h = file.read(32)\n                file.seek(location)\n        for tf in imghdr.tests:\n            res = tf(h, f)\n            if res: return res\n    finally:\n        if f: f.close()\n    return None\n\nHere’s an example of the use of this function:\n\nfname = 'images/puppy.jpg'\nwhat(fname)\n\n'jpeg'\n\n\nWith maybe_open, Self, and L.map_first, we can rewrite this in a much more concise and (in our opinion) clear way:\n\ndef what(file, h=None):\n    if h is None:\n        with maybe_open(file, 'rb') as f: h = f.peek(32)\n    return L(imghdr.tests).map_first(Self(h,file))\n\n…and we can check that it still works:\n\ntest_eq(what(fname), 'jpeg')\n\n…along with the version passing a file handle:\n\nwith open(fname,'rb') as f: test_eq(what(f), 'jpeg')\n\n…along with the h parameter version:\n\nwith open(fname,'rb') as f: test_eq(what(None, h=f.read(32)), 'jpeg')\n\n\nsource\n\n\n\n\n mkdir (path, exist_ok=False, parents=False, overwrite=False, **kwargs)\n\nCreates and returns a directory defined by path, optionally removing previous existing directory if overwrite is True\n\nwith tempfile.TemporaryDirectory() as d:\n    path = Path(os.path.join(d, 'new_dir'))\n    new_dir = mkdir(path)\n    assert new_dir.exists()\n    test_eq(new_dir, path)\n        \n    # test overwrite\n    with open(new_dir/'test.txt', 'w') as f: f.writelines('test')\n    test_eq(len(list(walk(new_dir))), 1) # assert file is present\n    new_dir = mkdir(new_dir, overwrite=True)\n    test_eq(len(list(walk(new_dir))), 0) # assert file was deleted\n\n\nsource\n\n\n\n\n image_size (fn)\n\nTuple of (w,h) for png, gif, or jpg; None otherwise\n\ntest_eq(image_size(fname), (1200,803))\n\n\nsource\n\n\n\n\n bunzip (fn)\n\nbunzip fn, raising exception if output already exists\n\nf = Path('files/test.txt')\nif f.exists(): f.unlink()\nbunzip('files/test.txt.bz2')\nt = f.open().readlines()\ntest_eq(len(t),1)\ntest_eq(t[0], 'test\\n')\nf.unlink()\n\n\nsource\n\n\n\n\n loads (s, **kw)\n\nSame as json.loads, but handles None\n\nsource\n\n\n\n\n loads_multi (s:str)\n\nGenerator of &gt;=0 decoded json dicts, possibly with non-json ignored text at start and end\n\ntst = \"\"\"\n# ignored\n{ \"a\":1 }\nhello\n{\n\"b\":2\n}\n\"\"\"\n\ntest_eq(list(loads_multi(tst)), [{'a': 1}, {'b': 2}])\n\n\nsource\n\n\n\n\n dumps (obj, **kw)\n\nSame as json.dumps, but uses ujson if available\n\nsource\n\n\n\n\n untar_dir (fname, dest, rename=False, overwrite=False)\n\nuntar file into dest, creating a directory if the root contains more than one item\n\ndef test_untar(foldername, rename=False, **kwargs):\n    with tempfile.TemporaryDirectory() as d:\n        nm = os.path.join(d, 'a')\n        shutil.make_archive(nm, 'gztar', **kwargs)\n        with tempfile.TemporaryDirectory() as d2:\n            d2 = Path(d2)\n            untar_dir(nm+'.tar.gz', d2, rename=rename)\n            test_eq(d2.ls(), [d2/foldername])\n\nIf the contents of fname contain just one file or directory, it is placed directly in dest:\n\n# using `base_dir` in `make_archive` results in `images` directory included in file names\ntest_untar('images', base_dir='images')\n\nIf rename then the directory created is named based on the archive, without extension:\n\ntest_untar('a', base_dir='images', rename=True)\n\nIf the contents of fname contain multiple files and directories, a new folder in dest is created with the same name as fname (but without extension):\n\n# using `root_dir` in `make_archive` results in `images` directory *not* included in file names\ntest_untar('a', root_dir='images')\n\n\nsource\n\n\n\n\n repo_details (url)\n\nTuple of owner,name from ssh or https git repo url\n\ntest_eq(repo_details('https://github.com/fastai/fastai.git'), ['fastai', 'fastai'])\ntest_eq(repo_details('git@github.com:fastai/nbdev.git\\n'), ['fastai', 'nbdev'])\n\n\nsource\n\n\n\n\n run (cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False,\n      stderr=False)\n\nPass cmd (splitting with shlex if string) to subprocess.run; return stdout; raise IOError if fails\nYou can pass a string (which will be split based on standard shell rules), a list, or pass args directly:\n\nrun('echo', same_in_win=True)\nrun('pip', '--version', same_in_win=True)\nrun(['pip', '--version'], same_in_win=True)\n\n'pip 23.3.1 from /Users/jhoward/miniconda3/lib/python3.11/site-packages/pip (python 3.11)'\n\n\n\nif sys.platform == 'win32':\n    assert 'ipynb' in run('cmd /c dir /p')\n    assert 'ipynb' in run(['cmd', '/c', 'dir', '/p'])\n    assert 'ipynb' in run('cmd', '/c', 'dir',  '/p')\nelse:\n    assert 'ipynb' in run('ls -ls')\n    assert 'ipynb' in run(['ls', '-l'])\n    assert 'ipynb' in run('ls', '-l')\n\nSome commands fail in non-error situations, like grep. Use ignore_ex in those cases, which will return a tuple of stdout and returncode:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c findstr asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\nelse:\n    test_eq(run('grep asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\n\nrun automatically decodes returned bytes to a str. Use as_bytes to skip that:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c echo hi'), 'hi')\nelse:\n    test_eq(run('echo hi', as_bytes=True), b'hi\\n')\n\n\nsource\n\n\n\n\n open_file (fn, mode='r', **kwargs)\n\nOpen a file, with optional compression if gz or bz2 suffix\n\nsource\n\n\n\n\n save_pickle (fn, o)\n\nSave a pickle file, to a file name or opened file\n\nsource\n\n\n\n\n load_pickle (fn)\n\nLoad a pickle file from a file name or opened file\n\nfor suf in '.pkl','.bz2','.gz':\n    # delete=False is added for Windows\n    # https://stackoverflow.com/questions/23212435/permission-denied-to-write-to-my-temporary-file\n    with tempfile.NamedTemporaryFile(suffix=suf, delete=False) as f:\n        fn = Path(f.name)\n        save_pickle(fn, 't')\n        t = load_pickle(fn)\n    f.close()\n    test_eq(t,'t')\n\n\nsource\n\n\n\n\n parse_env (s:str=None, fn:Union[str,pathlib.Path]=None)\n\nParse a shell-style environment string or file\n\ntestf = \"\"\"# comment\n   # another comment\n export FOO=\"bar#baz\"\nBAR=thing # comment \"ok\"\n  baz='thong'\nQUX=quux\nexport ZAP = \"zip\" # more comments\n   FOOBAR = 42   # trailing space and comment\"\"\"\n\nexp = dict(FOO='bar#baz', BAR='thing', baz='thong', QUX='quux', ZAP='zip', FOOBAR='42')\n\ntest_eq(parse_env(testf),  exp)\n\n\nsource\n\n\n\n\n expand_wildcards (code)\n\nExpand all wildcard imports in the given code string.\n\ninp = \"\"\"from math import *\nfrom os import *\nfrom random import *\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\nexp = \"\"\"from math import pi, sin\nfrom os import path\nfrom random import randint\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)\n\ninp = \"\"\"from itertools import *\ndef func(): pass\"\"\"\ntest_eq(expand_wildcards(inp), inp)\n\ninp = \"\"\"def outer():\n    from math import *\n    def inner():\n        from os import *\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\nexp = \"\"\"def outer():\n    from math import pi, sin\n    def inner():\n        from os import path\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#file-functions",
    "href": "xtras.html#file-functions",
    "title": "Utility functions",
    "section": "",
    "text": "Utilities (other than extensions to Pathlib.Path) for dealing with IO.\n\nsource\n\n\n\n walk (path:pathlib.Path|str, symlinks:bool=True, keep_file:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_true&gt;, keep_folder:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_true&gt;, skip_folder:&lt;built-\n       infunctioncallable&gt;=&lt;function ret_false&gt;, func:&lt;built-\n       infunctioncallable&gt;=&lt;function join&gt;, ret_folders:bool=False)\n\nGenerator version of os.walk, using functions to filter files and folders\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\npathlib.Path | str\n\npath to start searching\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nkeep_file\ncallable\nret_true\nfunction that returns True for wanted files\n\n\nkeep_folder\ncallable\nret_true\nfunction that returns True for folders to enter\n\n\nskip_folder\ncallable\nret_false\nfunction that returns True for folders to skip\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\n\n\nsource\n\n\n\n\n globtastic (path:pathlib.Path|str, recursive:bool=True,\n             symlinks:bool=True, file_glob:str=None, file_re:str=None,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str=None, skip_folder_re:str=None, func:&lt;built-\n             infunctioncallable&gt;=&lt;function join&gt;, ret_folders:bool=False)\n\nA more powerful glob, including regex matches, symlink handling, and skip parameters\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\npathlib.Path | str\n\npath to start searching\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\nNone\nSkip folders matching regex,\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\nReturns\nL\n\nPaths to matched files\n\n\n\n\nglobtastic('.', skip_folder_re='^[_.]', folder_re='core', file_glob='*.*py*', file_re='c')\n\n(#5) ['./fastcore/docments.py','./fastcore/dispatch.py','./fastcore/basics.py','./fastcore/docscrape.py','./fastcore/script.py']\n\n\n\nsource\n\n\n\n\n maybe_open (f, mode='r', **kwargs)\n\nContext manager: open f if it is a path (and close on exit)\nThis is useful for functions where you want to accept a path or file. maybe_open will not close your file handle if you pass one in.\n\ndef _f(fn):\n    with maybe_open(fn) as f: return f.encoding\n\nfname = '00_test.ipynb'\nsys_encoding = 'cp1252' if sys.platform == 'win32' else 'UTF-8'\ntest_eq(_f(fname), sys_encoding)\nwith open(fname) as fh: test_eq(_f(fh), sys_encoding)\n\nFor example, we can use this to reimplement imghdr.what from the Python standard library, which is written in Python 3.9 as:\n\nfrom fastcore import imghdr\n\n\ndef what(file, h=None):\n    f = None\n    try:\n        if h is None:\n            if isinstance(file, (str,os.PathLike)):\n                f = open(file, 'rb')\n                h = f.read(32)\n            else:\n                location = file.tell()\n                h = file.read(32)\n                file.seek(location)\n        for tf in imghdr.tests:\n            res = tf(h, f)\n            if res: return res\n    finally:\n        if f: f.close()\n    return None\n\nHere’s an example of the use of this function:\n\nfname = 'images/puppy.jpg'\nwhat(fname)\n\n'jpeg'\n\n\nWith maybe_open, Self, and L.map_first, we can rewrite this in a much more concise and (in our opinion) clear way:\n\ndef what(file, h=None):\n    if h is None:\n        with maybe_open(file, 'rb') as f: h = f.peek(32)\n    return L(imghdr.tests).map_first(Self(h,file))\n\n…and we can check that it still works:\n\ntest_eq(what(fname), 'jpeg')\n\n…along with the version passing a file handle:\n\nwith open(fname,'rb') as f: test_eq(what(f), 'jpeg')\n\n…along with the h parameter version:\n\nwith open(fname,'rb') as f: test_eq(what(None, h=f.read(32)), 'jpeg')\n\n\nsource\n\n\n\n\n mkdir (path, exist_ok=False, parents=False, overwrite=False, **kwargs)\n\nCreates and returns a directory defined by path, optionally removing previous existing directory if overwrite is True\n\nwith tempfile.TemporaryDirectory() as d:\n    path = Path(os.path.join(d, 'new_dir'))\n    new_dir = mkdir(path)\n    assert new_dir.exists()\n    test_eq(new_dir, path)\n        \n    # test overwrite\n    with open(new_dir/'test.txt', 'w') as f: f.writelines('test')\n    test_eq(len(list(walk(new_dir))), 1) # assert file is present\n    new_dir = mkdir(new_dir, overwrite=True)\n    test_eq(len(list(walk(new_dir))), 0) # assert file was deleted\n\n\nsource\n\n\n\n\n image_size (fn)\n\nTuple of (w,h) for png, gif, or jpg; None otherwise\n\ntest_eq(image_size(fname), (1200,803))\n\n\nsource\n\n\n\n\n bunzip (fn)\n\nbunzip fn, raising exception if output already exists\n\nf = Path('files/test.txt')\nif f.exists(): f.unlink()\nbunzip('files/test.txt.bz2')\nt = f.open().readlines()\ntest_eq(len(t),1)\ntest_eq(t[0], 'test\\n')\nf.unlink()\n\n\nsource\n\n\n\n\n loads (s, **kw)\n\nSame as json.loads, but handles None\n\nsource\n\n\n\n\n loads_multi (s:str)\n\nGenerator of &gt;=0 decoded json dicts, possibly with non-json ignored text at start and end\n\ntst = \"\"\"\n# ignored\n{ \"a\":1 }\nhello\n{\n\"b\":2\n}\n\"\"\"\n\ntest_eq(list(loads_multi(tst)), [{'a': 1}, {'b': 2}])\n\n\nsource\n\n\n\n\n dumps (obj, **kw)\n\nSame as json.dumps, but uses ujson if available\n\nsource\n\n\n\n\n untar_dir (fname, dest, rename=False, overwrite=False)\n\nuntar file into dest, creating a directory if the root contains more than one item\n\ndef test_untar(foldername, rename=False, **kwargs):\n    with tempfile.TemporaryDirectory() as d:\n        nm = os.path.join(d, 'a')\n        shutil.make_archive(nm, 'gztar', **kwargs)\n        with tempfile.TemporaryDirectory() as d2:\n            d2 = Path(d2)\n            untar_dir(nm+'.tar.gz', d2, rename=rename)\n            test_eq(d2.ls(), [d2/foldername])\n\nIf the contents of fname contain just one file or directory, it is placed directly in dest:\n\n# using `base_dir` in `make_archive` results in `images` directory included in file names\ntest_untar('images', base_dir='images')\n\nIf rename then the directory created is named based on the archive, without extension:\n\ntest_untar('a', base_dir='images', rename=True)\n\nIf the contents of fname contain multiple files and directories, a new folder in dest is created with the same name as fname (but without extension):\n\n# using `root_dir` in `make_archive` results in `images` directory *not* included in file names\ntest_untar('a', root_dir='images')\n\n\nsource\n\n\n\n\n repo_details (url)\n\nTuple of owner,name from ssh or https git repo url\n\ntest_eq(repo_details('https://github.com/fastai/fastai.git'), ['fastai', 'fastai'])\ntest_eq(repo_details('git@github.com:fastai/nbdev.git\\n'), ['fastai', 'nbdev'])\n\n\nsource\n\n\n\n\n run (cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False,\n      stderr=False)\n\nPass cmd (splitting with shlex if string) to subprocess.run; return stdout; raise IOError if fails\nYou can pass a string (which will be split based on standard shell rules), a list, or pass args directly:\n\nrun('echo', same_in_win=True)\nrun('pip', '--version', same_in_win=True)\nrun(['pip', '--version'], same_in_win=True)\n\n'pip 23.3.1 from /Users/jhoward/miniconda3/lib/python3.11/site-packages/pip (python 3.11)'\n\n\n\nif sys.platform == 'win32':\n    assert 'ipynb' in run('cmd /c dir /p')\n    assert 'ipynb' in run(['cmd', '/c', 'dir', '/p'])\n    assert 'ipynb' in run('cmd', '/c', 'dir',  '/p')\nelse:\n    assert 'ipynb' in run('ls -ls')\n    assert 'ipynb' in run(['ls', '-l'])\n    assert 'ipynb' in run('ls', '-l')\n\nSome commands fail in non-error situations, like grep. Use ignore_ex in those cases, which will return a tuple of stdout and returncode:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c findstr asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\nelse:\n    test_eq(run('grep asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\n\nrun automatically decodes returned bytes to a str. Use as_bytes to skip that:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c echo hi'), 'hi')\nelse:\n    test_eq(run('echo hi', as_bytes=True), b'hi\\n')\n\n\nsource\n\n\n\n\n open_file (fn, mode='r', **kwargs)\n\nOpen a file, with optional compression if gz or bz2 suffix\n\nsource\n\n\n\n\n save_pickle (fn, o)\n\nSave a pickle file, to a file name or opened file\n\nsource\n\n\n\n\n load_pickle (fn)\n\nLoad a pickle file from a file name or opened file\n\nfor suf in '.pkl','.bz2','.gz':\n    # delete=False is added for Windows\n    # https://stackoverflow.com/questions/23212435/permission-denied-to-write-to-my-temporary-file\n    with tempfile.NamedTemporaryFile(suffix=suf, delete=False) as f:\n        fn = Path(f.name)\n        save_pickle(fn, 't')\n        t = load_pickle(fn)\n    f.close()\n    test_eq(t,'t')\n\n\nsource\n\n\n\n\n parse_env (s:str=None, fn:Union[str,pathlib.Path]=None)\n\nParse a shell-style environment string or file\n\ntestf = \"\"\"# comment\n   # another comment\n export FOO=\"bar#baz\"\nBAR=thing # comment \"ok\"\n  baz='thong'\nQUX=quux\nexport ZAP = \"zip\" # more comments\n   FOOBAR = 42   # trailing space and comment\"\"\"\n\nexp = dict(FOO='bar#baz', BAR='thing', baz='thong', QUX='quux', ZAP='zip', FOOBAR='42')\n\ntest_eq(parse_env(testf),  exp)\n\n\nsource\n\n\n\n\n expand_wildcards (code)\n\nExpand all wildcard imports in the given code string.\n\ninp = \"\"\"from math import *\nfrom os import *\nfrom random import *\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\nexp = \"\"\"from math import pi, sin\nfrom os import path\nfrom random import randint\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)\n\ninp = \"\"\"from itertools import *\ndef func(): pass\"\"\"\ntest_eq(expand_wildcards(inp), inp)\n\ninp = \"\"\"def outer():\n    from math import *\n    def inner():\n        from os import *\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\nexp = \"\"\"def outer():\n    from math import pi, sin\n    def inner():\n        from os import path\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#collections",
    "href": "xtras.html#collections",
    "title": "Utility functions",
    "section": "Collections",
    "text": "Collections\n\nsource\n\ndict2obj\n\n dict2obj (d, list_func=&lt;class 'fastcore.foundation.L'&gt;, dict_func=&lt;class\n           'fastcore.basics.AttrDict'&gt;)\n\nConvert (possibly nested) dicts (or lists of dicts) to AttrDict\nThis is a convenience to give you “dotted” access to (possibly nested) dictionaries, e.g:\n\nd1 = dict(a=1, b=dict(c=2,d=3))\nd2 = dict2obj(d1)\ntest_eq(d2.b.c, 2)\ntest_eq(d2.b['c'], 2)\n\nIt can also be used on lists of dicts.\n\n_list_of_dicts = [d1, d1]\nds = dict2obj(_list_of_dicts)\ntest_eq(ds[0].b.c, 2)\n\n\nsource\n\n\nobj2dict\n\n obj2dict (d)\n\nConvert (possibly nested) AttrDicts (or lists of AttrDicts) to dict\nobj2dict can be used to reverse what is done by dict2obj:\n\ntest_eq(obj2dict(d2), d1)\ntest_eq(obj2dict(ds), _list_of_dicts)\n\n\nsource\n\n\nrepr_dict\n\n repr_dict (d)\n\nPrint nested dicts and lists, such as returned by dict2obj\n\nprint(repr_dict(d2))\n\n- a: 1\n- b: \n  - c: 2\n  - d: 3\n\n\n\nsource\n\n\nis_listy\n\n is_listy (x)\n\nisinstance(x, (tuple,list,L,slice,Generator))\n\nassert is_listy((1,))\nassert is_listy([1])\nassert is_listy(L([1]))\nassert is_listy(slice(2))\nassert not is_listy(array([1]))\n\n\nsource\n\n\nmapped\n\n mapped (f, it)\n\nmap f over it, unless it’s not listy, in which case return f(it)\n\ndef _f(x,a=1): return x-a\n\ntest_eq(mapped(_f,1),0)\ntest_eq(mapped(_f,[1,2]),[0,1])\ntest_eq(mapped(_f,(1,)),(0,))",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#extensions-to-pathlib.path",
    "href": "xtras.html#extensions-to-pathlib.path",
    "title": "Utility functions",
    "section": "Extensions to Pathlib.Path",
    "text": "Extensions to Pathlib.Path\nThe following methods are added to the standard python libary Pathlib.Path.\n\nsource\n\nPath.readlines\n\n Path.readlines (hint=-1, encoding='utf8')\n\nRead the content of self\n\nsource\n\n\nPath.read_json\n\n Path.read_json (encoding=None, errors=None)\n\nSame as read_text followed by loads\n\nsource\n\n\nPath.mk_write\n\n Path.mk_write (data, encoding=None, errors=None, mode=511)\n\nMake all parent dirs of self, and write data\n\nsource\n\n\nPath.relpath\n\n Path.relpath (start=None)\n\nSame as os.path.relpath, but returns a Path, and resolves symlinks\n\np = Path('../fastcore/').resolve()\np\n\nPath('/Users/daniel.roy.greenfeld/fh/fastcore/fastcore')\n\n\n\np.relpath(Path.cwd())\n\nPath('../fastcore')\n\n\n\nsource\n\n\nPath.ls\n\n Path.ls (n_max=None, file_type=None, file_exts=None)\n\nContents of path as a list\nWe add an ls() method to pathlib.Path which is simply defined as list(Path.iterdir()), mainly for convenience in REPL environments such as notebooks.\n\npath = Path()\nt = path.ls()\nassert len(t)&gt;0\nt1 = path.ls(10)\ntest_eq(len(t1), 10)\nt2 = path.ls(file_exts='.ipynb')\nassert len(t)&gt;len(t2)\nt[0]\n\nPath('000_tour.ipynb')\n\n\nYou can also pass an optional file_type MIME prefix and/or a list of file extensions.\n\nlib_path = (path/'../fastcore')\ntxt_files=lib_path.ls(file_type='text')\nassert len(txt_files) &gt; 0 and txt_files[0].suffix=='.py'\nipy_files=path.ls(file_exts=['.ipynb'])\nassert len(ipy_files) &gt; 0 and ipy_files[0].suffix=='.ipynb'\ntxt_files[0],ipy_files[0]\n\n(Path('../fastcore/shutil.py'), Path('000_tour.ipynb'))\n\n\n\nsource\n\n\nPath.__repr__\n\n Path.__repr__ ()\n\nReturn repr(self).\nfastai also updates the repr of Path such that, if Path.BASE_PATH is defined, all paths are printed relative to that path (as long as they are contained in Path.BASE_PATH:\n\nt = ipy_files[0].absolute()\ntry:\n    Path.BASE_PATH = t.parent.parent\n    test_eq(repr(t), f\"Path('nbs/{t.name}')\")\nfinally: Path.BASE_PATH = None\n\n\nsource\n\n\nPath.delete\n\n Path.delete ()\n\nDelete a file, symlink, or directory tree",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#reindexing-collections",
    "href": "xtras.html#reindexing-collections",
    "title": "Utility functions",
    "section": "Reindexing Collections",
    "text": "Reindexing Collections\n\nsource\n\nReindexCollection\n\n ReindexCollection (coll, idxs=None, cache=None, tfm=&lt;function noop&gt;)\n\nReindexes collection coll with indices idxs and optional LRU cache of size cache\nThis is useful when constructing batches or organizing data in a particular manner (i.e. for deep learning). This class is primarly used in organizing data for language models in fastai.\nYou can supply a custom index upon instantiation with the idxs argument, or you can call the reindex method to supply a new index for your collection.\nHere is how you can reindex a list such that the elements are reversed:\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e'], idxs=[4,3,2,1,0])\nlist(rc)\n\n['e', 'd', 'c', 'b', 'a']\n\n\nAlternatively, you can use the reindex method:\n\nsource\n\nReindexCollection.reindex\n\n ReindexCollection.reindex (idxs)\n\nReplace self.idxs with idxs\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e'])\nrc.reindex([4,3,2,1,0])\nlist(rc)\n\n['e', 'd', 'c', 'b', 'a']\n\n\nYou can optionally specify a LRU cache, which uses functools.lru_cache upon instantiation:\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\n\n#trigger a cache hit by indexing into the same element multiple times\nt[0], t[0]\nt._get.cache_info()\n\nCacheInfo(hits=1, misses=1, maxsize=2, currsize=1)\n\n\nYou can optionally clear the LRU cache by calling the cache_clear method:\n\nsource\n\n\nReindexCollection.cache_clear\n\n ReindexCollection.cache_clear ()\n\nClear LRU cache\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\n\n#trigger a cache hit by indexing into the same element multiple times\nt[0], t[0]\nt.cache_clear()\nt._get.cache_info()\n\nCacheInfo(hits=0, misses=0, maxsize=2, currsize=0)\n\n\n\nsource\n\n\nReindexCollection.shuffle\n\n ReindexCollection.shuffle ()\n\nRandomly shuffle indices\nNote that an ordered index is automatically constructed for the data structure even if one is not supplied.\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\nrc.shuffle()\nlist(rc)\n\n['a', 'd', 'h', 'c', 'e', 'b', 'f', 'g']\n\n\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\ntest_eq(list(t), range(sz))\ntest_eq(t[sz-1], sz-1)\ntest_eq(t._get.cache_info().hits, 1)\nt.shuffle()\ntest_eq(t._get.cache_info().hits, 1)\ntest_ne(list(t), range(sz))\ntest_eq(set(t), set(range(sz)))\nt.cache_clear()\ntest_eq(t._get.cache_info().hits, 0)\ntest_eq(t.count(0), 1)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#other-helpers",
    "href": "xtras.html#other-helpers",
    "title": "Utility functions",
    "section": "Other Helpers",
    "text": "Other Helpers\n\nsource\n\nexec_eval\n\n exec_eval (code, g=None, l=None)\n\nEvaluate code in g (defaults to globals()) and l (defaults to locals())\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncode\n\n\nCode to exec/eval\n\n\ng\nNoneType\nNone\nGlobals namespace dict\n\n\nl\nNoneType\nNone\nLocals namespace dict\n\n\n\nThis is a combination of eval and exec, which behaves like ipython and Jupyter. If the last line is an expression, it is evaluated and the result is returned:\n\nexec_eval('''\ndef f(x): return x+1\nf(1)\n''')\n\n2\n\n\nBy default, the code uses the caller’s globals and locals. For instance, here f is available since it’s been added to our symbol table:\n\nexec_eval('print(f(2))')\n\n3\n\n\nPass a dict as the g param in order to use an arbitrary namespace:\n\nexec_eval('print(f)', {'f': 'Hi I am f.'})\n\nHi I am f.\n\n\n\nsource\n\n\nget_source_link\n\n get_source_link (func)\n\nReturn link to func in source code\nget_source_link allows you get a link to source code related to an object. For nbdev related projects such as fastcore, we can get the full link to a GitHub repo. For nbdev projects, be sure to properly set the git_url in settings.ini (derived from lib_name and branch on top of the prefix you will need to adapt) so that those links are correct.\nFor example, below we get the link to fastcore.test.test_eq:\n\nfrom fastcore.test import test_eq\n\n\nassert 'fastcore/test.py' in get_source_link(test_eq)\nassert get_source_link(test_eq).startswith('https://github.com/fastai/fastcore')\nget_source_link(test_eq)\n\n'https://github.com/fastai/fastcore/tree/master/fastcore/test.py#L35'\n\n\n\nsource\n\n\ntruncstr\n\n truncstr (s:str, maxlen:int, suf:str='…', space='')\n\nTruncate s to length maxlen, adding suffix suf if truncated\n\nw = 'abacadabra'\ntest_eq(truncstr(w, 10), w)\ntest_eq(truncstr(w, 5), 'abac…')\ntest_eq(truncstr(w, 5, suf=''), 'abaca')\ntest_eq(truncstr(w, 11, space='_'), w+\"_\")\ntest_eq(truncstr(w, 10, space='_'), w[:-1]+'…')\ntest_eq(truncstr(w, 5, suf='!!'), 'aba!!')\n\n\nsource\n\n\nsparkline\n\n sparkline (data, mn=None, mx=None, empty_zero=False)\n\nSparkline for data, with Nones (and zero, if empty_zero) shown as empty column\n\ndata = [9,6,None,1,4,0,8,15,10]\nprint(f'without \"empty_zero\": {sparkline(data, empty_zero=False)}')\nprint(f'   with \"empty_zero\": {sparkline(data, empty_zero=True )}')\n\nwithout \"empty_zero\": ▅▂ ▁▂▁▃▇▅\n   with \"empty_zero\": ▅▂ ▁▂ ▃▇▅\n\n\nYou can set a maximum and minimum for the y-axis of the sparkline with the arguments mn and mx respectively:\n\nsparkline([1,2,3,400], mn=0, mx=3)\n\n'▂▅▇▇'\n\n\n\nsource\n\n\nmodify_exception\n\n modify_exception (e:Exception, msg:str=None, replace:bool=False)\n\nModifies e with a custom message attached\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ne\nException\n\nAn exception\n\n\nmsg\nstr\nNone\nA custom message\n\n\nreplace\nbool\nFalse\nWhether to replace e.args with [msg]\n\n\nReturns\nException\n\n\n\n\n\n\nmsg = \"This is my custom message!\"\n\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(), None)), contains='')\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(), msg)), contains=msg)\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(\"The first message\"), msg)), contains=\"The first message This is my custom message!\")\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(\"The first message\"), msg, True)), contains=\"This is my custom message!\")\n\n\nsource\n\n\nround_multiple\n\n round_multiple (x, mult, round_down=False)\n\nRound x to nearest multiple of mult\n\ntest_eq(round_multiple(63,32), 64)\ntest_eq(round_multiple(50,32), 64)\ntest_eq(round_multiple(40,32), 32)\ntest_eq(round_multiple( 0,32),  0)\ntest_eq(round_multiple(63,32, round_down=True), 32)\ntest_eq(round_multiple((63,40),32), (64,32))\n\n\nsource\n\n\nset_num_threads\n\n set_num_threads (nt)\n\nGet numpy (and others) to use nt threads\nThis sets the number of threads consistently for many tools, by:\n\nSet the following environment variables equal to nt: OPENBLAS_NUM_THREADS,NUMEXPR_NUM_THREADS,OMP_NUM_THREADS,MKL_NUM_THREADS\nSets nt threads for numpy and pytorch.\n\n\nsource\n\n\njoin_path_file\n\n join_path_file (file, path, ext='')\n\nReturn path/file if file is a string or a Path, file otherwise\n\npath = Path.cwd()/'_tmp'/'tst'\nf = join_path_file('tst.txt', path)\nassert path.exists()\ntest_eq(f, path/'tst.txt')\nwith open(f, 'w') as f_: assert join_path_file(f_, path) == f_\nshutil.rmtree(Path.cwd()/'_tmp')\n\n\nsource\n\n\nautostart\n\n autostart (g)\n\nDecorator that automatically starts a generator\n\nsource\n\nEventTimer\n\n EventTimer (store=5, span=60)\n\nAn event timer with history of store items of time span\nAdd events with add, and get number of events and their frequency (freq).\n\n# Random wait function for testing\ndef _randwait(): yield from (sleep(random.random()/200) for _ in range(100))\n\nc = EventTimer(store=5, span=0.03)\nfor o in _randwait(): c.add(1)\nprint(f'Num Events: {c.events}, Freq/sec: {c.freq:.01f}')\nprint('Most recent: ', sparkline(c.hist), *L(c.hist).map('{:.01f}'))\n\nNum Events: 3, Freq/sec: 205.6\nMost recent:  ▁▁▃▁▇ 254.1 263.2 284.5 259.9 315.7\n\n\n\nsource\n\n\n\nstringfmt_names\n\n stringfmt_names (s:str)\n\nUnique brace-delimited names in s\n\ns = '/pulls/{pull_number}/reviews/{review_id}'\ntest_eq(stringfmt_names(s), ['pull_number','review_id'])\n\n\nsource\n\nPartialFormatter\n\n PartialFormatter ()\n\nA string.Formatter that doesn’t error on missing fields, and tracks missing fields and unused args\n\nsource\n\n\n\npartial_format\n\n partial_format (s:str, **kwargs)\n\nstring format s, ignoring missing field errors, returning missing and extra fields\nThe result is a tuple of (formatted_string,missing_fields,extra_fields), e.g:\n\nres,missing,xtra = partial_format(s, pull_number=1, foo=2)\ntest_eq(res, '/pulls/1/reviews/{review_id}')\ntest_eq(missing, ['review_id'])\ntest_eq(xtra, {'foo':2})\n\n\nsource\n\n\nutc2local\n\n utc2local (dt:datetime.datetime)\n\nConvert dt from UTC to local time\n\ndt = datetime(2000,1,1,12)\nprint(f'{dt} UTC is {utc2local(dt)} local time')\n\n2000-01-01 12:00:00 UTC is 2000-01-01 22:00:00+10:00 local time\n\n\n\nsource\n\n\nlocal2utc\n\n local2utc (dt:datetime.datetime)\n\nConvert dt from local to UTC time\n\nprint(f'{dt} local is {local2utc(dt)} UTC time')\n\n2000-01-01 12:00:00 local is 2000-01-01 02:00:00+00:00 UTC time\n\n\n\nsource\n\n\ntrace\n\n trace (f)\n\nAdd set_trace to an existing function f\nYou can add a breakpoint to an existing function, e.g:\nPath.cwd = trace(Path.cwd)\nPath.cwd()\nNow, when the function is called it will drop you into the debugger. Note, you must issue the s command when you begin to step into the function that is being traced.\n\nsource\n\n\nmodified_env\n\n modified_env (*delete, **replace)\n\nContext manager temporarily modifying os.environ by deleting delete and replacing replace\n\n# USER isn't in Cloud Linux Environments\nenv_test = 'USERNAME' if sys.platform == \"win32\" else 'SHELL'\noldusr = os.environ[env_test]\n\nreplace_param = {env_test: 'a'}\nwith modified_env('PATH', **replace_param):\n    test_eq(os.environ[env_test], 'a')\n    assert 'PATH' not in os.environ\n\nassert 'PATH' in os.environ\ntest_eq(os.environ[env_test], oldusr)\n\n\nsource\n\nContextManagers\n\n ContextManagers (mgrs)\n\nWrapper for contextlib.ExitStack which enters a collection of context managers\n\nsource\n\n\n\nshufflish\n\n shufflish (x, pct=0.04)\n\nRandomly relocate items of x up to pct of len(x) from their starting location\n\nsource\n\n\nconsole_help\n\n console_help (libname:str)\n\nShow help for all console scripts from libname\n\n\n\n\nType\nDetails\n\n\n\n\nlibname\nstr\nname of library for console script listing\n\n\n\n\nsource\n\n\nhl_md\n\n hl_md (s, lang='xml', show=True)\n\nSyntax highlight s using lang.\nWhen we display code in a notebook, it’s nice to highlight it, so we create a function to simplify that:\n\nhl_md('&lt;test&gt;&lt;xml foo=\"bar\"&gt;a child&lt;/xml&gt;&lt;/test&gt;')\n\n&lt;test&gt;&lt;xml foo=\"bar\"&gt;a child&lt;/xml&gt;&lt;/test&gt;\n\n\n\nsource\n\n\ntype2str\n\n type2str (typ:type)\n\nStringify typ\n\ntest_eq(type2str(Optional[float]), 'Union[float, None]')\n\n\nsource\n\n\ndataclass_src\n\n dataclass_src (cls)\n\n\nDC = make_dataclass('DC', [('x', int), ('y', Optional[float], None), ('z', float, None)])\nprint(dataclass_src(DC))\n\n@dataclass\nclass DC:\n    x: int\n    y: Union[float, None] = None\n    z: float = None\n\n\n\n\nsource\n\n\nUnset\n\n Unset (value, names=None, module=None, qualname=None, type=None, start=1)\n\nAn enumeration.\n\nsource\n\n\nnullable_dc\n\n nullable_dc (cls)\n\nLike dataclass, but default of UNSET added to fields without defaults\n\n@nullable_dc\nclass Person: name: str; age: int; city: str = \"Unknown\"\nPerson(name=\"Bob\")\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n\nsource\n\n\nmake_nullable\n\n make_nullable (clas)\n\n\n@dataclass\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nmake_nullable(Person)\nPerson(\"Bob\", city='NY')\n\nPerson(name='Bob', age=UNSET, city='NY')\n\n\n\nPerson(name=\"Bob\")\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n\nPerson(\"Bob\", 34)\n\nPerson(name='Bob', age=34, city='Unknown')\n\n\n\nsource\n\n\nflexiclass\n\n flexiclass (cls)\n\nConvert cls into a dataclass like make_nullable. Converts in place and also returns the result.\n\n\n\n\nType\nDetails\n\n\n\n\ncls\n\nThe class to convert\n\n\nReturns\ndataclass\n\n\n\n\nThis can be used as a decorator…\n\n@flexiclass\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nbob = Person(name=\"Bob\")\nbob\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n…or can update the behavior of an existing class (or dataclass):\n\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nflexiclass(Person)\nbob = Person(name=\"Bob\")\nbob\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\nAction occurs in-place:\n\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nflexiclass(Person)\nis_dataclass(Person)\n\nTrue\n\n\n\nsource\n\n\nasdict\n\n asdict (o)\n\nConvert o to a dict, supporting dataclasses, namedtuples, iterables, and __dict__ attrs.\nAny UNSET values are not included.\n\nasdict(bob)\n\n{'name': 'Bob', 'city': 'Unknown'}\n\n\nTo customise dict conversion behavior for a class, implement the _asdict method (this is used in the Python stdlib for named tuples).\n\nsource\n\n\nis_typeddict\n\n is_typeddict (cls:type)\n\nCheck if cls is a TypedDict\n\nclass MyDict(TypedDict): name:str\n\nassert is_typeddict(MyDict)\nassert not is_typeddict({'a':1})\n\n\nsource\n\n\nis_namedtuple\n\n is_namedtuple (cls)\n\nTrue if cls is a namedtuple type\n\nassert is_namedtuple(namedtuple('tst', ['a']))\nassert not is_namedtuple(tuple)\n\n\nsource\n\n\nflexicache\n\n flexicache (*funcs, maxsize=128)\n\nLike lru_cache, but customisable with policy funcs\nThis is a flexible lru cache function that you can pass a list of functions to. Those functions define the cache eviction policy. For instance, time_policy is provided for time-based cache eviction, and mtime_policy evicts based on a file’s modified-time changing. The policy functions are passed the last value that function returned was (initially None), and return a new value to indicate the cache has expired. When the cache expires, all functions are called with None to force getting new values.\n\nsource\n\n\ntime_policy\n\n time_policy (seconds)\n\nA flexicache policy that expires cached items after seconds have passed\n\nsource\n\n\nmtime_policy\n\n mtime_policy (filepath)\n\nA flexicache policy that expires cached items after filepath modified-time changes\n\n@flexicache(time_policy(10), mtime_policy('000_tour.ipynb'))\ndef cached_func(x, y): return x+y\n\ncached_func(1,2)\n\n3\n\n\n\n@flexicache(time_policy(10), mtime_policy('000_tour.ipynb'))\nasync def cached_func(x, y): return x+y\n\nawait cached_func(1,2)\nawait cached_func(1,2)\n\n3\n\n\n\nsource\n\n\ntimed_cache\n\n timed_cache (seconds=60, maxsize=128)\n\nLike lru_cache, but also with time-based eviction\nThis function is a small convenience wrapper for using flexicache with time_policy.\n\n@timed_cache(seconds=0.05, maxsize=2)\ndef cached_func(x): return x * 2, time()\n\n# basic caching\nresult1, time1 = cached_func(2)\ntest_eq(result1, 4)\nsleep(0.001)\nresult2, time2 = cached_func(2)\ntest_eq(result2, 4)\ntest_eq(time1, time2)\n\n# caching different values\nresult3, _ = cached_func(3)\ntest_eq(result3, 6)\n\n# maxsize\n_, time4 = cached_func(4)\n_, time2_new = cached_func(2)\ntest_close(time2, time2_new, eps=0.1)\n_, time3_new = cached_func(3)\ntest_ne(time3_new, time())\n\n# time expiration\nsleep(0.05)\n_, time4_new = cached_func(4)\ntest_ne(time4_new, time())",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "foundation.html",
    "href": "foundation.html",
    "title": "Foundation",
    "section": "",
    "text": "source\n\n\n\n working_directory (path)\n\nChange working directory to path and return to previous on exit.\n\nsource\n\n\n\n\n add_docs (cls, cls_doc=None, **docs)\n\nCopy values from docs to cls docstrings, and confirm all public methods are documented\nadd_docs allows you to add docstrings to a class and its associated methods. This function allows you to group docstrings together seperate from your code, which enables you to define one-line functions as well as organize your code more succintly. We believe this confers a number of benefits which we discuss in our style guide.\nSuppose you have the following undocumented class:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nYou can add documentation to this class like so:\n\nadd_docs(T, cls_doc=\"A docstring for the class.\",\n            foo=\"The foo method.\",\n            bar=\"The bar method.\")\n\nNow, docstrings will appear as expected:\n\ntest_eq(T.__doc__, \"A docstring for the class.\")\ntest_eq(T.foo.__doc__, \"The foo method.\")\ntest_eq(T.bar.__doc__, \"The bar method.\")\n\nadd_docs also validates that all of your public methods contain a docstring. If one of your methods is not documented, it will raise an error:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nf=lambda: add_docs(T, \"A docstring for the class.\", foo=\"The foo method.\")\ntest_fail(f, contains=\"Missing docs\")\n\n\nsource\n\n\n\n\n docs (cls)\n\nDecorator version of add_docs, using _docs dict\nInstead of using add_docs, you can use the decorator docs as shown below. Note that the docstring for the class can be set with the argument cls_doc:\n\n@docs\nclass _T:\n    def f(self): pass\n    def g(cls): pass\n    \n    _docs = dict(cls_doc=\"The class docstring\", \n                 f=\"The docstring for method f.\",\n                 g=\"A different docstring for method g.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\ntest_eq(_T.g.__doc__, \"A different docstring for method g.\")\n\nFor either the docs decorator or the add_docs function, you can still define your docstrings in the normal way. Below we set the docstring for the class as usual, but define the method docstrings through the _docs attribute:\n\n@docs\nclass _T:\n    \"The class docstring\"\n    def f(self): pass\n    _docs = dict(f=\"The docstring for method f.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\n\n\n\n\n\n\n is_iter (o)\n\nTest whether o can be used in a for loop\n\nassert is_iter([1])\nassert not is_iter(array(1))\nassert is_iter(array([1,2]))\nassert (o for o in range(3))\n\n\nsource\n\n\n\n\n coll_repr (c, max_n=20)\n\nString repr of up to max_n items of (possibly lazy) collection c\ncoll_repr is used to provide a more informative __repr__ about list-like objects. coll_repr and is used by L to build a __repr__ that displays the length of a list in addition to a preview of a list.\nBelow is an example of the __repr__ string created for a list of 1000 elements:\n\ntest_eq(coll_repr(range(1000),10), '(#1000) [0,1,2,3,4,5,6,7,8,9...]')\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0,1,2,3,4...]')\ntest_eq(coll_repr(range(10),   5), '(#10) [0,1,2,3,4...]')\ntest_eq(coll_repr(range(5),    5), '(#5) [0,1,2,3,4]')\n\n\nsource\n\n\n\n\n is_bool (x)\n\nCheck whether x is a bool or None\n\nsource\n\n\n\n\n mask2idxs (mask)\n\nConvert bool mask or index list to index L\n\ntest_eq(mask2idxs([False,True,False,True]), [1,3])\ntest_eq(mask2idxs(array([False,True,False,True])), [1,3])\ntest_eq(mask2idxs(array([1,2,3])), [1,2,3])\n\n\nsource\n\n\n\n\n cycle (o)\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\n\n\n zip_cycle (x, *args)\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\n\n\n is_indexer (idx)\n\nTest whether idx will index a single item in a list\nYou can, for example index a single item in a list with an integer or a 0-dimensional numpy array:\n\nassert is_indexer(1)\nassert is_indexer(np.array(1))\n\nHowever, you cannot index into single item in a list with another list or a numpy array with ndim &gt; 0.\n\nassert not is_indexer([1, 2])\nassert not is_indexer(np.array([[1, 2], [3, 4]]))",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#foundational-functions",
    "href": "foundation.html#foundational-functions",
    "title": "Foundation",
    "section": "",
    "text": "source\n\n\n\n working_directory (path)\n\nChange working directory to path and return to previous on exit.\n\nsource\n\n\n\n\n add_docs (cls, cls_doc=None, **docs)\n\nCopy values from docs to cls docstrings, and confirm all public methods are documented\nadd_docs allows you to add docstrings to a class and its associated methods. This function allows you to group docstrings together seperate from your code, which enables you to define one-line functions as well as organize your code more succintly. We believe this confers a number of benefits which we discuss in our style guide.\nSuppose you have the following undocumented class:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nYou can add documentation to this class like so:\n\nadd_docs(T, cls_doc=\"A docstring for the class.\",\n            foo=\"The foo method.\",\n            bar=\"The bar method.\")\n\nNow, docstrings will appear as expected:\n\ntest_eq(T.__doc__, \"A docstring for the class.\")\ntest_eq(T.foo.__doc__, \"The foo method.\")\ntest_eq(T.bar.__doc__, \"The bar method.\")\n\nadd_docs also validates that all of your public methods contain a docstring. If one of your methods is not documented, it will raise an error:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nf=lambda: add_docs(T, \"A docstring for the class.\", foo=\"The foo method.\")\ntest_fail(f, contains=\"Missing docs\")\n\n\nsource\n\n\n\n\n docs (cls)\n\nDecorator version of add_docs, using _docs dict\nInstead of using add_docs, you can use the decorator docs as shown below. Note that the docstring for the class can be set with the argument cls_doc:\n\n@docs\nclass _T:\n    def f(self): pass\n    def g(cls): pass\n    \n    _docs = dict(cls_doc=\"The class docstring\", \n                 f=\"The docstring for method f.\",\n                 g=\"A different docstring for method g.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\ntest_eq(_T.g.__doc__, \"A different docstring for method g.\")\n\nFor either the docs decorator or the add_docs function, you can still define your docstrings in the normal way. Below we set the docstring for the class as usual, but define the method docstrings through the _docs attribute:\n\n@docs\nclass _T:\n    \"The class docstring\"\n    def f(self): pass\n    _docs = dict(f=\"The docstring for method f.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\n\n\n\n\n\n\n is_iter (o)\n\nTest whether o can be used in a for loop\n\nassert is_iter([1])\nassert not is_iter(array(1))\nassert is_iter(array([1,2]))\nassert (o for o in range(3))\n\n\nsource\n\n\n\n\n coll_repr (c, max_n=20)\n\nString repr of up to max_n items of (possibly lazy) collection c\ncoll_repr is used to provide a more informative __repr__ about list-like objects. coll_repr and is used by L to build a __repr__ that displays the length of a list in addition to a preview of a list.\nBelow is an example of the __repr__ string created for a list of 1000 elements:\n\ntest_eq(coll_repr(range(1000),10), '(#1000) [0,1,2,3,4,5,6,7,8,9...]')\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0,1,2,3,4...]')\ntest_eq(coll_repr(range(10),   5), '(#10) [0,1,2,3,4...]')\ntest_eq(coll_repr(range(5),    5), '(#5) [0,1,2,3,4]')\n\n\nsource\n\n\n\n\n is_bool (x)\n\nCheck whether x is a bool or None\n\nsource\n\n\n\n\n mask2idxs (mask)\n\nConvert bool mask or index list to index L\n\ntest_eq(mask2idxs([False,True,False,True]), [1,3])\ntest_eq(mask2idxs(array([False,True,False,True])), [1,3])\ntest_eq(mask2idxs(array([1,2,3])), [1,2,3])\n\n\nsource\n\n\n\n\n cycle (o)\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\n\n\n zip_cycle (x, *args)\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\n\n\n is_indexer (idx)\n\nTest whether idx will index a single item in a list\nYou can, for example index a single item in a list with an integer or a 0-dimensional numpy array:\n\nassert is_indexer(1)\nassert is_indexer(np.array(1))\n\nHowever, you cannot index into single item in a list with another list or a numpy array with ndim &gt; 0.\n\nassert not is_indexer([1, 2])\nassert not is_indexer(np.array([[1, 2], [3, 4]]))",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#l-helpers",
    "href": "foundation.html#l-helpers",
    "title": "Foundation",
    "section": "L helpers",
    "text": "L helpers\n\nsource\n\nCollBase\n\n CollBase (items)\n\nBase class for composing a list of items\nColBase is a base class that emulates the functionality of a python list:\n\nclass _T(CollBase): pass\nl = _T([1,2,3,4,5])\n\ntest_eq(len(l), 5) # __len__\ntest_eq(l[-1], 5); test_eq(l[0], 1) #__getitem__\nl[2] = 100; test_eq(l[2], 100)      # __set_item__\ndel l[0]; test_eq(len(l), 4)        # __delitem__\ntest_eq(str(l), '[2, 100, 4, 5]')   # __repr__\n\n\nsource\n\n\nL\n\n L (x=None, *args, **kwargs)\n\nBehaves like a list of items but can also index with list of indices or masks\nL is a drop in replacement for a python list. Inspired by NumPy, L, supports advanced indexing and has additional methods (outlined below) that provide additional functionality and encourage simple expressive code. For example, the code below takes a list of pairs, selects the second item of each pair, takes its absolute value, filters items greater than 4, and adds them up:\n\nfrom fastcore.utils import gt\n\n\nd = dict(a=1,b=-5,d=6,e=9).items()\ntest_eq(L(d).itemgot(1).map(abs).filter(gt(4)).sum(), 20) # abs(-5) + abs(6) + abs(9) = 20; 1 was filtered out.\n\nRead this overview section for a quick tutorial of L, as well as background on the name.\nYou can create an L from an existing iterable (e.g. a list, range, etc) and access or modify it with an int list/tuple index, mask, int, or slice. All list methods can also be used with L.\n\nt = L(range(12))\ntest_eq(t, list(range(12)))\ntest_ne(t, list(range(11)))\nt.reverse()\ntest_eq(t[0], 11)\nt[3] = \"h\"\ntest_eq(t[3], \"h\")\nt[3,5] = (\"j\",\"k\")\ntest_eq(t[3,5], [\"j\",\"k\"])\ntest_eq(t, L(t))\ntest_eq(L(L(1,2),[3,4]), ([1,2],[3,4]))\nt\n\n(#12) [11,10,9,'j',7,'k',5,4,3,2,1,0]\n\n\nAny L is a Sequence so you can use it with methods like random.sample:\n\nassert isinstance(t, Sequence)\n\n\nimport random\n\n\nrandom.seed(0)\nrandom.sample(t, 3)\n\n[5, 0, 11]\n\n\nThere are optimized indexers for arrays, tensors, and DataFrames.\n\nimport pandas as pd\n\n\narr = np.arange(9).reshape(3,3)\nt = L(arr, use_list=None)\ntest_eq(t[1,2], arr[[1,2]])\n\ndf = pd.DataFrame({'a':[1,2,3]})\nt = L(df, use_list=None)\ntest_eq(t[1,2], L(pd.DataFrame({'a':[2,3]}, index=[1,2]), use_list=None))\n\nYou can also modify an L with append, +, and *.\n\nt = L()\ntest_eq(t, [])\nt.append(1)\ntest_eq(t, [1])\nt += [3,2]\ntest_eq(t, [1,3,2])\nt = t + [4]\ntest_eq(t, [1,3,2,4])\nt = 5 + t\ntest_eq(t, [5,1,3,2,4])\ntest_eq(L(1,2,3), [1,2,3])\ntest_eq(L(1,2,3), L(1,2,3))\nt = L(1)*5\nt = t.map(operator.neg)\ntest_eq(t,[-1]*5)\ntest_eq(~L([True,False,False]), L([False,True,True]))\nt = L(range(4))\ntest_eq(zip(t, L(1).cycle()), zip(range(4),(1,1,1,1)))\nt = L.range(100)\ntest_shuffled(t,t.shuffle())\n\n\ntest_eq(L([]).sum(), 0)\ntest_eq(L([]).product(), 1)\n\n\ndef _f(x,a=0): return x+a\nt = L(1)*5\ntest_eq(t.map(_f), t)\ntest_eq(t.map(_f,1), [2]*5)\ntest_eq(t.map(_f,a=2), [3]*5)\n\nAn L can be constructed from anything iterable, although tensors and arrays will not be iterated over on construction, unless you pass use_list to the constructor.\n\ntest_eq(L([1,2,3]),[1,2,3])\ntest_eq(L(L([1,2,3])),[1,2,3])\ntest_ne(L([1,2,3]),[1,2,])\ntest_eq(L('abc'),['abc'])\ntest_eq(L(range(0,3)),[0,1,2])\ntest_eq(L(o for o in range(0,3)),[0,1,2])\ntest_eq(L(array(0)),[array(0)])\ntest_eq(L([array(0),array(1)]),[array(0),array(1)])\ntest_eq(L(array([0.,1.1]))[0],array([0.,1.1]))\ntest_eq(L(array([0.,1.1]), use_list=True), [array(0.),array(1.1)])  # `use_list=True` to unwrap arrays/arrays\n\nIf match is not None then the created list is same len as match, either by:\n\nIf len(items)==1 then items is replicated,\nOtherwise an error is raised if match and items are not already the same size.\n\n\ntest_eq(L(1,match=[1,2,3]),[1,1,1])\ntest_eq(L([1,2],match=[2,3]),[1,2])\ntest_fail(lambda: L([1,2],match=[1,2,3]))\n\nIf you create an L from an existing L then you’ll get back the original object (since L uses the NewChkMeta metaclass).\n\ntest_is(L(t), t)\n\nAn L is considred equal to a list if they have the same elements. It’s never considered equal to a str a set or a dict even if they have the same elements/keys.\n\ntest_eq(L(['a', 'b']), ['a', 'b'])\ntest_ne(L(['a', 'b']), 'ab')\ntest_ne(L(['a', 'b']), {'a':1, 'b':2})\n\n\n\nL Methods\n\nsource\n\n\nL.__getitem__\n\n L.__getitem__ (idx)\n\nRetrieve idx (can be list of indices, or mask, or int) items\n\nt = L(range(12))\ntest_eq(t[1,2], [1,2])                # implicit tuple\ntest_eq(t[[1,2]], [1,2])              # list\ntest_eq(t[:3], [0,1,2])               # slice\ntest_eq(t[[False]*11 + [True]], [11]) # mask\ntest_eq(t[array(3)], 3)\n\n\nsource\n\n\nL.__setitem__\n\n L.__setitem__ (idx, o)\n\nSet idx (can be list of indices, or mask, or int) items to o (which is broadcast if not iterable)\n\nt[4,6] = 0\ntest_eq(t[4,6], [0,0])\nt[4,6] = [1,2]\ntest_eq(t[4,6], [1,2])\n\n\nsource\n\n\nL.unique\n\n L.unique (sort=False, bidir=False, start=None)\n\nUnique items, in stable order\n\ntest_eq(L(4,1,2,3,4,4).unique(), [4,1,2,3])\n\n\nsource\n\n\nL.val2idx\n\n L.val2idx ()\n\nDict from value to index\n\ntest_eq(L(1,2,3).val2idx(), {3:2,1:0,2:1})\n\n\nsource\n\n\nL.groupby\n\n L.groupby (key, val=&lt;function noop&gt;)\n\nSame as fastcore.basics.groupby\n\nwords = L.split('aaa abc bba')\ntest_eq(words.groupby(0, (1,2)), {'a':[('a','a'),('b','c')], 'b':[('b','a')]})\n\n\nsource\n\n\nL.filter\n\n L.filter (f=&lt;function noop&gt;, negate=False, **kwargs)\n\nCreate new L filtered by predicate f, passing args and kwargs to f\n\nlist(t)\n\n[0, 1, 2, 3, 1, 5, 2, 7, 8, 9, 10, 11]\n\n\n\ntest_eq(t.filter(lambda o:o&lt;5), [0,1,2,3,1,2])\ntest_eq(t.filter(lambda o:o&lt;5, negate=True), [5,7,8,9,10,11])\n\n\nsource\n\n\nL.argwhere\n\n L.argwhere (f, negate=False, **kwargs)\n\nLike filter, but return indices for matching items\n\ntest_eq(t.argwhere(lambda o:o&lt;5), [0,1,2,3,4,6])\n\n\nsource\n\n\nL.argfirst\n\n L.argfirst (f, negate=False)\n\nReturn index of first matching item\n\ntest_eq(t.argfirst(lambda o:o&gt;4), 5)\ntest_eq(t.argfirst(lambda o:o&gt;4,negate=True),0)\n\n\nsource\n\n\nL.map\n\n L.map (f, *args, **kwargs)\n\nCreate new L with f applied to all items, passing args and kwargs to f\n\ntest_eq(L.range(4).map(operator.neg), [0,-1,-2,-3])\n\nIf f is a string then it is treated as a format string to create the mapping:\n\ntest_eq(L.range(4).map('#{}#'), ['#0#','#1#','#2#','#3#'])\n\nIf f is a dictionary (or anything supporting __getitem__) then it is indexed to create the mapping:\n\ntest_eq(L.range(4).map(list('abcd')), list('abcd'))\n\nYou can also pass the same arg params that bind accepts:\n\ndef f(a=None,b=None): return b\ntest_eq(L.range(4).map(f, b=arg0), range(4))\n\n\nsource\n\n\nL.map_dict\n\n L.map_dict (f=&lt;function noop&gt;, *args, **kwargs)\n\nLike map, but creates a dict from items to function results\n\ntest_eq(L(range(1,5)).map_dict(), {1:1, 2:2, 3:3, 4:4})\ntest_eq(L(range(1,5)).map_dict(operator.neg), {1:-1, 2:-2, 3:-3, 4:-4})\n\n\nsource\n\n\nL.zip\n\n L.zip (cycled=False)\n\nCreate new L with zip(*items)\n\nt = L([[1,2,3],'abc'])\ntest_eq(t.zip(), [(1, 'a'),(2, 'b'),(3, 'c')])\n\n\nt = L([[1,2,3,4],['a','b','c']])\ntest_eq(t.zip(cycled=True ), [(1, 'a'),(2, 'b'),(3, 'c'),(4, 'a')])\ntest_eq(t.zip(cycled=False), [(1, 'a'),(2, 'b'),(3, 'c')])\n\n\nsource\n\n\nL.map_zip\n\n L.map_zip (f, *args, cycled=False, **kwargs)\n\nCombine zip and starmap\n\nt = L([1,2,3],[2,3,4])\ntest_eq(t.map_zip(operator.mul), [2,6,12])\n\n\nsource\n\n\nL.zipwith\n\n L.zipwith (*rest, cycled=False)\n\nCreate new L with self zip with each of *rest\n\nb = [[0],[1],[2,2]]\nt = L([1,2,3]).zipwith(b)\ntest_eq(t, [(1,[0]), (2,[1]), (3,[2,2])])\n\n\nsource\n\n\nL.map_zipwith\n\n L.map_zipwith (f, *rest, cycled=False, **kwargs)\n\nCombine zipwith and starmap\n\ntest_eq(L(1,2,3).map_zipwith(operator.mul, [2,3,4]), [2,6,12])\n\n\nsource\n\n\nL.itemgot\n\n L.itemgot (*idxs)\n\nCreate new L with item idx of all items\n\ntest_eq(t.itemgot(1), b)\n\n\nsource\n\n\nL.attrgot\n\n L.attrgot (k, default=None)\n\nCreate new L with attr k (or value k for dicts) of all items.\n\n# Example when items are not a dict\na = [SimpleNamespace(a=3,b=4),SimpleNamespace(a=1,b=2)]\ntest_eq(L(a).attrgot('b'), [4,2])\n\n#Example of when items are a dict\nb =[{'id': 15, 'name': 'nbdev'}, {'id': 17, 'name': 'fastcore'}]\ntest_eq(L(b).attrgot('id'), [15, 17])\n\n\nsource\n\n\nL.sorted\n\n L.sorted (key=None, reverse=False, cmp=None, **kwargs)\n\nNew L sorted by key, using sort_ex. If key is str use attrgetter; if int use itemgetter\n\ntest_eq(L(a).sorted('a').attrgot('b'), [2,4])\n\n\nsource\n\n\nL.split\n\n L.split (s, sep=None, maxsplit=-1)\n\nClass Method: Same as str.split, but returns an L\n\ntest_eq(L.split('a b c'), list('abc'))\n\n\nsource\n\n\nL.range\n\n L.range (a, b=None, step=None)\n\nClass Method: Same as range, but returns L. Can pass collection for a, to use len(a)\n\ntest_eq_type(L.range([1,1,1]), L(range(3)))\ntest_eq_type(L.range(5,2,2), L(range(5,2,2)))\n\n\nsource\n\n\nL.concat\n\n L.concat ()\n\nConcatenate all elements of list\n\ntest_eq(L([0,1,2,3],4,L(5,6)).concat(), range(7))\n\n\nsource\n\n\nL.copy\n\n L.copy ()\n\nSame as list.copy, but returns an L\n\nt = L([0,1,2,3],4,L(5,6)).copy()\ntest_eq(t.concat(), range(7))\n\n\nsource\n\n\nL.map_first\n\n L.map_first (f=&lt;function noop&gt;, g=&lt;function noop&gt;, *args, **kwargs)\n\nFirst element of map_filter\n\nt = L(0,1,2,3)\ntest_eq(t.map_first(lambda o:o*2 if o&gt;2 else None), 6)\n\n\nsource\n\n\nL.setattrs\n\n L.setattrs (attr, val)\n\nCall setattr on all items\n\nt = L(SimpleNamespace(),SimpleNamespace())\nt.setattrs('foo', 'bar')\ntest_eq(t.attrgot('foo'), ['bar','bar'])",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#config",
    "href": "foundation.html#config",
    "title": "Foundation",
    "section": "Config",
    "text": "Config\n\nsource\n\nsave_config_file\n\n save_config_file (file, d, **kwargs)\n\nWrite settings dict to a new config file, or overwrite the existing one.\n\nsource\n\n\nread_config_file\n\n read_config_file (file, **kwargs)\n\nConfig files are saved and read using Python’s configparser.ConfigParser, inside the DEFAULT section.\n\n_d = dict(user='fastai', lib_name='fastcore', some_path='test', some_bool=True, some_num=3)\ntry:\n    save_config_file('tmp.ini', _d)\n    res = read_config_file('tmp.ini')\nfinally: os.unlink('tmp.ini')\ndict(res)\n\n{'user': 'fastai',\n 'lib_name': 'fastcore',\n 'some_path': 'test',\n 'some_bool': 'True',\n 'some_num': '3'}\n\n\n\nsource\n\n\nConfig\n\n Config (cfg_path, cfg_name, create=None, save=True, extra_files=None,\n         types=None)\n\nReading and writing ConfigParser ini files\nConfig is a convenient wrapper around ConfigParser ini files with a single section (DEFAULT).\nInstantiate a Config from an ini file at cfg_path/cfg_name:\n\nsave_config_file('../tmp.ini', _d)\ntry: cfg = Config('..', 'tmp.ini')\nfinally: os.unlink('../tmp.ini')\ncfg\n\n{'user': 'fastai', 'lib_name': 'fastcore', 'some_path': 'test', 'some_bool': 'True', 'some_num': '3'}\n\n\nYou can create a new file if one doesn’t exist by providing a create dict:\n\ntry: cfg = Config('..', 'tmp.ini', create=_d)\nfinally: os.unlink('../tmp.ini')\ncfg\n\n{'user': 'fastai', 'lib_name': 'fastcore', 'some_path': 'test', 'some_bool': 'True', 'some_num': '3'}\n\n\nIf you additionally pass save=False, the Config will contain the items from create without writing a new file:\n\ncfg = Config('..', 'tmp.ini', create=_d, save=False)\ntest_eq(cfg.user,'fastai')\nassert not Path('../tmp.ini').exists()\n\n\nsource\n\n\nConfig.get\n\n Config.get (k, default=None)\n\nKeys can be accessed as attributes, items, or with get and an optional default:\n\ntest_eq(cfg.user,'fastai')\ntest_eq(cfg['some_path'], 'test')\ntest_eq(cfg.get('foo','bar'),'bar')\n\nExtra files can be read before cfg_path/cfg_name using extra_files, in the order they appear:\n\nwith tempfile.TemporaryDirectory() as d:\n    a = Config(d, 'a.ini', {'a':0,'b':0})\n    b = Config(d, 'b.ini', {'a':1,'c':0})\n    c = Config(d, 'c.ini', {'a':2,'d':0}, extra_files=[a.config_file,b.config_file])\n    test_eq(c.d, {'a':'2','b':'0','c':'0','d':'0'})\n\nIf you pass a dict types, then the values of that dict will be used as types to instantiate all values returned. Path is a special case – in that case, the path returned will be relative to the path containing the config file (assuming the value is relative). bool types use str2bool to convert to boolean.\n\n_types = dict(some_path=Path, some_bool=bool, some_num=int)\ncfg = Config('..', 'tmp.ini', create=_d, save=False, types=_types)\n\ntest_eq(cfg.user,'fastai')\ntest_eq(cfg['some_path'].resolve(), (Path('..')/'test').resolve())\ntest_eq(cfg.get('some_num'), 3)\n\n\nsource\n\n\nConfig.find\n\n Config.find (cfg_name, cfg_path=None, **kwargs)\n\nSearch cfg_path and its parents to find cfg_name\nYou can use Config.find to search subdirectories for a config file, starting in the current path if no path is specified:\n\nConfig.find('settings.ini').repo\n\n'fastcore'",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "tour.html",
    "href": "tour.html",
    "title": "A tour of fastcore",
    "section": "",
    "text": "Here’s a (somewhat) quick tour of a few higlights from fastcore.\n\nDocumentation\nAll fast.ai projects, including this one, are built with nbdev, which is a full literate programming environment built on Jupyter Notebooks. That means that every piece of documentation, including the page you’re reading now, can be accessed as interactive Jupyter notebooks. In fact, you can even grab a link directly to a notebook running interactively on Google Colab - if you want to follow along with this tour, click the link below:\n\ncolab_link('index')\n\nOpen index in Colab\n\n\nThe full docs are available at fastcore.fast.ai. The code in the examples and in all fast.ai libraries follow the fast.ai style guide. In order to support interactive programming, all fast.ai libraries are designed to allow for import * to be used safely, particular by ensuring that __all__ is defined in all packages. In order to see where a function is from, just type it:\n\ncoll_repr\n\n&lt;function fastcore.foundation.coll_repr(c, max_n=10)&gt;\n\n\nFor more details, including a link to the full documentation and source code, use doc, which pops up a window with this information:\ndoc(coll_repr)\n\nThe documentation also contains links to any related functions or classes, which appear like this: coll_repr (in the notebook itself you will just see a word with back-ticks around it; the links are auto-generated in the documentation site). The documentation will generally show one or more examples of use, along with any background context necessary to understand them. As you’ll see, the examples for each function and method are shown as tests, rather than example outputs, so let’s start by explaining that.\n\n\nTesting\nfastcore’s testing module is designed to work well with nbdev, which is a full literate programming environment built on Jupyter Notebooks. That means that your tests, docs, and code all live together in the same notebook. fastcore and nbdev’s approach to testing starts with the premise that all your tests should pass. If one fails, no more tests in a notebook are run.\nTests look like this:\n\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0,1,2,3,4...]')\n\nThat’s an example from the docs for coll_repr. As you see, it’s not showing you the output directly. Here’s what that would look like:\n\ncoll_repr(range(1000), 5)\n\n'(#1000) [0,1,2,3,4...]'\n\n\nSo, the test is actually showing you what the output looks like, because if the function call didn’t return '(#1000) [0,1,2,3,4...]', then the test would have failed.\nSo every test shown in the docs is also showing you the behavior of the library — and vice versa!\nTest functions always start with test_, and then follow with the operation being tested. So test_eq tests for equality (as you saw in the example above). This includes tests for equality of arrays and tensors, lists and generators, and many more:\n\ntest_eq([0,1,2,3], np.arange(4))\n\nWhen a test fails, it prints out information about what was expected:\ntest_eq([0,1,2,3], np.arange(3))\n----\n  AssertionError: ==:\n  [0, 1, 2, 3]\n  [0 1 2]\nIf you want to check that objects are the same type, rather than the just contain the same collection, use test_eq_type.\nYou can test with any comparison function using test, e.g test whether an object is less than:\n\ntest(2, 3, operator.lt)\n\nYou can even test that exceptions are raised:\n\ndef divide_zero(): return 1/0\ntest_fail(divide_zero)\n\n…and test that things are printed to stdout:\n\ntest_stdout(lambda: print('hi'), 'hi')\n\n\n\nFoundations\nfast.ai is unusual in that we often use mixins in our code. Mixins are widely used in many programming languages, such as Ruby, but not so much in Python. We use mixins to attach new behavior to existing libraries, or to allow modules to add new behavior to our own classes, such as in extension modules. One useful example of a mixin we define is Path.ls, which lists a directory and returns an L (an extended list class which we’ll discuss shortly):\n\np = Path('images')\np.ls()\n\n(#6) [Path('images/mnist3.png'),Path('images/att_00000.png'),Path('images/puppy.jpg'),Path('images/att_00005.png'),Path('images/att_00007.png'),Path('images/att_00006.png')]\n\n\nYou can easily add you own mixins with the patch decorator, which takes advantage of Python 3 function annotations to say what class to patch:\n\n@patch\ndef num_items(self:Path): return len(self.ls())\n\np.num_items()\n\n6\n\n\nWe also use **kwargs frequently. In python **kwargs in a parameter like means “put any additional keyword arguments into a dict called kwargs”. Normally, using kwargs makes an API quite difficult to work with, because it breaks things like tab-completion and popup lists of signatures. utils provides use_kwargs and delegates to avoid this problem. See our detailed article on delegation on this topic.\nGetAttr solves a similar problem (and is also discussed in the article linked above): it’s allows you to use Python’s exceptionally useful __getattr__ magic method, but avoids the problem that normally in Python tab-completion and docs break when using this. For instance, you can see here that Python’s dir function, which is used to find the attributes of a python object, finds everything inside the self.default attribute here:\n\nclass Author:\n    def __init__(self, name): self.name = name\n\nclass ProductPage(GetAttr):\n    _default = 'author'\n    def __init__(self,author,price,cost): self.author,self.price,self.cost = author,price,cost\n\np = ProductPage(Author(\"Jeremy\"), 1.50, 0.50)\n[o for o in dir(p) if not o.startswith('_')]\n\n['author', 'cost', 'name', 'price']\n\n\nLooking at that ProductPage example, it’s rather verbose and duplicates a lot of attribute names, which can lead to bugs later if you change them only in one place. fastcore provides store_attr to simplify this common pattern. It also provides basic_repr to give simple objects a useful repr:\n\nclass ProductPage:\n    def __init__(self,author,price,cost): store_attr()\n    __repr__ = basic_repr('author,price,cost')\n\nProductPage(\"Jeremy\", 1.50, 0.50)\n\n__main__.ProductPage(author='Jeremy', price=1.5, cost=0.5)\n\n\nOne of the most interesting fastcore functions is the funcs_kwargs decorator. This allows class behavior to be modified without sub-classing. This can allow folks that aren’t familiar with object-oriented programming to customize your class more easily. Here’s an example of a class that uses funcs_kwargs:\n\n@funcs_kwargs\nclass T:\n    _methods=['some_method']\n    def __init__(self, **kwargs): assert not kwargs, f'Passed unknown args: {kwargs}'\n\np = T(some_method = print)\np.some_method(\"hello\")\n\nhello\n\n\nThe assert not kwargs above is used to ensure that the user doesn’t pass an unknown parameter (i.e one that’s not in _methods). fastai uses funcs_kwargs in many places, for instance, you can customize any part of a DataLoader by passing your own methods.\nfastcore also provides many utility functions that make a Python programmer’s life easier, in fastcore.utils. We won’t look at many here, since you can easily look at the docs yourself. To get you started, have a look at the docs for chunked (remember, if you’re in a notebook, type doc(chunked)), which is a handy function for creating lazily generated batches from a collection.\nPython’s ProcessPoolExecutor is extended to allow max_workers to be set to 0, to easily turn off parallel processing. This makes it easy to debug your code in serial, then run it in parallel. It also allows you to pass arguments to your parallel function, and to ensure there’s a pause between calls, in case the process you are running has race conditions. parallel makes parallel processing even easier to use, and even adds an optional progress bar.\n\n\nL\nLike most languages, Python allows for very concise syntax for some very common types, such as list, which can be constructed with [1,2,3]. Perl’s designer Larry Wall explained the reasoning for this kind of syntax:\n\nIn metaphorical honor of Huffman’s compression code that assigns smaller numbers of bits to more common bytes. In terms of syntax, it simply means that commonly used things should be shorter, but you shouldn’t waste short sequences on less common constructs.\n\nOn this basis, fastcore has just one type that has a single letter name: L. The reason for this is that it is designed to be a replacement for list, so we want it to be just as easy to use as [1,2,3]. Here’s how to create that as an L:\n\nL(1,2,3)\n\n(#3) [1,2,3]\n\n\nThe first thing to notice is that an L object includes in its representation its number of elements; that’s the (#3) in the output above. If there’s more than 10 elements, it will automatically truncate the list:\n\np = L.range(20).shuffle()\np\n\n(#20) [5,1,9,10,18,13,6,17,3,16...]\n\n\nL contains many of the same indexing ideas that NumPy’s array does, including indexing with a list of indexes, or a boolean mask list:\n\np[2,4,6]\n\n(#3) [9,18,6]\n\n\nIt also contains other methods used in array, such as L.argwhere:\n\np.argwhere(ge(15))\n\n(#5) [4,7,9,18,19]\n\n\nAs you can see from this example, fastcore also includes a number of features that make a functional style of programming easier, such as a full range of boolean functions (e.g ge, gt, etc) which give the same answer as the functions from Python’s operator module if given two parameters, but return a curried function if given one parameter.\nThere’s too much functionality to show it all here, so be sure to check the docs. Many little things are added that we thought should have been in list in the first place, such as making this do what you’d expect (which is an error with list, but works fine with L):\n\n1 + L(2,3,4)\n\n(#4) [1,2,3,4]\n\n\n\n\nTransforms\nA Transform is the main building block of the fastai data pipelines. In the most general terms a transform can be any function you want to apply to your data, however the Transform class provides several mechanisms that make the process of building them easy and flexible (see the docs for information about each of these):\n\nType dispatch\nDispatch over tuples\nReversability\nType propagation\nPreprocessing\nFiltering based on the dataset type\nOrdering\nAppending new behavior with decorators\n\nTransform looks for three special methods, encodes, decodes, and setups, which provide the implementation for __call__, decode, and setup respectively. For instance:\n\nclass A(Transform):\n    def encodes(self, x): return x+1\n\nA()(1)\n\n2\n\n\nFor simple transforms like this, you can also use Transform as a decorator:\n\n@Transform\ndef f(x): return x+1\n\nf(1)\n\n2\n\n\nTransforms can be composed into a Pipeline:\n\n@Transform\ndef g(x): return x/2\n\npipe = Pipeline([f,g])\npipe(3)\n\n2.0\n\n\nThe power of Transform and Pipeline is best understood by seeing how they’re used to create a complete data processing pipeline. This is explained in chapter 11 of the fastai book, which is available for free in Jupyter Notebook format.",
    "crumbs": [
      "A tour of fastcore"
    ]
  },
  {
    "objectID": "net.html",
    "href": "net.html",
    "title": "Network functionality",
    "section": "",
    "text": "from fastcore.test import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *",
    "crumbs": [
      "Network functionality"
    ]
  },
  {
    "objectID": "net.html#urls",
    "href": "net.html#urls",
    "title": "Network functionality",
    "section": "URLs",
    "text": "URLs\n\nsource\n\nurlquote\n\n urlquote (url)\n\nUpdate url’s path with urllib.parse.quote\n\nurlquote(\"https://github.com/fastai/fastai/compare/master@{1.day.ago}…master\")\n\n'https://github.com/fastai/fastai/compare/master@%7B1.day.ago%7D%E2%80%A6master'\n\n\n\nurlquote(\"https://www.google.com/search?q=你好\")\n\n'https://www.google.com/search?q=%E4%BD%A0%E5%A5%BD'\n\n\n\nsource\n\n\nurlwrap\n\n urlwrap (url, data=None, headers=None)\n\nWrap url in a urllib Request with urlquote\n\nsource\n\nHTTP4xxClientError\n\n HTTP4xxClientError (url, code, msg, hdrs, fp)\n\nBase class for client exceptions (code 4xx) from url* functions\n\nsource\n\n\nHTTP5xxServerError\n\n HTTP5xxServerError (url, code, msg, hdrs, fp)\n\nBase class for server exceptions (code 5xx) from url* functions\n\nsource\n\n\n\nurlopener\n\n urlopener ()\n\n\nsource\n\n\nurlopen\n\n urlopen (url, data=None, headers=None, timeout=None, **kwargs)\n\nLike urllib.request.urlopen, but first urlwrap the url, and encode data\nWith urlopen, the body of the response will also be returned in addition to the message if there is an error:\n\ntry: urlopen('https://api.github.com/v3')\nexcept HTTPError as e: \n    print(e.code, e.msg)\n    assert 'documentation_url' in e.msg\n\n404 Not Found\n====Error Body====\n{\n  \"message\": \"Not Found\",\n  \"documentation_url\": \"https://docs.github.com/rest\"\n}\n\n\n\n\nsource\n\n\nurlread\n\n urlread (url, data=None, headers=None, decode=True, return_json=False,\n          return_headers=False, timeout=None, **kwargs)\n\nRetrieve url, using data dict or kwargs to POST if present\n\nsource\n\n\nurljson\n\n urljson (url, data=None, timeout=None)\n\nRetrieve url and decode json\n\ntest_eq(urljson('https://httpbin.org/get')['headers']['User-Agent'], url_default_headers['User-Agent'])\n\n\nsource\n\n\nurlcheck\n\n urlcheck (url, headers=None, timeout=10)\n\n\nsource\n\n\nurlclean\n\n urlclean (url)\n\nRemove fragment, params, and querystring from url if present\n\ntest_eq(urlclean('http://a.com/b?c=1#d'), 'http://a.com/b')\n\n\nsource\n\n\nurlretrieve\n\n urlretrieve (url, filename=None, reporthook=None, data=None,\n              headers=None, timeout=None)\n\nSame as urllib.request.urlretrieve but also works with Request objects\n\nsource\n\n\nurldest\n\n urldest (url, dest=None)\n\n\nsource\n\n\nurlsave\n\n urlsave (url, dest=None, reporthook=None, headers=None, timeout=None)\n\nRetrieve url and save based on its name\n\n#skip\nwith tempfile.TemporaryDirectory() as d: urlsave('http://www.google.com/index.html', d)\n\n\nsource\n\n\nurlvalid\n\n urlvalid (x)\n\nTest if x is a valid URL\n\nassert urlvalid('http://www.google.com/')\nassert not urlvalid('www.google.com/')\nassert not urlvalid(1)\n\n\nsource\n\n\nurlrequest\n\n urlrequest (url, verb, headers=None, route=None, query=None, data=None,\n             json_data=True)\n\nRequest for url with optional route params replaced by route, plus query string, and post data\n\nhdr = {'Hdr1':'1', 'Hdr2':'2'}\nreq = urlrequest('http://example.com/{foo}/1', 'POST',\n                 headers=hdr, route={'foo':'3'}, query={'q':'4'}, data={'d':'5'})\n\ntest_eq(req.headers, hdr)\ntest_eq(req.full_url, 'http://example.com/3/1?q=4')\ntest_eq(req.method, 'POST')\ntest_eq(req.data, b'{\"d\": \"5\"}')\n\n\nreq = urlrequest('http://example.com/{foo}/1', 'POST', data={'d':'5','e':'6'}, headers=hdr, json_data=False)\ntest_eq(req.data, b'd=5&e=6')\n\n\nsource\n\n\nRequest.summary\n\n Request.summary (skip=None)\n\nSummary containing full_url, headers, method, and data, removing skip from headers\n\nreq.summary(skip='Hdr1')\n\n{'full_url': 'http://example.com/{foo}/1',\n 'method': 'POST',\n 'data': b'd=5&e=6',\n 'headers': {'Hdr2': '2'}}\n\n\n\nsource\n\n\nurlsend\n\n urlsend (url, verb, headers=None, decode=True, route=None, query=None,\n          data=None, json_data=True, return_json=True,\n          return_headers=False, debug=None, timeout=None)\n\nSend request with urlrequest, converting result to json if return_json\n\nsource\n\n\ndo_request\n\n do_request (url, post=False, headers=None, **data)\n\nCall GET or json-encoded POST on url, depending on post",
    "crumbs": [
      "Network functionality"
    ]
  },
  {
    "objectID": "net.html#basic-clientserver",
    "href": "net.html#basic-clientserver",
    "title": "Network functionality",
    "section": "Basic client/server",
    "text": "Basic client/server\n\nsource\n\nstart_server\n\n start_server (port, host=None, dgram=False, reuse_addr=True,\n               n_queue=None)\n\nCreate a socket server on port, with optional host, of type dgram\nYou can create a TCP client and server pass an int as port and optional host. host defaults to your main network interface if not provided. You can create a Unix socket client and server by passing a string to port. A SOCK_STREAM socket is created by default, unless you pass dgram=True, in which case a SOCK_DGRAM socket is created. n_queue sets the listening queue size.\n\nsource\n\n\nstart_client\n\n start_client (port, host=None, dgram=False)\n\nCreate a socket client on port, with optional host, of type dgram\n\nsource\n\n\ntobytes\n\n tobytes (s:str)\n\nConvert s into HTTP-ready bytes format\n\ntest_eq(tobytes('foo\\nbar'), b'foo\\r\\nbar')\n\n\nsource\n\n\nhttp_response\n\n http_response (body=None, status=200, hdrs=None, **kwargs)\n\nCreate an HTTP-ready response, adding kwargs to hdrs\n\nexp = b'HTTP/1.1 200 OK\\r\\nUser-Agent: me\\r\\nContent-Length: 4\\r\\n\\r\\nbody'\ntest_eq(http_response('body', 200, User_Agent='me'), exp)\n\n\nsource\n\n\nrecv_once\n\n recv_once (host:str='localhost', port:int=8000)\n\nSpawn a thread to receive a single HTTP request and store in d['r']",
    "crumbs": [
      "Network functionality"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to fastcore",
    "section": "",
    "text": "Python is a powerful, dynamic language. Rather than bake everything into the language, it lets the programmer customize it to make it work for them. fastcore uses this flexibility to add to Python features inspired by other languages we’ve loved, like multiple dispatch from Julia, mixins from Ruby, and currying, binding, and more from Haskell. It also adds some “missing features” and clean up some rough edges in the Python standard library, such as simplifying parallel processing, and bringing ideas from NumPy over to Python’s list type.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Welcome to fastcore",
    "section": "Getting started",
    "text": "Getting started\nTo install fastcore run: conda install fastcore -c fastai (if you use Anaconda, which we recommend) or pip install fastcore. For an editable install, clone this repo and run: pip install -e \".[dev]\". fastcore is tested to work on Ubuntu, macOS and Windows (versions tested are those shown with the -latest suffix here).\nfastcore contains many features, including:\n\nfastcore.test: Simple testing functions\nfastcore.foundation: Mixins, delegation, composition, and more\nfastcore.xtras: Utility functions to help with functional-style programming, parallel processing, and more\nfastcore.dispatch: Multiple dispatch methods\nfastcore.transform: Pipelines of composed partially reversible transformations\n\nTo get started, we recommend you read through the fastcore tour.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Welcome to fastcore",
    "section": "Contributing",
    "text": "Contributing\nAfter you clone this repository, please run nbdev_install_hooks in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.\nTo run the tests in parallel, launch nbdev_test.\nBefore submitting a PR, check that the local library and notebooks match.\n\nIf you made a change to the notebooks in one of the exported cells, you can export it to the library with nbdev_prepare.\nIf you made a change to the library, you can export it back to the notebooks with nbdev_update.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "parallel.html",
    "href": "parallel.html",
    "title": "Parallel",
    "section": "",
    "text": "from fastcore.test import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *\n\n\nsource\n\nthreaded\n\n threaded (process=False)\n\nRun f in a Thread (or Process if process=True), and returns it\n\n@threaded\ndef _1():\n    time.sleep(0.05)\n    print(\"second\")\n    return 5\n\n@threaded\ndef _2():\n    time.sleep(0.01)\n    print(\"first\")\n\na = _1()\n_2()\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\nAfter the thread is complete, the return value is stored in the result attr.\n\na.result\n\n5\n\n\n\nsource\n\n\nstartthread\n\n startthread (f)\n\nLike threaded, but start thread immediately\n\n@startthread\ndef _():\n    time.sleep(0.05)\n    print(\"second\")\n\n@startthread\ndef _():\n    time.sleep(0.01)\n    print(\"first\")\n\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\n\nsource\n\n\nstartproc\n\n startproc (f)\n\nLike threaded(True), but start Process immediately\n\n@startproc\ndef _():\n    time.sleep(0.05)\n    print(\"second\")\n\n@startproc\ndef _():\n    time.sleep(0.01)\n    print(\"first\")\n\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\n\nsource\n\n\nparallelable\n\n parallelable (param_name, num_workers, f=None)\n\n\nsource\n\nThreadPoolExecutor\n\n ThreadPoolExecutor (max_workers=4, on_exc=&lt;built-in function print&gt;,\n                     pause=0, **kwargs)\n\nSame as Python’s ThreadPoolExecutor, except can pass max_workers==0 for serial execution\n\nsource\n\n\nProcessPoolExecutor\n\n ProcessPoolExecutor (max_workers=4, on_exc=&lt;built-in function print&gt;,\n                      pause=0, mp_context=None, initializer=None,\n                      initargs=())\n\nSame as Python’s ProcessPoolExecutor, except can pass max_workers==0 for serial execution\n\nsource\n\n\n\nparallel\n\n parallel (f, items, *args, n_workers=4, total=None, progress=None,\n           pause=0, method=None, threadpool=False, timeout=None,\n           chunksize=1, **kwargs)\n\nApplies func in parallel to items, using n_workers\n\ninp,exp = range(50),range(1,51)\n\ntest_eq(parallel(_add_one, inp, n_workers=2), exp)\ntest_eq(parallel(_add_one, inp, threadpool=True, n_workers=2), exp)\ntest_eq(parallel(_add_one, inp, n_workers=1, a=2), range(2,52))\ntest_eq(parallel(_add_one, inp, n_workers=0), exp)\ntest_eq(parallel(_add_one, inp, n_workers=0, a=2), range(2,52))\n\nUse the pause parameter to ensure a pause of pause seconds between processes starting. This is in case there are race conditions in starting some process, or to stagger the time each process starts, for example when making many requests to a webserver. Set threadpool=True to use ThreadPoolExecutor instead of ProcessPoolExecutor.\n\nfrom datetime import datetime\n\n\ndef print_time(i): \n    time.sleep(random.random()/1000)\n    print(i, datetime.now())\n\nparallel(print_time, range(5), n_workers=2, pause=0.25);\n\n0 2024-10-11 23:06:05.920741\n1 2024-10-11 23:06:06.171470\n2 2024-10-11 23:06:06.431925\n3 2024-10-11 23:06:06.689940\n4 2024-10-11 23:06:06.937109\n\n\n\nsource\n\n\nparallel_async\n\n parallel_async (f, items, *args, n_workers=16, timeout=None, chunksize=1,\n                 on_exc=&lt;built-in function print&gt;, **kwargs)\n\nApplies f to items in parallel using asyncio and a semaphore to limit concurrency.\n\nimport asyncio\n\n\nasync def print_time_async(i): \n    wait = random.random()\n    await asyncio.sleep(wait)\n    print(i, datetime.now(), wait)\n\nawait parallel_async(print_time_async, range(6), n_workers=3);\n\n0 2024-10-11 23:06:39.545583 0.10292732609738675\n3 2024-10-11 23:06:39.900393 0.3516179734831676\n4 2024-10-11 23:06:39.941094 0.03699593757956876\n2 2024-10-11 23:06:39.957677 0.5148658606540902\n1 2024-10-11 23:06:40.099716 0.6574035385815227\n5 2024-10-11 23:06:40.654097 0.7116319667399102\n\n\n\nsource\n\n\nrun_procs\n\n run_procs (f, f_done, args)\n\nCall f for each item in args in parallel, yielding f_done\n\nsource\n\n\nparallel_gen\n\n parallel_gen (cls, items, n_workers=4, **kwargs)\n\nInstantiate cls in n_workers procs & call each on a subset of items in parallel.\n\n# class _C:\n#     def __call__(self, o): return ((i+1) for i in o)\n\n# items = range(5)\n\n# res = L(parallel_gen(_C, items, n_workers=0))\n# idxs,dat1 = zip(*res.sorted(itemgetter(0)))\n# test_eq(dat1, range(1,6))\n\n# res = L(parallel_gen(_C, items, n_workers=3))\n# idxs,dat2 = zip(*res.sorted(itemgetter(0)))\n# test_eq(dat2, dat1)\n\ncls is any class with __call__. It will be passed args and kwargs when initialized. Note that n_workers instances of cls are created, one in each process. items are then split in n_workers batches and one is sent to each cls. The function then returns a generator of tuples of item indices and results.\n\nclass TestSleepyBatchFunc:\n    \"For testing parallel processes that run at different speeds\"\n    def __init__(self): self.a=1\n    def __call__(self, batch):\n        for k in batch:\n            time.sleep(random.random()/4)\n            yield k+self.a\n\nx = np.linspace(0,0.99,20)\n\nres = L(parallel_gen(TestSleepyBatchFunc, x, n_workers=2))\ntest_eq(res.sorted().itemgot(1), x+1)\n\n\n\n\n\n\n\n\n\n# #|hide\n# from subprocess import Popen, PIPE\n# # test num_workers &gt; 0 in scripts works when python process start method is spawn\n# process = Popen([\"python\", \"parallel_test.py\"], stdout=PIPE)\n# _, err = process.communicate(timeout=10)\n# exit_code = process.wait()\n# test_eq(exit_code, 0)",
    "crumbs": [
      "Parallel"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "Transforms",
    "section": "",
    "text": "from __future__ import annotations\nfrom nbdev.showdoc import *\nfrom fastcore.test import *\nfrom fastcore.nb_imports import *\n\nThe classes here provide functionality for creating a composition of partially reversible functions. By “partially reversible” we mean that a transform can be decoded, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already).\nClasses are also provided and for composing transforms, and mapping them over collections. Pipeline is a transform which composes several Transform, knowing how to decode them or show an encoded item.\n\nsource\n\nTransform\n\n Transform (enc=None, dec=None, split_idx=None, order=None)\n\nDelegates (__call__,decode,setup) to (encodes,decodes,setups) if split_idx matches\nA Transform is the main building block of the fastai data pipelines. In the most general terms a transform can be any function you want to apply to your data, however the Transform class provides several mechanisms that make the process of building them easy and flexible.\n\n\nThe main Transform features:\n\nType dispatch - Type annotations are used to determine if a transform should be applied to the given argument. It also gives an option to provide several implementations and it choses the one to run based on the type. This is useful for example when running both independent and dependent variables through the pipeline where some transforms only make sense for one and not the other. Another usecase is designing a transform that handles different data formats. Note that if a transform takes multiple arguments only the type of the first one is used for dispatch.\nHandling of tuples - When a tuple (or a subclass of tuple) of data is passed to a transform it will get applied to each element separately. You can opt out of this behavior by passing a list or an L, as only tuples gets this specific behavior. An alternative is to use ItemTransform defined below, which will always take the input as a whole.\nReversability - A transform can be made reversible by implementing the decodes method. This is mainly used to turn something like a category which is encoded as a number back into a label understandable by humans for showing purposes. Like the regular call method, the decode method that is used to decode will be applied over each element of a tuple separately.\nType propagation - Whenever possible a transform tries to return data of the same type it received. Mainly used to maintain semantics of things like ArrayImage which is a thin wrapper of pytorch’s Tensor. You can opt out of this behavior by adding -&gt;None return type annotation.\nPreprocessing - The setup method can be used to perform any one-time calculations to be later used by the transform, for example generating a vocabulary to encode categorical data.\nFiltering based on the dataset type - By setting the split_idx flag you can make the transform be used only in a specific DataSource subset like in training, but not validation.\nOrdering - You can set the order attribute which the Pipeline uses when it needs to merge two lists of transforms.\nAppending new behavior with decorators - You can easily extend an existing Transform by creating encodes or decodes methods for new data types. You can put those new methods outside the original transform definition and decorate them with the class you wish them patched into. This can be used by the fastai library users to add their own behavior, or multiple modules contributing to the same transform.\n\n\n\nDefining a Transform\nThere are a few ways to create a transform with different ratios of simplicity to flexibility. - Extending the Transform class - Use inheritence to implement the methods you want. - Passing methods to the constructor - Instantiate the Transform class and pass your functions as enc and dec arguments. - @Transform decorator - Turn any function into a Transform by just adding a decorator - very straightforward if all you need is a single encodes implementation. - Passing a function to fastai APIs - Same as above, but when passing a function to other transform aware classes like Pipeline or TfmdDS you don’t even need a decorator. Your function will get converted to a Transform automatically.\nA simple way to create a Transform is to pass a function to the constructor. In the below example, we pass an anonymous function that does integer division by 2:\n\nf = Transform(lambda o:o//2)\n\nIf you call this transform, it will apply the transformation:\n\ntest_eq_type(f(2), 1)\n\nAnother way to define a Transform is to extend the Transform class:\n\nclass A(Transform): pass\n\nHowever, to enable your transform to do something, you have to define an encodes method. Note that we can use the class name as a decorator to add this method to the original class.\n\n@A\ndef encodes(self, x): return x+1\n\nf1 = A()\ntest_eq(f1(1), 2) # f1(1) is the same as f1.encode(1)\n\nIn addition to adding an encodes method, we can also add a decodes method. This enables you to call the decode method (without an s). For more information about the purpose of decodes, see the discussion about Reversibility in the above section.\nJust like with encodes, you can add a decodes method to the original class by using the class name as a decorator:\n\nclass B(A): pass\n\n@B\ndef decodes(self, x): return x-1\n\nf2 = B()\ntest_eq(f2.decode(2), 1)\n\ntest_eq(f2(1), 2) # uses A's encode method from the parent class\n\nIf you do not define an encodes or decodes method the original value will be returned:\n\nclass _Tst(Transform): pass \n\nf3 = _Tst() # no encodes or decodes method have been defined\ntest_eq_type(f3.decode(2.0), 2.0)\ntest_eq_type(f3(2), 2)\n\nTransforms can be created from class methods too:\n\nclass A:\n    @classmethod\n    def create(cls, x:int): return x+1\ntest_eq(Transform(A.create)(1), 2)\n\n\nDefining Transforms With A Decorator\nTransform can be used as a decorator to turn a function into a Transform.\n\n@Transform\ndef f(x): return x//2\ntest_eq_type(f(2), 1)\ntest_eq_type(f.decode(2.0), 2.0)\n\n@Transform\ndef f(x): return x*2\ntest_eq_type(f(2), 4)\ntest_eq_type(f.decode(2.0), 2.0)\n\n\n\nTyped Dispatch and Transforms\nWe can also apply different transformations depending on the type of the input passed by using TypedDispatch. TypedDispatch automatically works with Transform when using type hints:\n\nclass A(Transform): pass\n\n@A\ndef encodes(self, x:int): return x//2\n\n@A\ndef encodes(self, x:float): return x+1\n\nWhen we pass in an int, this calls the first encodes method:\n\nf = A()\ntest_eq_type(f(3), 1)\n\nWhen we pass in a float, this calls the second encodes method:\n\ntest_eq_type(f(2.), 3.)\n\nWhen we pass in a type that is not specified in encodes, the original value is returned:\n\ntest_eq(f('a'), 'a')\n\nIf the type annotation is a tuple, then any type in the tuple will match:\n\nclass MyClass(int): pass\n\nclass A(Transform):\n    def encodes(self, x:MyClass|float): return x/2\n    def encodes(self, x:str|list): return str(x)+'_1'\n\nf = A()\n\nThe below two examples match the first encodes, with a type of MyClass and float, respectively:\n\ntest_eq(f(MyClass(2)), 1.) # input is of type MyClass \ntest_eq(f(6.0), 3.0) # input is of type float\n\nThe next two examples match the second encodes method, with a type of str and list, respectively:\n\ntest_eq(f('a'), 'a_1') # input is of type str\ntest_eq(f(['a','b','c']), \"['a', 'b', 'c']_1\") # input is of type list\n\n\n\nCasting Types With Transform\nWithout any intervention it is easy for operations to change types in Python. For example, FloatSubclass (defined below) becomes a float after performing multiplication:\n\nclass FloatSubclass(float): pass\ntest_eq_type(FloatSubclass(3.0) * 2, 6.0)\n\nThis behavior is often not desirable when performing transformations on data. Therefore, Transform will attempt to cast the output to be of the same type as the input by default. In the below example, the output will be cast to a FloatSubclass type to match the type of the input:\n\n@Transform\ndef f(x): return x*2\n\ntest_eq_type(f(FloatSubclass(3.0)), FloatSubclass(6.0))\n\nWe can optionally turn off casting by annotating the transform function with a return type of None:\n\n@Transform\ndef f(x)-&gt; None: return x*2 # Same transform as above, but with a -&gt; None annotation\n\ntest_eq_type(f(FloatSubclass(3.0)), 6.0)  # Casting is turned off because of -&gt; None annotation\n\nHowever, Transform will only cast output back to the input type when the input is a subclass of the output. In the below example, the input is of type FloatSubclass which is not a subclass of the output which is of type str. Therefore, the output doesn’t get cast back to FloatSubclass and stays as type str:\n\n@Transform\ndef f(x): return str(x)\n    \ntest_eq_type(f(Float(2.)), '2.0')\n\nJust like encodes, the decodes method will cast outputs to match the input type in the same way. In the below example, the output of decodes remains of type MySubclass:\n\nclass MySubclass(int): pass\n\ndef enc(x): return MySubclass(x+1)\ndef dec(x): return x-1\n\n\nf = Transform(enc,dec)\nt = f(1) # t is of type MySubclass\ntest_eq_type(f.decode(t), MySubclass(1)) # the output of decode is cast to MySubclass to match the input type.\n\n\n\nApply Transforms On Subsets With split_idx\nYou can apply transformations to subsets of data by specifying a split_idx property. If a transform has a split_idx then it’s only applied if the split_idx param matches. In the below example, we set split_idx equal to 1:\n\ndef enc(x): return x+1\ndef dec(x): return x-1\nf = Transform(enc,dec)\nf.split_idx = 1\n\nThe transformations are applied when a matching split_idx parameter is passed:\n\ntest_eq(f(1, split_idx=1),2)\ntest_eq(f.decode(2, split_idx=1),1)\n\nOn the other hand, transformations are ignored when the split_idx parameter does not match:\n\ntest_eq(f(1, split_idx=0), 1)\ntest_eq(f.decode(2, split_idx=0), 2)\n\n\n\nTransforms on Lists\nTransform operates on lists as a whole, not element-wise:\n\nclass A(Transform):\n    def encodes(self, x): return dict(x)\n    def decodes(self, x): return list(x.items())\n    \nf = A()\n_inp = [(1,2), (3,4)]\nt = f(_inp)\n\ntest_eq(t, dict(_inp))\ntest_eq(f.decodes(t), _inp)\n\nIf you want a transform to operate on a list elementwise, you must implement this appropriately in the encodes and decodes methods:\n\nclass AL(Transform): pass\n\n@AL\ndef encodes(self, x): return [x_+1 for x_ in x]\n\n@AL\ndef decodes(self, x): return [x_-1 for x_ in x]\n\nf = AL()\nt = f([1,2])\n\ntest_eq(t, [2,3])\ntest_eq(f.decode(t), [1,2])\n\n\n\nTransforms on Tuples\nUnlike lists, Transform operates on tuples element-wise.\n\ndef neg_int(x): return -x\nf = Transform(neg_int)\n\ntest_eq(f((1,2,3)), (-1,-2,-3))\n\nTransforms will also apply TypedDispatch element-wise on tuples when an input type annotation is specified. In the below example, the values 1.0 and 3.0 are ignored because they are of type float, not int:\n\ndef neg_int(x:int): return -x\nf = Transform(neg_int)\n\ntest_eq(f((1.0, 2, 3.0)), (1.0, -2, 3.0))\n\nAnother example of how Transform can use TypedDispatch with tuples is shown below:\n\nclass B(Transform): pass\n\n@B\ndef encodes(self, x:int): return x+1\n\n@B\ndef encodes(self, x:str): return x+'hello'\n\n@B\ndef encodes(self, x): return str(x)+'!'\n\nIf the input is not an int or str, the third encodes method will apply:\n\nb = B()\ntest_eq(b([1]), '[1]!') \ntest_eq(b([1.0]), '[1.0]!')\n\nHowever, if the input is a tuple, then the appropriate method will apply according to the type of each element in the tuple:\n\ntest_eq(b(('1',)), ('1hello',))\ntest_eq(b((1,2)), (2,3))\ntest_eq(b(('a',1.0)), ('ahello','1.0!'))\n\nDispatching over tuples works recursively, by the way:\n\nclass B(Transform):\n    def encodes(self, x:int): return x+1\n    def encodes(self, x:str): return x+'_hello'\n    def decodes(self, x:int): return x-1\n    def decodes(self, x:str): return x.replace('_hello', '')\n\nf = B()\nstart = (1.,(2,'3'))\nt = f(start)\ntest_eq_type(t, (1.,(3,'3_hello')))\ntest_eq(f.decode(t), start)\n\nDispatching also works with typing module type classes, like numbers.integral:\n\n@Transform\ndef f(x:numbers.Integral): return x+1\n\nt = f((1,'1',1))\ntest_eq(t, (2, '1', 2))\n\n\nsource\n\n\n\nInplaceTransform\n\n InplaceTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA Transform that modifies in-place and just returns whatever it’s passed\n\nclass A(InplaceTransform): pass\n\n@A\ndef encodes(self, x:pd.Series): x.fillna(10, inplace=True)\n    \nf = A()\n\ntest_eq_type(f(pd.Series([1,2,None])),pd.Series([1,2,10],dtype=np.float64)) #fillna fills with floats.\n\n\nsource\n\n\nDisplayedTransform\n\n DisplayedTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA transform with a __repr__ that shows its attrs\nTransforms normally are represented by just their class name and a list of encodes and decodes implementations:\n\nclass A(Transform): encodes,decodes = noop,noop\nf = A()\nf\n\nA:\nencodes: (object,object) -&gt; noop\ndecodes: (object,object) -&gt; noop\n\n\nA DisplayedTransform will in addition show the contents of all attributes listed in the comma-delimited string self.store_attrs:\n\nclass A(DisplayedTransform):\n    encodes = noop\n    def __init__(self, a, b=2):\n        super().__init__()\n        store_attr()\n    \nA(a=1,b=2)\n\nA -- {'a': 1, 'b': 2}:\nencodes: (object,object) -&gt; noop\ndecodes: \n\n\n\nsource\n\n\nItemTransform\n\n ItemTransform (enc=None, dec=None, split_idx=None, order=None)\n\nA transform that always take tuples as items\nItemTransform is the class to use to opt out of the default behavior of Transform.\n\nclass AIT(ItemTransform): \n    def encodes(self, xy): x,y=xy; return (x+y,y)\n    def decodes(self, xy): x,y=xy; return (x-y,y)\n    \nf = AIT()\ntest_eq(f((1,2)), (3,2))\ntest_eq(f.decode((3,2)), (1,2))\n\nIf you pass a special tuple subclass, the usual retain type behavior of Transform will keep it:\n\nclass _T(tuple): pass\nx = _T((1,2))\ntest_eq_type(f(x), _T((3,2)))\n\n\nsource\n\n\nget_func\n\n get_func (t, name, *args, **kwargs)\n\nGet the t.name (potentially partial-ized with args and kwargs) or noop if not defined\nThis works for any kind of t supporting getattr, so a class or a module.\n\ntest_eq(get_func(operator, 'neg', 2)(), -2)\ntest_eq(get_func(operator.neg, '__call__')(2), -2)\ntest_eq(get_func(list, 'foobar')([2]), [2])\na = [2,1]\nget_func(list, 'sort')(a)\ntest_eq(a, [1,2])\n\nTransforms are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the TypeDispatch module and type-annotation in Transform, but you can also use the following class.\n\nsource\n\n\nFunc\n\n Func (name, *args, **kwargs)\n\nBasic wrapper around a name with args and kwargs to call on a given type\nYou can call the Func object on any module name or type, even a list of types. It will return the corresponding function (with a default to noop if nothing is found) or list of functions.\n\ntest_eq(Func('sqrt')(math), math.sqrt)\n\n\n\n\nSig\n\n Sig (*args, **kwargs)\n\nSig is just sugar-syntax to create a Func object more easily with the syntax Sig.name(*args, **kwargs).\n\nf = Sig.sqrt()\ntest_eq(f(math), math.sqrt)\n\n\nsource\n\n\ncompose_tfms\n\n compose_tfms (x, tfms, is_enc=True, reverse=False, **kwargs)\n\nApply all func_nm attribute of tfms on x, maybe in reverse order\n\ndef to_int  (x):   return Int(x)\ndef to_float(x):   return Float(x)\ndef double  (x):   return x*2\ndef half(x)-&gt;None: return x/2\n\n\ndef test_compose(a, b, *fs): test_eq_type(compose_tfms(a, tfms=map(Transform,fs)), b)\n\ntest_compose(1,   Int(1),   to_int)\ntest_compose(1,   Float(1), to_int,to_float)\ntest_compose(1,   Float(2), to_int,to_float,double)\ntest_compose(2.0, 2.0,      to_int,double,half)\n\n\nclass A(Transform):\n    def encodes(self, x:float):  return Float(x+1)\n    def decodes(self, x): return x-1\n    \ntfms = [A(), Transform(math.sqrt)]\nt = compose_tfms(3., tfms=tfms)\ntest_eq_type(t, Float(2.))\ntest_eq(compose_tfms(t, tfms=tfms, is_enc=False), 1.)\ntest_eq(compose_tfms(4., tfms=tfms, reverse=True), 3.)\n\n\ntfms = [A(), Transform(math.sqrt)]\ntest_eq(compose_tfms((9,3.), tfms=tfms), (3,2.))\n\n\nsource\n\n\nmk_transform\n\n mk_transform (f)\n\nConvert function f to Transform if it isn’t already one\n\nsource\n\n\ngather_attrs\n\n gather_attrs (o, k, nm)\n\nUsed in getattr to collect all attrs k from self.{nm}\n\nsource\n\n\ngather_attr_names\n\n gather_attr_names (o, nm)\n\nUsed in dir to collect all attrs k from self.{nm}\n\nsource\n\n\nPipeline\n\n Pipeline (funcs=None, split_idx=None)\n\nA pipeline of composed (for encode/decode) transforms, setup with types\n\nadd_docs(Pipeline,\n         __call__=\"Compose `__call__` of all `fs` on `o`\",\n         decode=\"Compose `decode` of all `fs` on `o`\",\n         show=\"Show `o`, a single item from a tuple, decoding as needed\",\n         add=\"Add transforms `ts`\",\n         setup=\"Call each tfm's `setup` in order\")\n\nPipeline is a wrapper for compose_tfms. You can pass instances of Transform or regular functions in funcs, the Pipeline will wrap them all in Transform (and instantiate them if needed) during the initialization. It handles the transform setup by adding them one at a time and calling setup on each, goes through them in order in __call__ or decode and can show an object by applying decoding the transforms up until the point it gets an object that knows how to show itself.\n\n# Empty pipeline is noop\npipe = Pipeline()\ntest_eq(pipe(1), 1)\ntest_eq(pipe((1,)), (1,))\n# Check pickle works\nassert pickle.loads(pickle.dumps(pipe))\n\n\nclass IntFloatTfm(Transform):\n    def encodes(self, x):  return Int(x)\n    def decodes(self, x):  return Float(x)\n    foo=1\n\nint_tfm=IntFloatTfm()\n\ndef neg(x): return -x\nneg_tfm = Transform(neg, neg)\n\n\npipe = Pipeline([neg_tfm, int_tfm])\n\nstart = 2.0\nt = pipe(start)\ntest_eq_type(t, Int(-2))\ntest_eq_type(pipe.decode(t), Float(start))\ntest_stdout(lambda:pipe.show(t), '-2')\n\n\npipe = Pipeline([neg_tfm, int_tfm])\nt = pipe(start)\ntest_stdout(lambda:pipe.show(pipe((1.,2.))), '-1\\n-2')\ntest_eq(pipe.foo, 1)\nassert 'foo' in dir(pipe)\nassert 'int_float_tfm' in dir(pipe)\n\nYou can add a single transform or multiple transforms ts using Pipeline.add. Transforms will be ordered by Transform.order.\n\npipe = Pipeline([neg_tfm, int_tfm])\nclass SqrtTfm(Transform):\n    order=-1\n    def encodes(self, x): \n        return x**(.5)\n    def decodes(self, x): return x**2\npipe.add(SqrtTfm())\ntest_eq(pipe(4),-2)\ntest_eq(pipe.decode(-2),4)\npipe.add([SqrtTfm(),SqrtTfm()])\ntest_eq(pipe(256),-2)\ntest_eq(pipe.decode(-2),256)\n\nTransforms are available as attributes named with the snake_case version of the names of their types. Attributes in transforms can be directly accessed as attributes of the pipeline.\n\ntest_eq(pipe.int_float_tfm, int_tfm)\ntest_eq(pipe.foo, 1)\n\npipe = Pipeline([int_tfm, int_tfm])\npipe.int_float_tfm\ntest_eq(pipe.int_float_tfm[0], int_tfm)\ntest_eq(pipe.foo, [1,1])\n\n\n# Check opposite order\npipe = Pipeline([int_tfm,neg_tfm])\nt = pipe(start)\ntest_eq(t, -2)\ntest_stdout(lambda:pipe.show(t), '-2')\n\n\nclass A(Transform):\n    def encodes(self, x):  return int(x)\n    def decodes(self, x):  return Float(x)\n\npipe = Pipeline([neg_tfm, A])\nt = pipe(start)\ntest_eq_type(t, -2)\ntest_eq_type(pipe.decode(t), Float(start))\ntest_stdout(lambda:pipe.show(t), '-2.0')\n\n\ns2 = (1,2)\npipe = Pipeline([neg_tfm, A])\nt = pipe(s2)\ntest_eq_type(t, (-1,-2))\ntest_eq_type(pipe.decode(t), (Float(1.),Float(2.)))\ntest_stdout(lambda:pipe.show(t), '-1.0\\n-2.0')\n\n\nfrom PIL import Image\n\n\nclass ArrayImage(ndarray):\n    _show_args = {'cmap':'viridis'}\n    def __new__(cls, x, *args, **kwargs):\n        if isinstance(x,tuple): super().__new__(cls, x, *args, **kwargs)\n        if args or kwargs: raise RuntimeError('Unknown array init args')\n        if not isinstance(x,ndarray): x = array(x)\n        return x.view(cls)\n    \n    def show(self, ctx=None, figsize=None, **kwargs):\n        if ctx is None: _,ctx = plt.subplots(figsize=figsize)\n        ctx.imshow(im, **{**self._show_args, **kwargs})\n        ctx.axis('off')\n        return ctx\n    \nim = Image.open(TEST_IMAGE)\nim_t = ArrayImage(im)\n\n\ndef f1(x:ArrayImage): return -x\ndef f2(x): return Image.open(x).resize((128,128))\ndef f3(x:Image.Image): return(ArrayImage(array(x)))\n\n\npipe = Pipeline([f2,f3,f1])\nt = pipe(TEST_IMAGE)\ntest_eq(type(t), ArrayImage)\ntest_eq(t, -array(f3(f2(TEST_IMAGE))))\n\n\npipe = Pipeline([f2,f3])\nt = pipe(TEST_IMAGE)\nax = pipe.show(t)\n\n\n\n\n\n\n\n\n\n#test_fig_exists(ax)\n\n\n#Check filtering is properly applied\nadd1 = B()\nadd1.split_idx = 1\npipe = Pipeline([neg_tfm, A(), add1])\ntest_eq(pipe(start), -2)\npipe.split_idx=1\ntest_eq(pipe(start), -1)\npipe.split_idx=0\ntest_eq(pipe(start), -2)\nfor t in [None, 0, 1]:\n    pipe.split_idx=t\n    test_eq(pipe.decode(pipe(start)), start)\n    test_stdout(lambda: pipe.show(pipe(start)), \"-2.0\")\n\n\ndef neg(x): return -x\ntest_eq(type(mk_transform(neg)), Transform)\ntest_eq(type(mk_transform(math.sqrt)), Transform)\ntest_eq(type(mk_transform(lambda a:a*2)), Transform)\ntest_eq(type(mk_transform(Pipeline([neg]))), Pipeline)\n\n\n\nMethods\n\n#TODO: method examples\n\n\nsource\n\n\nPipeline.__call__\n\n Pipeline.__call__ (o)\n\nCall self as a function.\n\nsource\n\n\nPipeline.decode\n\n Pipeline.decode (o, full=True)\n\n\nsource\n\n\nPipeline.setup\n\n Pipeline.setup (items=None, train_setup=False)\n\nDuring the setup, the Pipeline starts with no transform and adds them one at a time, so that during its setup, each transform gets the items processed up to its point and not after.",
    "crumbs": [
      "Transforms"
    ]
  },
  {
    "objectID": "xml.html",
    "href": "xml.html",
    "title": "XML",
    "section": "",
    "text": "from IPython.display import Markdown\nfrom pprint import pprint\n\nfrom fastcore.test import test_eq",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#ft-functions",
    "href": "xml.html#ft-functions",
    "title": "XML",
    "section": "FT functions",
    "text": "FT functions\n\nsource\n\nattrmap\n\n attrmap (o)\n\n\nsource\n\n\nvalmap\n\n valmap (o)\n\n\nsource\n\n\nFT\n\n FT (tag:str, cs:tuple, attrs:dict=None, void_=False, **kwargs)\n\nA ‘Fast Tag’ structure, containing tag,children,and attrs\n\nsource\n\n\nft\n\n ft (tag:str, *c, void_:bool=False, attrmap:&lt;built-\n     infunctioncallable&gt;=&lt;function attrmap&gt;, valmap:&lt;built-\n     infunctioncallable&gt;=&lt;function valmap&gt;, ft_cls=&lt;class '__main__.FT'&gt;,\n     **kw)\n\nCreate an FT structure for to_xml()\nThe main HTML tags are exported as ft partials.\nAttributes are passed as keywords. Use ‘klass’ and ‘fr’ instead of ‘class’ and ‘for’, to avoid Python reserved word clashes.\n\nsource\n\n\nHtml\n\n Html (*c, doctype=True, **kwargs)\n\nAn HTML tag, optionally preceeded by !DOCTYPE HTML\n\nsamp = Html(\n    Head(Title('Some page')),\n    Body(Div('Some text\\nanother line', (Input(name=\"jph's\"), Img(src=\"filename\", data=1)),\n             cls=['myclass', 'another'],\n             style={'padding':1, 'margin':2}))\n)\npprint(samp)\n\n(!doctype((),{'html': True}),\n html((head((title(('Some page',),{}),),{}), body((div(('Some text\\nanother line', input((),{'name': \"jph's\"}), img((),{'src': 'filename', 'data': 1})),{'class': 'myclass another', 'style': 'padding:1; margin:2'}),),{})),{}))\n\n\n\nelem = P('Some text', id=\"myid\")\nprint(elem.tag)\nprint(elem.children)\nprint(elem.attrs)\n\np\n('Some text',)\n{'id': 'myid'}\n\n\nYou can get and set attrs directly:\n\nelem.id = 'newid'\nprint(elem.id, elem.get('id'), elem.get('foo', 'missing'))\nelem\n\nnewid newid missing\n\n\np(('Some text',),{'id': 'newid'})\n\n\n\nsource\n\n\nSafe\n*str(object=’’) -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str\nCreate a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to ‘strict’.*",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#conversion-to-xmlhtml",
    "href": "xml.html#conversion-to-xmlhtml",
    "title": "XML",
    "section": "Conversion to XML/HTML",
    "text": "Conversion to XML/HTML\n\nsource\n\nto_xml\n\n to_xml (elm, lvl=0, indent=True, do_escape=True)\n\nConvert ft element tree into an XML string\n\nh = to_xml(samp, do_escape=False)\nprint(h)\n\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Some page&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div class=\"myclass another\" style=\"padding:1; margin:2\"&gt;\nSome text\nanother line      &lt;input name=\"jph's\"&gt;\n&lt;img src=\"filename\" data=\"1\"&gt;    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\nclass PageTitle:\n    def __ft__(self): return H1(\"Hello\")\n\nclass HomePage:\n    def __ft__(self): return Div(PageTitle(), Div('hello'))\n\nh = to_xml(Div(HomePage()))\nexpected_output = \"\"\"&lt;div&gt;\n  &lt;div&gt;\n    &lt;h1&gt;Hello&lt;/h1&gt;\n    &lt;div&gt;hello&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\"\"\"\nassert h == expected_output\n\n\nprint(h)\n\n&lt;div&gt;\n  &lt;div&gt;\n    &lt;h1&gt;Hello&lt;/h1&gt;\n    &lt;div&gt;hello&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n\n\n\nh = to_xml(samp, indent=False)\nprint(h)\n\n&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Some page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"myclass another\" style=\"padding:1; margin:2\"&gt;Some text\nanother line&lt;input name=\"jph's\"&gt;&lt;img src=\"filename\" data=\"1\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\nInteroperability both directions with Django and Jinja using the html() protocol:\n\ndef _esc(s): return s.__html__() if hasattr(s, '__html__') else Safe(escape(s))\n\nr = Safe('&lt;b&gt;Hello from Django&lt;/b&gt;')\nprint(to_xml(Div(r)))\nprint(_esc(Div(P('Hello from fastcore &lt;3'))))\n\n&lt;div&gt;&lt;b&gt;Hello from Django&lt;/b&gt;&lt;/div&gt;\n\n&lt;div&gt;\n  &lt;p&gt;Hello from fastcore &lt;3&lt;/p&gt;\n&lt;/div&gt;",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#display",
    "href": "xml.html#display",
    "title": "XML",
    "section": "Display",
    "text": "Display\n\nsource\n\nhighlight\n\n highlight (s, lang='html')\n\nMarkdown to syntax-highlight s in language lang\n\nsource\n\n\nshowtags\n\n showtags (s)\n\nYou can also reorder the children to come after the attrs, if you use this alternative syntax for FT where the children are in a second pair of () (behind the scenes this is because FT implements __call__ to add children).\n\nBody(klass='myclass')(\n    Div(style='padding:3px')(\n        'Some text 1&lt;2',\n        I(spurious=True)('in italics'),\n        Input(name='me'),\n        Img(src=\"filename\", data=1)\n    )\n)\n\n&lt;body class=\"myclass\"&gt;\n  &lt;div style=\"padding:3px\"&gt;\nSome text 1&lt;2&lt;i spurious&gt;in italics&lt;/i&gt;    &lt;input name=\"me\"&gt;\n&lt;img src=\"filename\" data=\"1\"&gt;  &lt;/div&gt;\n&lt;/body&gt;\n\n\n\nsource\n\n\ngetattr\n\n __getattr__ (tag)",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "meta.html",
    "href": "meta.html",
    "title": "Meta",
    "section": "",
    "text": "from fastcore.foundation import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *\nSee this blog post for more information about metaclasses.\nsource",
    "crumbs": [
      "Meta"
    ]
  },
  {
    "objectID": "meta.html#metaprogramming",
    "href": "meta.html#metaprogramming",
    "title": "Meta",
    "section": "Metaprogramming",
    "text": "Metaprogramming\n\nsource\n\nempty2none\n\n empty2none (p)\n\nReplace Parameter.empty with None\n\nsource\n\n\nanno_dict\n\n anno_dict (f)\n\n__annotation__ dictionary withemptycast toNone`, returning empty if doesn’t exist\n\ndef _f(a:int, b:L)-&gt;str: ...\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n\n\nsource\n\n\nuse_kwargs_dict\n\n use_kwargs_dict (keep=False, **kwargs)\n\nDecorator: replace **kwargs in signature with names params\nReplace all **kwargs with named arguments like so:\n\n@use_kwargs_dict(y=1,z=None)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None)')\n\nAdd named arguments, but optionally keep **kwargs by setting keep=True:\n\n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n\n\nsource\n\n\nuse_kwargs\n\n use_kwargs (names, keep=False)\n\nDecorator: replace **kwargs in signature with names params\nuse_kwargs is different than use_kwargs_dict as it only replaces **kwargs with named parameters without any default values:\n\n@use_kwargs(['y', 'z'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=None, z=None)')\n\nYou may optionally keep the **kwargs argument in your signature by setting keep=True:\n\n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n\n\nsource\n\n\ndelegates\n\n delegates (to:function=None, keep=False, but:list=None)\n\nDecorator: replace **kwargs in signature with params from to\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nto\nfunction\nNone\nDelegatee\n\n\nkeep\nbool\nFalse\nKeep kwargs in decorated function?\n\n\nbut\nlist\nNone\nExclude these parameters from signature\n\n\n\nA common Python idiom is to accept **kwargs in addition to named parameters that are passed onto other function calls. It is especially common to use **kwargs when you want to give the user an option to override default parameters of any functions or methods being called by the parent function.\nFor example, suppose we have have a function foo that passes arguments to baz like so:\n\ndef baz(a, b:int=2, c:int=3): return a + b + c\n\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\nassert foo(c=1, a=1) == 7\n\nThe problem with this approach is the api for foo is obfuscated. Users cannot introspect what the valid arguments for **kwargs are without reading the source code. When a user tries tries to introspect the signature of foo, they are presented with this:\n\ninspect.signature(foo)\n\n&lt;Signature (c, a, **kwargs)&gt;\n\n\nWe can address this issue by using the decorator delegates to include parameters from other functions. For example, if we apply the delegates decorator to foo to include parameters from baz:\n\n@delegates(baz)\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\ntest_sig(foo, '(c, a, *, b: int = 2)')\ninspect.signature(foo)\n\n&lt;Signature (c, a, *, b: int = 2)&gt;\n\n\nWe can optionally decide to keep **kwargs by setting keep=True:\n\n@delegates(baz, keep=True)\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\ninspect.signature(foo)\n\n&lt;Signature (c, a, *, b: int = 2, **kwargs)&gt;\n\n\nIt is important to note that only parameters with default parameters are included. For example, in the below scenario only c, but NOT e and d are included in the signature of foo after applying delegates:\n\ndef basefoo(e, d, c=2): pass\n\n@delegates(basefoo)\ndef foo(a, b=1, **kwargs): pass\ninspect.signature(foo) # e and d are not included b/c they don't have default parameters.\n\n&lt;Signature (a, b=1, *, c=2)&gt;\n\n\nThe reason that required arguments (i.e. those without default parameters) are automatically excluded is that you should be explicitly implementing required arguments into your function’s signature rather than relying on delegates.\nAdditionally, you can exclude specific parameters from being included in the signature with the but parameter. In the example below, we exclude the parameter d:\n\ndef basefoo(e, c=2, d=3): pass\n\n@delegates(basefoo, but= ['d'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, c=2)')\ninspect.signature(foo)\n\n&lt;Signature (a, b=1, *, c=2)&gt;\n\n\nYou can also use delegates between methods in a class. Here is an example of delegates with class methods:\n\n# example 1: class methods\nclass _T():\n    @classmethod\n    def foo(cls, a=1, b=2):\n        pass\n    \n    @classmethod\n    @delegates(foo)\n    def bar(cls, c=3, **kwargs):\n        pass\n\ntest_sig(_T.bar, '(c=3, *, a=1, b=2)')\n\nHere is the same example with instance methods:\n\n# example 2: instance methods\nclass _T():\n    def foo(self, a=1, b=2):\n        pass\n    \n    @delegates(foo)\n    def bar(self, c=3, **kwargs):\n        pass\n\nt = _T()\ntest_sig(t.bar, '(c=3, *, a=1, b=2)')\n\nYou can also delegate between classes. By default, the delegates decorator will delegate to the superclass:\n\nclass BaseFoo:\n    def __init__(self, e, c=2): pass\n\n@delegates()# since no argument was passsed here we delegate to the superclass\nclass Foo(BaseFoo):\n    def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs)\n\ntest_sig(Foo, '(a, b=1, *, c=2)')\n\n\nsource\n\n\nmethod\n\n method (f)\n\nMark f as a method\nThe method function is used to change a function’s type to a method. In the below example we change the type of a from a function to a method:\n\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function'\n\na = method(a)\nassert type(a).__name__ == 'method'\n\n\nsource\n\n\nfuncs_kwargs\n\n funcs_kwargs (as_method=False)\n\nReplace methods in cls._methods with those from kwargs\nThe func_kwargs decorator allows you to add a list of functions or methods to an existing class. You must set this list as a class attribute named _methods when defining your class. Additionally, you must incldue the **kwargs argument in the ___init__ method of your class.\nAfter defining your class this way, you can add functions to your class upon instantation as illusrated below.\nFor example, we define class T to allow adding the function b to class T as follows (note that this function is stored as an attribute of T and doesn’t have access to cls or self):\n\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\nBecause we defined the class T this way, the signature of T indicates the option to add the function or method(s) specified in _methods. In this example, b is added to the signature:\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\n&lt;Signature (f=1, *, b=None)&gt;\n\n\nYou can now add the function b to class T upon instantiation:\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nIf you try to add a function with a name not listed in _methods it will be ignored. In the below example, the attempt to add a function named a is ignored:\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\nNote that you can also add methods not defined in the original class as long it is specified in the _methods attribute:\n\n@funcs_kwargs\nclass T:\n    _methods=['c']\n    def __init__(self, f=1, **kwargs): pass\n\nt = T(c = lambda: 4)\ntest_eq(t.c(), 4)\n\nUntil now, these examples showed how to add functions stored as an instance attribute without access to self. However, if you need access to self you can set as_method=True in the func_kwargs decorator to add a method instead:\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\nHere is an example of how you might use this functionality with inheritence:\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')",
    "crumbs": [
      "Meta"
    ]
  },
  {
    "objectID": "dispatch.html",
    "href": "dispatch.html",
    "title": "Type dispatch",
    "section": "",
    "text": "from nbdev.showdoc import *\nfrom fastcore.test import *\nfrom fastcore.nb_imports import *",
    "crumbs": [
      "Type dispatch"
    ]
  },
  {
    "objectID": "dispatch.html#helpers",
    "href": "dispatch.html#helpers",
    "title": "Type dispatch",
    "section": "Helpers",
    "text": "Helpers\n\nsource\n\nlenient_issubclass\n\n lenient_issubclass (cls, types)\n\nIf possible return whether cls is a subclass of types, otherwise return False.\n\nassert not lenient_issubclass(typing.Collection, list)\nassert lenient_issubclass(list, typing.Collection)\nassert lenient_issubclass(typing.Collection, object)\nassert lenient_issubclass(typing.List, typing.Collection)\nassert not lenient_issubclass(typing.Collection, typing.List)\nassert not lenient_issubclass(object, typing.Callable)\n\n\nsource\n\n\nsorted_topologically\n\n sorted_topologically (iterable, cmp=&lt;built-in function lt&gt;,\n                       reverse=False)\n\nReturn a new list containing all items from the iterable sorted topologically\n\ntd = [3, 1, 2, 5]\ntest_eq(sorted_topologically(td), [1, 2, 3, 5])\ntest_eq(sorted_topologically(td, reverse=True), [5, 3, 2, 1])\n\n\ntd = {int:1, numbers.Number:2, numbers.Integral:3}\ntest_eq(sorted_topologically(td, cmp=lenient_issubclass), [int, numbers.Integral, numbers.Number])\n\n\ntd = [numbers.Integral, tuple, list, int, dict]\ntd = sorted_topologically(td, cmp=lenient_issubclass)\nassert td.index(int) &lt; td.index(numbers.Integral)",
    "crumbs": [
      "Type dispatch"
    ]
  },
  {
    "objectID": "dispatch.html#typedispatch",
    "href": "dispatch.html#typedispatch",
    "title": "Type dispatch",
    "section": "TypeDispatch",
    "text": "TypeDispatch\nType dispatch, or Multiple dispatch, allows you to change the way a function behaves based upon the input types it recevies. This is a prominent feature in some programming languages like Julia. For example, this is a conceptual example of how multiple dispatch works in Julia, returning different values depending on the input types of x and y:\ncollide_with(x::Asteroid, y::Asteroid) = ... \n# deal with asteroid hitting asteroid\n\ncollide_with(x::Asteroid, y::Spaceship) = ... \n# deal with asteroid hitting spaceship\n\ncollide_with(x::Spaceship, y::Asteroid) = ... \n# deal with spaceship hitting asteroid\n\ncollide_with(x::Spaceship, y::Spaceship) = ... \n# deal with spaceship hitting spaceship\nType dispatch can be especially useful in data science, where you might allow different input types (i.e. numpy arrays and pandas dataframes) to function that processes data. Type dispatch allows you to have a common API for functions that do similar tasks.\nThe TypeDispatch class allows us to achieve type dispatch in Python. It contains a dictionary that maps types from type annotations to functions, which ensures that the proper function is called when passed inputs.\n\nsource\n\nTypeDispatch\n\n TypeDispatch (funcs=(), bases=())\n\nDictionary-like object; __getitem__ matches keys of types using issubclass\nTo demonstrate how TypeDispatch works, we define a set of functions that accept a variety of input types, specified with different type annotations:\n\ndef f2(x:int, y:float): return x+y              #int and float for 2nd arg\ndef f_nin(x:numbers.Integral)-&gt;int:  return x+1 #integral numeric\ndef f_ni2(x:int): return x                      #integer\ndef f_bll(x:bool|list): return x              #bool or list\ndef f_num(x:numbers.Number): return x           #Number (root of numerics)\n\nWe can optionally initialize TypeDispatch with a list of functions we want to search. Printing an instance of TypeDispatch will display convenient mapping of types -&gt; functions:\n\nt = TypeDispatch([f_nin,f_ni2,f_num,f_bll,None])\nt\n\n(bool,object) -&gt; f_bll\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(Number,object) -&gt; f_num\n(list,object) -&gt; f_bll\n(object,object) -&gt; NoneType\n\n\nNote that only the first two arguments are used for TypeDispatch. If your function only contains one argument, the second parameter will be shown as object. If you pass None into TypeDispatch, then this will be displayed as (object, object) -&gt; NoneType.\nTypeDispatch is a dictionary-like object, which means that you can retrieve a function by the associated type annotation. For example, the statement:\nt[float]\nWill return f_num because that is the matching function that has a type annotation that is a super-class of of float - numbers.Number:\n\nassert issubclass(float, numbers.Number)\ntest_eq(t[float], f_num)\n\nThe same is true for other types as well:\n\ntest_eq(t[np.int32], f_nin)\ntest_eq(t[bool], f_bll)\ntest_eq(t[list], f_bll)\ntest_eq(t[np.int32], f_nin)\n\nIf you try to get a type that doesn’t match, TypeDispatch will return None:\n\ntest_eq(t[str], None)\n\n\nsource\n\n\nTypeDispatch.add\n\n TypeDispatch.add (f)\n\nAdd type t and function f\nThis method allows you to add an additional function to an existing TypeDispatch instance :\n\ndef f_col(x:typing.Collection): return x\nt.add(f_col)\ntest_eq(t[str], f_col)\nt\n\n(bool,object) -&gt; f_bll\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(Number,object) -&gt; f_num\n(list,object) -&gt; f_bll\n(typing.Collection,object) -&gt; f_col\n(object,object) -&gt; NoneType\n\n\nIf you accidentally add the same function more than once things will still work as expected:\n\nt.add(f_ni2) \ntest_eq(t[int], f_ni2)\n\nHowever, if you add a function that has a type collision that raises an ambiguity, this will automatically resolve to the latest function added:\n\ndef f_ni3(z:int): return z # collides with f_ni2 with same type annotations\nt.add(f_ni3) \ntest_eq(t[int], f_ni3)\n\n\nUsing bases:\nThe argument bases can optionally accept a single instance of TypeDispatch or a collection (i.e. a tuple or list) of TypeDispatch objects. This can provide functionality similar to multiple inheritance.\nThese are searched for matching functions if no match in your list of functions:\n\ndef f_str(x:str): return x+'1'\n\nt = TypeDispatch([f_nin,f_ni2,f_num,f_bll,None])\nt2 = TypeDispatch(f_str, bases=t) # you can optionally supply a list of TypeDispatch objects for `bases`.\nt2\n\n(str,object) -&gt; f_str\n(bool,object) -&gt; f_bll\n(int,object) -&gt; f_ni2\n(Integral,object) -&gt; f_nin\n(Number,object) -&gt; f_num\n(list,object) -&gt; f_bll\n(object,object) -&gt; NoneType\n\n\n\ntest_eq(t2[int], f_ni2)       # searches `t` b/c not found in `t2`\ntest_eq(t2[np.int32], f_nin)  # searches `t` b/c not found in `t2`\ntest_eq(t2[float], f_num)     # searches `t` b/c not found in `t2`\ntest_eq(t2[bool], f_bll)      # searches `t` b/c not found in `t2`\ntest_eq(t2[str], f_str)       # found in `t`!\ntest_eq(t2('a'), 'a1')        # found in `t`!, and uses __call__\n\no = np.int32(1)\ntest_eq(t2(o), 2)             # found in `t2` and uses __call__\n\n\n\nUp To Two Arguments\nTypeDispatch supports up to two arguments when searching for the appropriate function. The following functions f1 and f2 both have two parameters:\n\ndef f1(x:numbers.Integral, y): return x+1  #Integral is a numeric type\ndef f2(x:int, y:float): return x+y\nt = TypeDispatch([f1,f2])\nt\n\n(int,float) -&gt; f2\n(Integral,object) -&gt; f1\n\n\nYou can lookup functions from a TypeDispatch instance with two parameters like this:\n\ntest_eq(t[np.int32], f1)\ntest_eq(t[int,float], f2)\n\nKeep in mind that anything beyond the first two parameters are ignored, and any collisions will be resolved in favor of the most recent function added. In the below example, f1 is ignored in favor of f2 because the first two parameters have identical type hints:\n\ndef f1(a:str, b:int, c:list): return a\ndef f2(a: str, b:int): return b\nt = TypeDispatch([f1,f2])\ntest_eq(t[str, int], f2)\nt\n\n(str,int) -&gt; f2\n\n\n\n\nMatching\nType Dispatch matches types with functions according to whether the supplied class is a subclass or the same class of the type annotation(s) of associated functions.\nLet’s consider an example where we try to retrieve the function corresponding to types of [np.int32, float].\nIn this scenario, f2 will not be matched. This is because the first type annotation of f2, int, is not a superclass (or the same class) of np.int32:\n\ndef f1(x:numbers.Integral, y): return x+1\ndef f2(x:int, y:float): return x+y\nt = TypeDispatch([f1,f2])\n\nassert not issubclass(np.int32, int)\n\nInstead, f1 is a valid match, as its first argument is annoted with the type numbers.Integeral, which np.int32 is a subclass of:\n\nassert issubclass(np.int32, numbers.Integral)\ntest_eq(t[np.int32,float], f1)\n\nIn f1 , the 2nd parameter y is not annotated, which means TypeDispatch will match anything where the first argument matches int that is not matched with anything else:\n\nassert issubclass(int, numbers.Integral) # int is a subclass of numbers.Integral\ntest_eq(t[int], f1)\ntest_eq(t[int,int], f1)\n\nIf no match is possible, None is returned:\n\ntest_eq(t[float,float], None)\n\n\nsource\n\n\n\nTypeDispatch.__call__\n\n TypeDispatch.__call__ (*args, **kwargs)\n\nCall self as a function.\nTypeDispatch is also callable. When you call an instance of TypeDispatch, it will execute the relevant function:\n\ndef f_arr(x:np.ndarray): return x.sum()\ndef f_int(x:np.int32): return x+1\nt = TypeDispatch([f_arr, f_int])\n\narr = np.array([5,4,3,2,1])\ntest_eq(t(arr), 15) # dispatches to f_arr\n\no = np.int32(1)\ntest_eq(t(o), 2) # dispatches to f_int\nassert t.first() is not None\n\nYou can also call an instance of of TypeDispatch when there are two parameters:\n\ndef f1(x:numbers.Integral, y): return x+1\ndef f2(x:int, y:float): return x+y\nt = TypeDispatch([f1,f2])\n\ntest_eq(t(3,2.0), 5)\ntest_eq(t(3,2), 4)\n\nWhen no match is found, a TypeDispatch instance becomes an identity function. This default behavior is leveraged by fasatai for data transformations to provide a sensible default when a matching function cannot be found.\n\ntest_eq(t('a'), 'a')\n\n\nsource\n\n\nTypeDispatch.returns\n\n TypeDispatch.returns (x)\n\nGet the return type of annotation of x.\nYou can optionally pass an object to TypeDispatch.returns and get the return type annotation back:\n\ndef f1(x:int) -&gt; np.ndarray: return np.array(x)\ndef f2(x:str) -&gt; float: return List\ndef f3(x:float): return List # f3 has no return type annotation\n\nt = TypeDispatch([f1, f2, f3])\n\ntest_eq(t.returns(1), np.ndarray)  # dispatched to f1\ntest_eq(t.returns('Hello'), float) # dispatched to f2\ntest_eq(t.returns(1.0), None)      # dispatched to f3\n\nclass _Test: pass\n_test = _Test()\ntest_eq(t.returns(_test), None) # type `_Test` not found, so None returned\n\n\nUsing TypeDispatch With Methods\nYou can use TypeDispatch when defining methods as well:\n\ndef m_nin(self, x:str|numbers.Integral): return str(x)+'1'\ndef m_bll(self, x:bool): self.foo='a'\ndef m_num(self, x:numbers.Number): return x*2\n\nt = TypeDispatch([m_nin,m_num,m_bll])\nclass A: f = t # set class attribute `f` equal to a TypeDispatch instance\n    \na = A()\ntest_eq(a.f(1), '11')  #dispatch to m_nin\ntest_eq(a.f(1.), 2.)   #dispatch to m_num\ntest_is(a.f.inst, a)\n\na.f(False) # this triggers t.m_bll to run, which sets self.foo to 'a'\ntest_eq(a.foo, 'a')\n\nAs discussed in TypeDispatch.__call__, when there is not a match, TypeDispatch.__call__ becomes an identity function. In the below example, a tuple does not match any type annotations so a tuple is returned:\n\ntest_eq(a.f(()), ())\n\nWe extend the previous example by using bases to add an additional method that supports tuples:\n\ndef m_tup(self, x:tuple): return x+(1,)\nt2 = TypeDispatch(m_tup, bases=t)\n\nclass A2: f = t2\na2 = A2()\ntest_eq(a2.f(1), '11')\ntest_eq(a2.f(1.), 2.)\ntest_is(a2.f.inst, a2)\na2.f(False)\ntest_eq(a2.foo, 'a')\ntest_eq(a2.f(()), (1,))\n\n\n\nUsing TypeDispatch With Class Methods\nYou can use TypeDispatch when defining class methods too:\n\ndef m_nin(cls, x:str|numbers.Integral): return str(x)+'1'\ndef m_bll(cls, x:bool): cls.foo='a'\ndef m_num(cls, x:numbers.Number): return x*2\n\nt = TypeDispatch([m_nin,m_num,m_bll])\nclass A: f = t # set class attribute `f` equal to a TypeDispatch\n\ntest_eq(A.f(1), '11')  #dispatch to m_nin\ntest_eq(A.f(1.), 2.)   #dispatch to m_num\ntest_is(A.f.owner, A)\n\nA.f(False) # this triggers t.m_bll to run, which sets A.foo to 'a'\ntest_eq(A.foo, 'a')",
    "crumbs": [
      "Type dispatch"
    ]
  },
  {
    "objectID": "dispatch.html#typedispatch-decorator",
    "href": "dispatch.html#typedispatch-decorator",
    "title": "Type dispatch",
    "section": "typedispatch Decorator",
    "text": "typedispatch Decorator\n\nsource\n\nDispatchReg\n\n DispatchReg ()\n\nA global registry for TypeDispatch objects keyed by function name\n\n@typedispatch\ndef f_td_test(x, y): return f'{x}{y}'\n@typedispatch\ndef f_td_test(x:numbers.Integral|int, y): return x+1\n@typedispatch\ndef f_td_test(x:int, y:float): return x+y\n@typedispatch\ndef f_td_test(x:int, y:int): return x*y\n\ntest_eq(f_td_test(3,2.0), 5)\nassert issubclass(int, numbers.Integral)\ntest_eq(f_td_test(3,2), 6)\n\ntest_eq(f_td_test('a','b'), 'ab')\n\n\nUsing typedispatch With other decorators\nYou can use typedispatch with classmethod and staticmethod decorator\n\nclass A:\n    @typedispatch\n    def f_td_test(self, x:numbers.Integral, y): return x+1\n    @typedispatch\n    @classmethod\n    def f_td_test(cls, x:int, y:float): return x+y\n    @typedispatch\n    @staticmethod\n    def f_td_test(x:int, y:int): return x*y\n    \ntest_eq(A.f_td_test(3,2), 6)\ntest_eq(A.f_td_test(3,2.0), 5)\ntest_eq(A().f_td_test(3,'2.0'), 4)",
    "crumbs": [
      "Type dispatch"
    ]
  },
  {
    "objectID": "dispatch.html#casting",
    "href": "dispatch.html#casting",
    "title": "Type dispatch",
    "section": "Casting",
    "text": "Casting\nNow that we can dispatch on types, let’s make it easier to cast objects to a different type.\n\nsource\n\nretain_meta\n\n retain_meta (x, res, as_copy=False)\n\nCall res.set_meta(x), if it exists\n\nsource\n\n\ndefault_set_meta\n\n default_set_meta (x, as_copy=False)\n\nCopy over _meta from x to res, if it’s missing\n\n\n\n(object,object) -&gt; cast\nDictionary-like object; __getitem__ matches keys of types using issubclass\nThis works both for plain python classes:…\n\nmk_class('_T1', 'a')   # mk_class is a fastai utility that constructs a class.\nclass _T2(_T1): pass\n\nt = _T1(a=1)\nt2 = cast(t, _T2)        \nassert t2 is t            # t2 refers to the same object as t\nassert isinstance(t, _T2) # t also changed in-place\nassert isinstance(t2, _T2)\n\ntest_eq_type(_T2(a=1), t2)\n\n…as well as for arrays and tensors.\n\nclass _T1(ndarray): pass\n\nt = array([1])\nt2 = cast(t, _T1)\ntest_eq(array([1]), t2)\ntest_eq(_T1, type(t2))\n\nTo customize casting for other types, define a separate cast function with typedispatch for your type.\n\nsource\n\n\nretain_type\n\n retain_type (new, old=None, typ=None, as_copy=False)\n\nCast new to type of old or typ if it’s a superclass\n\nclass _T(tuple): pass\na = _T((1,2))\nb = tuple((1,2))\nc = retain_type(b, typ=_T)\ntest_eq_type(c, a)\n\nIf old has a _meta attribute, its content is passed when casting new to the type of old. In the below example, only the attribute a, but not other_attr is kept, because other_attr is not in _meta:\n\nclass _A():\n    set_meta = default_set_meta\n    def __init__(self, t): self.t=t\n\nclass _B1(_A):\n    def __init__(self, t, a=1):\n        super().__init__(t)\n        self._meta = {'a':a}\n        self.other_attr = 'Hello' # will not be kept after casting.\n        \nx = _B1(1, a=2)\nb = _A(1)\nc = retain_type(b, old=x)\ntest_eq(c._meta, {'a': 2})\nassert not getattr(c, 'other_attr', None)\n\n\nsource\n\n\nretain_types\n\n retain_types (new, old=None, typs=None)\n\nCast each item of new to type of matching item in old if it’s a superclass\n\nclass T(tuple): pass\n\nt1,t2 = retain_types((1,(1,(1,1))), (2,T((2,T((3,4))))))\ntest_eq_type(t1, 1)\ntest_eq_type(t2, T((1,T((1,1)))))\n\nt1,t2 = retain_types((1,(1,(1,1))), typs = {tuple: [int, {T: [int, {T: [int,int]}]}]})\ntest_eq_type(t1, 1)\ntest_eq_type(t2, T((1,T((1,1)))))\n\n\nsource\n\n\nexplode_types\n\n explode_types (o)\n\nReturn the type of o, potentially in nested dictionaries for thing that are listy\n\ntest_eq(explode_types((2,T((2,T((3,4)))))), {tuple: [int, {T: [int, {T: [int,int]}]}]})",
    "crumbs": [
      "Type dispatch"
    ]
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Basic functionality",
    "section": "",
    "text": "source\n\n\n\n ifnone (a, b)\n\nb if a is None else a\nSince b if a is None else a is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate both a and b when calling ifnone (which it doesn’t do if using the if version directly).\n\ntest_eq(ifnone(None,1), 1)\ntest_eq(ifnone(2   ,1), 2)\n\n\nsource\n\n\n\n\n maybe_attr (o, attr)\n\ngetattr(o,attr,o)\nReturn the attribute attr for object o. If the attribute doesn’t exist, then return the object o instead.\n\nclass myobj: myattr='foo'\n\ntest_eq(maybe_attr(myobj, 'myattr'), 'foo')\ntest_eq(maybe_attr(myobj, 'another_attr'), myobj)\n\n\nsource\n\n\n\n\n basic_repr (flds=None)\n\nMinimal __repr__\nIn types which provide rich display functionality in Jupyter, their __repr__ is also called in order to provide a fallback text representation. Unfortunately, this includes a memory address which changes on every invocation, making it non-deterministic. This causes diffs to get messy and creates conflicts in git. To fix this, put __repr__=basic_repr() inside your class.\n\nclass SomeClass: __repr__=basic_repr()\nrepr(SomeClass())\n\n'SomeClass()'\n\n\nIf you pass a list of attributes (flds) of an object, then this will generate a string with the name of each attribute and its corresponding value. The format of this string is key=value, where key is the name of the attribute, and value is the value of the attribute. For each value, attempt to use the __name__ attribute, otherwise fall back to using the value’s __repr__ when constructing the string.\n\nclass SomeClass:\n    a=1\n    b='foo'\n    __repr__=basic_repr('a,b')\n    __name__='some-class'\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\nNested objects work too:\n\nclass AnotherClass:\n    c=SomeClass()\n    d='bar'\n    __repr__=basic_repr(['c', 'd'])\n\nrepr(AnotherClass())\n\n\"AnotherClass(c=SomeClass(a=1, b='foo'), d='bar')\"\n\n\nInstance variables (but not class variables) are shown if basic_repr is called with no arguments:\n\nclass SomeClass:\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n    __repr__=basic_repr()\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\n BasicRepr ()\n\nBase class for objects needing a basic __repr__\nAs a shortcut for creating a __repr__ for instance variables, you can inherit from BasicRepr:\n\nclass SomeClass(BasicRepr):\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\n is_array (x)\n\nTrue if x supports __array__ or iloc\n\nis_array(np.array(1)),is_array([1])\n\n(True, False)\n\n\n\nsource\n\n\n\n\n listify (o=None, *rest, use_list=False, match=None)\n\nConvert o to a list\nConversion is designed to “do what you mean”, e.g:\n\ntest_eq(listify('hi'), ['hi'])\ntest_eq(listify(b'hi'), [b'hi'])\ntest_eq(listify(array(1)), [array(1)])\ntest_eq(listify(1), [1])\ntest_eq(listify([1,2]), [1,2])\ntest_eq(listify(range(3)), [0,1,2])\ntest_eq(listify(None), [])\ntest_eq(listify(1,2), [1,2])\n\n\narr = np.arange(9).reshape(3,3)\nlistify(arr)\n\n[array([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])]\n\n\n\nlistify(array([1,2]))\n\n[array([1, 2])]\n\n\nGenerators are turned into lists too:\n\ngen = (o for o in range(3))\ntest_eq(listify(gen), [0,1,2])\n\nUse match to provide a length to match:\n\ntest_eq(listify(1,match=3), [1,1,1])\n\nIf match is a sequence, it’s length is used:\n\ntest_eq(listify(1,match=range(3)), [1,1,1])\n\nIf the listified item is not of length 1, it must be the same length as match:\n\ntest_eq(listify([1,1,1],match=3), [1,1,1])\ntest_fail(lambda: listify([1,1],match=3))\n\n\nsource\n\n\n\n\n tuplify (o, use_list=False, match=None)\n\nMake o a tuple\n\ntest_eq(tuplify(None),())\ntest_eq(tuplify([1,2,3]),(1,2,3))\ntest_eq(tuplify(1,match=[1,2,3]),(1,1,1))\n\n\nsource\n\n\n\n\n true (x)\n\nTest whether x is truthy; collections with &gt;0 elements are considered True\n\n[(o,true(o)) for o in\n (array(0),array(1),array([0]),array([0,1]),1,0,'',None)]\n\n[(array(0), False),\n (array(1), True),\n (array([0]), True),\n (array([0, 1]), True),\n (1, True),\n (0, False),\n ('', False),\n (None, False)]\n\n\n\nsource\n\n\n\n\n NullType ()\n\nAn object that is False and can be called, chained, and indexed\n\nbool(null.hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\n tonull (x)\n\nConvert None to null\n\nbool(tonull(None).hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\n get_class (nm, *fld_names, sup=None, doc=None, funcs=None, anno=None,\n            **flds)\n\nDynamically create a class, optionally inheriting from sup, containing fld_names\n\n_t = get_class('_t', 'a', b=2, anno={'b':int})\nt = _t()\ntest_eq(t.a, None)\ntest_eq(t.b, 2)\nt = _t(1, b=3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\nt = _t(1, 3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\ntest_eq(t, pickle.loads(pickle.dumps(t)))\ntest_eq(_t.__annotations__, {'b':int, 'a':typing.Any})\nrepr(t)\n\n'_t(a=1, b=3)'\n\n\nMost often you’ll want to call mk_class, since it adds the class to your module. See mk_class for more details and examples of use (which also apply to get_class).\n\nsource\n\n\n\n\n mk_class (nm, *fld_names, sup=None, doc=None, funcs=None, mod=None,\n           anno=None, **flds)\n\nCreate a class using get_class and add to the caller’s module\nAny kwargs will be added as class attributes, and sup is an optional (tuple of) base classes.\n\nmk_class('_t', a=1, sup=dict)\nt = _t()\ntest_eq(t.a, 1)\nassert(isinstance(t,dict))\n\nA __init__ is provided that sets attrs for any kwargs, and for any args (matching by position to fields), along with a __repr__ which prints all attrs. The docstring is set to doc. You can pass funcs which will be added as attrs with the function names.\n\ndef foo(self): return 1\nmk_class('_t', 'a', sup=dict, doc='test doc', funcs=foo)\n\nt = _t(3, b=2)\ntest_eq(t.a, 3)\ntest_eq(t.b, 2)\ntest_eq(t.foo(), 1)\ntest_eq(t.__doc__, 'test doc')\nt\n\n{}\n\n\n\nsource\n\n\n\n\n wrap_class (nm, *fld_names, sup=None, doc=None, funcs=None, **flds)\n\nDecorator: makes function a method of a new class nm passing parameters to mk_class\n\n@wrap_class('_t', a=2)\ndef bar(self,x): return x+1\n\nt = _t()\ntest_eq(t.a, 2)\ntest_eq(t.bar(3), 4)\n\n\nsource\n\n\n\n ignore_exceptions ()\n\nContext manager to ignore exceptions\n\nwith ignore_exceptions(): \n    # Exception will be ignored\n    raise Exception\n\n\nsource\n\n\n\n\n\n exec_local (code, var_name)\n\nCall exec on code and return the var var_name\n\ntest_eq(exec_local(\"a=1\", \"a\"), 1)\n\n\nsource\n\n\n\n\n risinstance (types, obj=None)\n\nCurried isinstance but with args reversed\n\nassert risinstance(int, 1)\nassert not risinstance(str, 0)\nassert risinstance(int)(1)\nassert not risinstance(int)(None)\n\ntypes can also be strings:\n\nassert risinstance(('str','int'), 'a')\nassert risinstance('str', 'a')\nassert not risinstance('int', 'a')\n\n\nsource\n\n\n\n\n ver2tuple (v:str)\n\n\ntest_eq(ver2tuple('3.8.1'), (3,8,1))\ntest_eq(ver2tuple('3.1'), (3,1,0))\ntest_eq(ver2tuple('3.'), (3,0,0))\ntest_eq(ver2tuple('3'), (3,0,0))",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#basics",
    "href": "basics.html#basics",
    "title": "Basic functionality",
    "section": "",
    "text": "source\n\n\n\n ifnone (a, b)\n\nb if a is None else a\nSince b if a is None else a is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate both a and b when calling ifnone (which it doesn’t do if using the if version directly).\n\ntest_eq(ifnone(None,1), 1)\ntest_eq(ifnone(2   ,1), 2)\n\n\nsource\n\n\n\n\n maybe_attr (o, attr)\n\ngetattr(o,attr,o)\nReturn the attribute attr for object o. If the attribute doesn’t exist, then return the object o instead.\n\nclass myobj: myattr='foo'\n\ntest_eq(maybe_attr(myobj, 'myattr'), 'foo')\ntest_eq(maybe_attr(myobj, 'another_attr'), myobj)\n\n\nsource\n\n\n\n\n basic_repr (flds=None)\n\nMinimal __repr__\nIn types which provide rich display functionality in Jupyter, their __repr__ is also called in order to provide a fallback text representation. Unfortunately, this includes a memory address which changes on every invocation, making it non-deterministic. This causes diffs to get messy and creates conflicts in git. To fix this, put __repr__=basic_repr() inside your class.\n\nclass SomeClass: __repr__=basic_repr()\nrepr(SomeClass())\n\n'SomeClass()'\n\n\nIf you pass a list of attributes (flds) of an object, then this will generate a string with the name of each attribute and its corresponding value. The format of this string is key=value, where key is the name of the attribute, and value is the value of the attribute. For each value, attempt to use the __name__ attribute, otherwise fall back to using the value’s __repr__ when constructing the string.\n\nclass SomeClass:\n    a=1\n    b='foo'\n    __repr__=basic_repr('a,b')\n    __name__='some-class'\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\nNested objects work too:\n\nclass AnotherClass:\n    c=SomeClass()\n    d='bar'\n    __repr__=basic_repr(['c', 'd'])\n\nrepr(AnotherClass())\n\n\"AnotherClass(c=SomeClass(a=1, b='foo'), d='bar')\"\n\n\nInstance variables (but not class variables) are shown if basic_repr is called with no arguments:\n\nclass SomeClass:\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n    __repr__=basic_repr()\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\n BasicRepr ()\n\nBase class for objects needing a basic __repr__\nAs a shortcut for creating a __repr__ for instance variables, you can inherit from BasicRepr:\n\nclass SomeClass(BasicRepr):\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\n is_array (x)\n\nTrue if x supports __array__ or iloc\n\nis_array(np.array(1)),is_array([1])\n\n(True, False)\n\n\n\nsource\n\n\n\n\n listify (o=None, *rest, use_list=False, match=None)\n\nConvert o to a list\nConversion is designed to “do what you mean”, e.g:\n\ntest_eq(listify('hi'), ['hi'])\ntest_eq(listify(b'hi'), [b'hi'])\ntest_eq(listify(array(1)), [array(1)])\ntest_eq(listify(1), [1])\ntest_eq(listify([1,2]), [1,2])\ntest_eq(listify(range(3)), [0,1,2])\ntest_eq(listify(None), [])\ntest_eq(listify(1,2), [1,2])\n\n\narr = np.arange(9).reshape(3,3)\nlistify(arr)\n\n[array([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])]\n\n\n\nlistify(array([1,2]))\n\n[array([1, 2])]\n\n\nGenerators are turned into lists too:\n\ngen = (o for o in range(3))\ntest_eq(listify(gen), [0,1,2])\n\nUse match to provide a length to match:\n\ntest_eq(listify(1,match=3), [1,1,1])\n\nIf match is a sequence, it’s length is used:\n\ntest_eq(listify(1,match=range(3)), [1,1,1])\n\nIf the listified item is not of length 1, it must be the same length as match:\n\ntest_eq(listify([1,1,1],match=3), [1,1,1])\ntest_fail(lambda: listify([1,1],match=3))\n\n\nsource\n\n\n\n\n tuplify (o, use_list=False, match=None)\n\nMake o a tuple\n\ntest_eq(tuplify(None),())\ntest_eq(tuplify([1,2,3]),(1,2,3))\ntest_eq(tuplify(1,match=[1,2,3]),(1,1,1))\n\n\nsource\n\n\n\n\n true (x)\n\nTest whether x is truthy; collections with &gt;0 elements are considered True\n\n[(o,true(o)) for o in\n (array(0),array(1),array([0]),array([0,1]),1,0,'',None)]\n\n[(array(0), False),\n (array(1), True),\n (array([0]), True),\n (array([0, 1]), True),\n (1, True),\n (0, False),\n ('', False),\n (None, False)]\n\n\n\nsource\n\n\n\n\n NullType ()\n\nAn object that is False and can be called, chained, and indexed\n\nbool(null.hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\n tonull (x)\n\nConvert None to null\n\nbool(tonull(None).hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\n get_class (nm, *fld_names, sup=None, doc=None, funcs=None, anno=None,\n            **flds)\n\nDynamically create a class, optionally inheriting from sup, containing fld_names\n\n_t = get_class('_t', 'a', b=2, anno={'b':int})\nt = _t()\ntest_eq(t.a, None)\ntest_eq(t.b, 2)\nt = _t(1, b=3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\nt = _t(1, 3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\ntest_eq(t, pickle.loads(pickle.dumps(t)))\ntest_eq(_t.__annotations__, {'b':int, 'a':typing.Any})\nrepr(t)\n\n'_t(a=1, b=3)'\n\n\nMost often you’ll want to call mk_class, since it adds the class to your module. See mk_class for more details and examples of use (which also apply to get_class).\n\nsource\n\n\n\n\n mk_class (nm, *fld_names, sup=None, doc=None, funcs=None, mod=None,\n           anno=None, **flds)\n\nCreate a class using get_class and add to the caller’s module\nAny kwargs will be added as class attributes, and sup is an optional (tuple of) base classes.\n\nmk_class('_t', a=1, sup=dict)\nt = _t()\ntest_eq(t.a, 1)\nassert(isinstance(t,dict))\n\nA __init__ is provided that sets attrs for any kwargs, and for any args (matching by position to fields), along with a __repr__ which prints all attrs. The docstring is set to doc. You can pass funcs which will be added as attrs with the function names.\n\ndef foo(self): return 1\nmk_class('_t', 'a', sup=dict, doc='test doc', funcs=foo)\n\nt = _t(3, b=2)\ntest_eq(t.a, 3)\ntest_eq(t.b, 2)\ntest_eq(t.foo(), 1)\ntest_eq(t.__doc__, 'test doc')\nt\n\n{}\n\n\n\nsource\n\n\n\n\n wrap_class (nm, *fld_names, sup=None, doc=None, funcs=None, **flds)\n\nDecorator: makes function a method of a new class nm passing parameters to mk_class\n\n@wrap_class('_t', a=2)\ndef bar(self,x): return x+1\n\nt = _t()\ntest_eq(t.a, 2)\ntest_eq(t.bar(3), 4)\n\n\nsource\n\n\n\n ignore_exceptions ()\n\nContext manager to ignore exceptions\n\nwith ignore_exceptions(): \n    # Exception will be ignored\n    raise Exception\n\n\nsource\n\n\n\n\n\n exec_local (code, var_name)\n\nCall exec on code and return the var var_name\n\ntest_eq(exec_local(\"a=1\", \"a\"), 1)\n\n\nsource\n\n\n\n\n risinstance (types, obj=None)\n\nCurried isinstance but with args reversed\n\nassert risinstance(int, 1)\nassert not risinstance(str, 0)\nassert risinstance(int)(1)\nassert not risinstance(int)(None)\n\ntypes can also be strings:\n\nassert risinstance(('str','int'), 'a')\nassert risinstance('str', 'a')\nassert not risinstance('int', 'a')\n\n\nsource\n\n\n\n\n ver2tuple (v:str)\n\n\ntest_eq(ver2tuple('3.8.1'), (3,8,1))\ntest_eq(ver2tuple('3.1'), (3,1,0))\ntest_eq(ver2tuple('3.'), (3,0,0))\ntest_eq(ver2tuple('3'), (3,0,0))",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#noop",
    "href": "basics.html#noop",
    "title": "Basic functionality",
    "section": "NoOp",
    "text": "NoOp\nThese are used when you need a pass-through function.\n\n\nnoop\n\n noop (x=None, *args, **kwargs)\n\nDo nothing\n\nnoop()\ntest_eq(noop(1),1)\n\n\n\n\nnoops\n\n noops (x=None, *args, **kwargs)\n\nDo nothing (method)\n\nclass _t: foo=noops\ntest_eq(_t().foo(1),1)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#infinite-lists",
    "href": "basics.html#infinite-lists",
    "title": "Basic functionality",
    "section": "Infinite Lists",
    "text": "Infinite Lists\nThese lists are useful for things like padding an array or adding index column(s) to arrays.\nInf defines the following properties:\n\ncount: itertools.count()\nzeros: itertools.cycle([0])\nones : itertools.cycle([1])\nnones: itertools.cycle([None])\n\n\ntest_eq([o for i,o in zip(range(5), Inf.count)],\n        [0, 1, 2, 3, 4])\n\ntest_eq([o for i,o in zip(range(5), Inf.zeros)],\n        [0]*5)\n\ntest_eq([o for i,o in zip(range(5), Inf.ones)],\n        [1]*5)\n\ntest_eq([o for i,o in zip(range(5), Inf.nones)],\n        [None]*5)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#operator-functions",
    "href": "basics.html#operator-functions",
    "title": "Basic functionality",
    "section": "Operator Functions",
    "text": "Operator Functions\n\nsource\n\nin_\n\n in_ (x, a)\n\nTrue if x in a\n\n# test if element is in another\nassert in_('c', ('b', 'c', 'a'))\nassert in_(4, [2,3,4,5])\nassert in_('t', 'fastai')\ntest_fail(in_('h', 'fastai'))\n\n# use in_ as a partial\nassert in_('fastai')('t')\nassert in_([2,3,4,5])(4)\ntest_fail(in_('fastai')('h'))\n\nIn addition to in_, the following functions are provided matching the behavior of the equivalent versions in operator: lt gt le ge eq ne add sub mul truediv is_ is_not mod.\n\nlt(3,5),gt(3,5),is_(None,None),in_(0,[1,2]),mod(3,2)\n\n(True, False, True, False, 1)\n\n\nSimilarly to _in, they also have additional functionality: if you only pass one param, they return a partial function that passes that param as the second positional parameter.\n\nlt(5)(3),gt(5)(3),is_(None)(None),in_([1,2])(0),mod(2)(3)\n\n(True, False, True, False, 1)\n\n\n\nsource\n\n\nret_true\n\n ret_true (*args, **kwargs)\n\nPredicate: always True\n\nassert ret_true(1,2,3)\nassert ret_true(False)\n\n\nsource\n\n\nret_false\n\n ret_false (*args, **kwargs)\n\nPredicate: always False\n\nsource\n\n\nstop\n\n stop (e=&lt;class 'StopIteration'&gt;)\n\nRaises exception e (by default StopIteration)\n\nsource\n\n\ngen\n\n gen (func, seq, cond=&lt;function ret_true&gt;)\n\nLike (func(o) for o in seq if cond(func(o))) but handles StopIteration\n\ntest_eq(gen(noop, Inf.count, lt(5)),\n        range(5))\ntest_eq(gen(operator.neg, Inf.count, gt(-5)),\n        [0,-1,-2,-3,-4])\ntest_eq(gen(lambda o:o if o&lt;5 else stop(), Inf.count),\n        range(5))\n\n\nsource\n\n\nchunked\n\n chunked (it, chunk_sz=None, drop_last=False, n_chunks=None)\n\nReturn batches from iterator it of size chunk_sz (or return n_chunks total)\nNote that you must pass either chunk_sz, or n_chunks, but not both.\n\nt = list(range(10))\ntest_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\ntest_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n\nt = map(lambda o:stop() if o==6 else o, Inf.count)\ntest_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5]])\nt = map(lambda o:stop() if o==7 else o, Inf.count)\ntest_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5], [6]])\n\nt = np.arange(10)\ntest_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\ntest_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n\ntest_eq(chunked([], 3),          [])\ntest_eq(chunked([], n_chunks=3), [])\n\n\nsource\n\n\notherwise\n\n otherwise (x, tst, y)\n\ny if tst(x) else x\n\ntest_eq(otherwise(2+1, gt(3), 4), 3)\ntest_eq(otherwise(2+1, gt(2), 4), 4)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#attribute-helpers",
    "href": "basics.html#attribute-helpers",
    "title": "Basic functionality",
    "section": "Attribute Helpers",
    "text": "Attribute Helpers\nThese functions reduce boilerplate when setting or manipulating attributes or properties of objects.\n\nsource\n\ncustom_dir\n\n custom_dir (c, add)\n\nImplement custom __dir__, adding add to cls\ncustom_dir allows you extract the __dict__ property of a class and appends the list add to it.\n\nclass _T: \n    def f(): pass\n\ns = custom_dir(_T(), add=['foo', 'bar'])\nassert {'foo', 'bar', 'f'}.issubset(s)\n\n\nsource\n\n\nAttrDict\ndict subclass that also provides access to keys as attrs\n\nd = AttrDict(a=1,b=\"two\")\ntest_eq(d.a, 1)\ntest_eq(d['b'], 'two')\ntest_eq(d.get('c','nope'), 'nope')\nd.b = 2\ntest_eq(d.b, 2)\ntest_eq(d['b'], 2)\nd['b'] = 3\ntest_eq(d['b'], 3)\ntest_eq(d.b, 3)\nassert 'a' in dir(d)\n\nAttrDict will pretty print in Jupyter Notebooks:\n\n_test_dict = {'a':1, 'b': {'c':1, 'd':2}, 'c': {'c':1, 'd':2}, 'd': {'c':1, 'd':2},\n              'e': {'c':1, 'd':2}, 'f': {'c':1, 'd':2, 'e': 4, 'f':[1,2,3,4,5]}}\nAttrDict(_test_dict)\n\n{ 'a': 1,\n  'b': {'c': 1, 'd': 2},\n  'c': {'c': 1, 'd': 2},\n  'd': {'c': 1, 'd': 2},\n  'e': {'c': 1, 'd': 2},\n  'f': {'c': 1, 'd': 2, 'e': 4, 'f': [1, 2, 3, 4, 5]}}\n\n\n\nsource\n\n\nAttrDictDefault\n\n AttrDictDefault (*args, default_=None, **kwargs)\n\nAttrDict subclass that returns None for missing attrs\n\nd = AttrDictDefault(a=1,b=\"two\", default_='nope')\ntest_eq(d.a, 1)\ntest_eq(d['b'], 'two')\ntest_eq(d.c, 'nope')\n\n\nsource\n\n\nNS\nSimpleNamespace subclass that also adds iter and dict support\nThis is very similar to AttrDict, but since it starts with SimpleNamespace, it has some differences in behavior. You can use it just like SimpleNamespace:\n\nd = NS(**_test_dict)\nd\n\nnamespace(a=1,\n          b={'c': 1, 'd': 2},\n          c={'c': 1, 'd': 2},\n          d={'c': 1, 'd': 2},\n          e={'c': 1, 'd': 2},\n          f={'c': 1, 'd': 2, 'e': 4, 'f': [1, 2, 3, 4, 5]})\n\n\n…but you can also index it to get/set:\n\nd['a']\n\n1\n\n\n…and iterate t:\n\nlist(d)\n\n['a', 'b', 'c', 'd', 'e', 'f']\n\n\n\nsource\n\n\nget_annotations_ex\n\n get_annotations_ex (obj, globals=None, locals=None)\n\nBackport of py3.10 get_annotations that returns globals/locals\nIn Python 3.10 inspect.get_annotations was added. However previous versions of Python are unable to evaluate type annotations correctly if from future import __annotations__ is used. Furthermore, all annotations are evaluated, even if only some subset are needed. get_annotations_ex provides the same functionality as inspect.get_annotations, but works on earlier versions of Python, and returns the globals and locals needed to evaluate types.\n\nsource\n\n\neval_type\n\n eval_type (t, glb, loc)\n\neval a type or collection of types, if needed, for annotations in py3.10+\nIn py3.10, or if from future import __annotations__ is used, a is a str:\n\nclass _T2a: pass\ndef func(a: _T2a): pass\nann,glb,loc = get_annotations_ex(func)\n\neval_type(ann['a'], glb, loc)\n\n__main__._T2a\n\n\n| is supported for defining Union types when using eval_type even for python versions prior to 3.9:\n\nclass _T2b: pass\ndef func(a: _T2a|_T2b): pass\nann,glb,loc = get_annotations_ex(func)\n\neval_type(ann['a'], glb, loc)\n\ntyping.Union[__main__._T2a, __main__._T2b]\n\n\n\nsource\n\n\ntype_hints\n\n type_hints (f)\n\nLike typing.get_type_hints but returns {} if not allowed type\nBelow is a list of allowed types for type hints in python:\n\nlist(typing._allowed_types)\n\n[function,\n builtin_function_or_method,\n method,\n module,\n wrapper_descriptor,\n method-wrapper,\n method_descriptor]\n\n\nFor example, type func is allowed so type_hints returns the same value as typing.get_hints:\n\ndef f(a:int)-&gt;bool: ... # a function with type hints (allowed)\nexp = {'a':int,'return':bool}\ntest_eq(type_hints(f), typing.get_type_hints(f))\ntest_eq(type_hints(f), exp)\n\nHowever, class is not an allowed type, so type_hints returns {}:\n\nclass _T:\n    def __init__(self, a:int=0)-&gt;bool: ...\nassert not type_hints(_T)\n\n\nsource\n\n\nannotations\n\n annotations (o)\n\nAnnotations for o, or type(o)\nThis supports a wider range of situations than type_hints, by checking type() and __init__ for annotations too:\n\nfor o in _T,_T(),_T.__init__,f: test_eq(annotations(o), exp)\nassert not annotations(int)\nassert not annotations(print)\n\n\nsource\n\n\nanno_ret\n\n anno_ret (func)\n\nGet the return annotation of func\n\ndef f(x) -&gt; float: return x\ntest_eq(anno_ret(f), float)\n\ndef f(x) -&gt; typing.Tuple[float,float]: return x\nassert anno_ret(f)==typing.Tuple[float,float]\n\nIf your return annotation is None, anno_ret will return NoneType (and not None):\n\ndef f(x) -&gt; None: return x\n\ntest_eq(anno_ret(f), NoneType)\nassert anno_ret(f) is not None # returns NoneType instead of None\n\nIf your function does not have a return type, or if you pass in None instead of a function, then anno_ret returns None:\n\ndef f(x): return x\n\ntest_eq(anno_ret(f), None)\ntest_eq(anno_ret(None), None) # instead of passing in a func, pass in None\n\n\nsource\n\n\nsignature_ex\n\n signature_ex (obj, eval_str:bool=False)\n\nBackport of inspect.signature(..., eval_str=True to &lt;py310\n\nsource\n\n\nunion2tuple\n\n union2tuple (t)\n\n\ntest_eq(union2tuple(Union[int,str]), (int,str))\ntest_eq(union2tuple(int), int)\nassert union2tuple(Tuple[int,str])==Tuple[int,str]\ntest_eq(union2tuple((int,str)), (int,str))\nif UnionType: test_eq(union2tuple(int|str), (int,str))\n\n\nsource\n\n\nargnames\n\n argnames (f, frame=False)\n\nNames of arguments to function or frame f\n\ntest_eq(argnames(f), ['x'])\n\n\nsource\n\n\nwith_cast\n\n with_cast (f)\n\nDecorator which uses any parameter annotations as preprocessing functions\n\n@with_cast\ndef _f(a, b:Path, c:str='', d=0): return (a,b,c,d)\n\ntest_eq(_f(1, '.', 3), (1,Path('.'),'3',0))\ntest_eq(_f(1, '.'), (1,Path('.'),'',0))\n\n@with_cast\ndef _g(a:int=0)-&gt;str: return a\n\ntest_eq(_g(4.0), '4')\ntest_eq(_g(4.4), '4')\ntest_eq(_g(2), '2')\n\n\nsource\n\n\nstore_attr\n\n store_attr (names=None, but='', cast=False, store_args=None, **attrs)\n\nStore params named in comma-separated names from calling context into attrs in self\nIn it’s most basic form, you can use store_attr to shorten code like this:\n\nclass T:\n    def __init__(self, a,b,c): self.a,self.b,self.c = a,b,c\n\n…to this:\n\nclass T:\n    def __init__(self, a,b,c): store_attr('a,b,c', self)\n\nThis class behaves as if we’d used the first form:\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\n\nclass T1:\n    def __init__(self, a,b,c): store_attr()\n\nIn addition, it stores the attrs as a dict in __stored_args__, which you can use for display, logging, and so forth.\n\ntest_eq(t.__stored_args__, {'a':1, 'b':3, 'c':2})\n\nSince you normally want to use the first argument (often called self) for storing attributes, it’s optional:\n\nclass T:\n    def __init__(self, a,b,c:str): store_attr('a,b,c')\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\nWith cast=True any parameter annotations will be used as preprocessing functions for the corresponding arguments:\n\nclass T:\n    def __init__(self, a:listify, b, c:str): store_attr('a,b,c', cast=True)\n\nt = T(1,c=2,b=3)\nassert t.a==[1] and t.b==3 and t.c=='2'\n\nYou can inherit from a class using store_attr, and just call it again to add in any new attributes added in the derived class:\n\nclass T2(T):\n    def __init__(self, d, **kwargs):\n        super().__init__(**kwargs)\n        store_attr('d')\n\nt = T2(d=1,a=2,b=3,c=4)\nassert t.a==2 and t.b==3 and t.c==4 and t.d==1\n\nYou can skip passing a list of attrs to store. In this case, all arguments passed to the method are stored:\n\nclass T:\n    def __init__(self, a,b,c): store_attr()\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\n\nclass T4(T):\n    def __init__(self, d, **kwargs):\n        super().__init__(**kwargs)\n        store_attr()\n\nt = T4(4, a=1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2 and t.d==4\n\n\nclass T4:\n    def __init__(self, *, a: int, b: float = 1):\n        store_attr()\n        \nt = T4(a=3)\nassert t.a==3 and t.b==1\nt = T4(a=3, b=2)\nassert t.a==3 and t.b==2\n\nYou can skip some attrs by passing but:\n\nclass T:\n    def __init__(self, a,b,c): store_attr(but='a')\n\nt = T(1,c=2,b=3)\nassert t.b==3 and t.c==2\nassert not hasattr(t,'a')\n\nYou can also pass keywords to store_attr, which is identical to setting the attrs directly, but also stores them in __stored_args__.\n\nclass T:\n    def __init__(self): store_attr(a=1)\n\nt = T()\nassert t.a==1\n\nYou can also use store_attr inside functions.\n\ndef create_T(a, b):\n    t = SimpleNamespace()\n    store_attr(self=t)\n    return t\n\nt = create_T(a=1, b=2)\nassert t.a==1 and t.b==2\n\n\nsource\n\n\nattrdict\n\n attrdict (o, *ks, default=None)\n\nDict from each k in ks to getattr(o,k)\n\nclass T:\n    def __init__(self, a,b,c): store_attr()\n\nt = T(1,c=2,b=3)\ntest_eq(attrdict(t,'b','c'), {'b':3, 'c':2})\n\n\nsource\n\n\nproperties\n\n properties (cls, *ps)\n\nChange attrs in cls with names in ps to properties\n\nclass T:\n    def a(self): return 1\n    def b(self): return 2\nproperties(T,'a')\n\ntest_eq(T().a,1)\ntest_eq(T().b(),2)\n\n\nsource\n\n\ncamel2words\n\n camel2words (s, space=' ')\n\nConvert CamelCase to ‘spaced words’\n\ntest_eq(camel2words('ClassAreCamel'), 'Class Are Camel')\n\n\nsource\n\n\ncamel2snake\n\n camel2snake (name)\n\nConvert CamelCase to snake_case\n\ntest_eq(camel2snake('ClassAreCamel'), 'class_are_camel')\ntest_eq(camel2snake('Already_Snake'), 'already__snake')\n\n\nsource\n\n\nsnake2camel\n\n snake2camel (s)\n\nConvert snake_case to CamelCase\n\ntest_eq(snake2camel('a_b_cc'), 'ABCc')\n\n\nsource\n\n\nclass2attr\n\n class2attr (cls_name)\n\nReturn the snake-cased name of the class; strip ending cls_name if it exists.\n\nclass Parent:\n    @property\n    def name(self): return class2attr(self, 'Parent')\n\nclass ChildOfParent(Parent): pass\nclass ParentChildOf(Parent): pass\n\np = Parent()\ncp = ChildOfParent()\ncp2 = ParentChildOf()\n\ntest_eq(p.name, 'parent')\ntest_eq(cp.name, 'child_of')\ntest_eq(cp2.name, 'parent_child_of')\n\n\nsource\n\n\ngetcallable\n\n getcallable (o, attr)\n\nCalls getattr with a default of noop\n\nclass Math:\n    def addition(self,a,b): return a+b\n\nm = Math()\n\ntest_eq(getcallable(m, \"addition\")(a=1,b=2), 3)\ntest_eq(getcallable(m, \"subtraction\")(a=1,b=2), None)\n\n\nsource\n\n\ngetattrs\n\n getattrs (o, *attrs, default=None)\n\nList of all attrs in o\n\nfrom fractions import Fraction\n\n\ngetattrs(Fraction(1,2), 'numerator', 'denominator')\n\n[1, 2]\n\n\n\nsource\n\n\nhasattrs\n\n hasattrs (o, attrs)\n\nTest whether o contains all attrs\n\nassert hasattrs(1,('imag','real'))\nassert not hasattrs(1,('imag','foo'))\n\n\nsource\n\n\nsetattrs\n\n setattrs (dest, flds, src)\n\n\nd = dict(a=1,bb=\"2\",ignore=3)\no = SimpleNamespace()\nsetattrs(o, \"a,bb\", d)\ntest_eq(o.a, 1)\ntest_eq(o.bb, \"2\")\n\n\nd = SimpleNamespace(a=1,bb=\"2\",ignore=3)\no = SimpleNamespace()\nsetattrs(o, \"a,bb\", d)\ntest_eq(o.a, 1)\ntest_eq(o.bb, \"2\")\n\n\nsource\n\n\ntry_attrs\n\n try_attrs (obj, *attrs)\n\nReturn first attr that exists in obj\n\ntest_eq(try_attrs(1, 'real'), 1)\ntest_eq(try_attrs(1, 'foobar', 'real'), 1)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#attribute-delegation",
    "href": "basics.html#attribute-delegation",
    "title": "Basic functionality",
    "section": "Attribute Delegation",
    "text": "Attribute Delegation\n\nsource\n\nGetAttrBase\n\n GetAttrBase ()\n\nBasic delegation of __getattr__ and __dir__\n\nsource\n\nGetAttr\n\n GetAttr ()\n\nInherit from this to have all attr accesses in self._xtra passed down to self.default\nInherit from GetAttr to have attr access passed down to an instance attribute. This makes it easy to create composites that don’t require callers to know about their components. For a more detailed discussion of how this works as well as relevant context, we suggest reading the delegated composition section of this blog article.\nYou can customise the behaviour of GetAttr in subclasses via; - _default - By default, this is set to 'default', so attr access is passed down to self.default - _default can be set to the name of any instance attribute that does not start with dunder __ - _xtra - By default, this is None, so all attr access is passed down - You can limit which attrs get passed down by setting _xtra to a list of attribute names\nTo illuminate the utility of GetAttr, suppose we have the following two classes, _WebPage which is a superclass of _ProductPage, which we wish to compose like so:\n\nclass _WebPage:\n    def __init__(self, title, author=\"Jeremy\"):\n        self.title,self.author = title,author\n\nclass _ProductPage:\n    def __init__(self, page, price): self.page,self.price = page,price\n        \npage = _WebPage('Soap', author=\"Sylvain\")\np = _ProductPage(page, 15.0)\n\nHow do we make it so we can just write p.author, instead of p.page.author to access the author attribute? We can use GetAttr, of course! First, we subclass GetAttr when defining _ProductPage. Next, we set self.default to the object whose attributes we want to be able to access directly, which in this case is the page argument passed on initialization:\n\nclass _ProductPage(GetAttr):\n    def __init__(self, page, price): self.default,self.price = page,price #self.default allows you to access page directly.\n\np = _ProductPage(page, 15.0)\n\nNow, we can access the author attribute directly from the instance:\n\ntest_eq(p.author, 'Sylvain')\n\nIf you wish to store the object you are composing in an attribute other than self.default, you can set the class attribute _data as shown below. This is useful in the case where you might have a name collision with self.default:\n\nclass _C(GetAttr):\n    _default = '_data' # use different component name; `self._data` rather than `self.default`\n    def __init__(self,a): self._data = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t._data, 'Hi') \ntest_fail(lambda: t.default) # we no longer have self.default\ntest_eq(t.lower(), 'hi')\ntest_eq(t.upper(), 'HI')\nassert 'lower' in dir(t)\nassert 'upper' in dir(t)\n\nBy default, all attributes and methods of the object you are composing are retained. In the below example, we compose a str object with the class _C. This allows us to directly call string methods on instances of class _C, such as str.lower() or str.upper():\n\nclass _C(GetAttr):\n    # allow all attributes and methods to get passed to `self.default` (by leaving _xtra=None)\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t.lower(), 'hi')\ntest_eq(t.upper(), 'HI')\nassert 'lower' in dir(t)\nassert 'upper' in dir(t)\n\nHowever, you can choose which attributes or methods to retain by defining a class attribute _xtra, which is a list of allowed attribute and method names to delegate. In the below example, we only delegate the lower method from the composed str object when defining class _C:\n\nclass _C(GetAttr):\n    _xtra = ['lower'] # specify which attributes get passed to `self.default`\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t.default, 'Hi')\ntest_eq(t.lower(), 'hi')\ntest_fail(lambda: t.upper()) # upper wasn't in _xtra, so it isn't available to be called\nassert 'lower' in dir(t)\nassert 'upper' not in dir(t)\n\nYou must be careful to properly set an instance attribute in __init__ that corresponds to the class attribute _default. The below example sets the class attribute _default to data, but erroneously fails to define self.data (and instead defines self.default).\nFailing to properly set instance attributes leads to errors when you try to access methods directly:\n\nclass _C(GetAttr):\n    _default = 'data' # use a bad component name; i.e. self.data does not exist\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n        \n# TODO: should we raise an error when we create a new instance ...\nt = _C('Hi')\ntest_eq(t.default, 'Hi')\n# ... or is it enough for all GetAttr features to raise errors\ntest_fail(lambda: t.data)\ntest_fail(lambda: t.lower())\ntest_fail(lambda: t.upper())\ntest_fail(lambda: dir(t))\n\n\nsource\n\n\n\ndelegate_attr\n\n delegate_attr (k, to)\n\nUse in __getattr__ to delegate to attr to without inheriting from GetAttr\ndelegate_attr is a functional way to delegate attributes, and is an alternative to GetAttr. We recommend reading the documentation of GetAttr for more details around delegation.\nYou can use achieve delegation when you define __getattr__ by using delegate_attr:\n\nclass _C:\n    def __init__(self, o): self.o = o # self.o corresponds to the `to` argument in delegate_attr.\n    def __getattr__(self, k): return delegate_attr(self, k, to='o')\n    \n\nt = _C('HELLO') # delegates to a string\ntest_eq(t.lower(), 'hello')\n\nt = _C(np.array([5,4,3])) # delegates to a numpy array\ntest_eq(t.sum(), 12)\n\nt = _C(pd.DataFrame({'a': [1,2], 'b': [3,4]})) # delegates to a pandas.DataFrame\ntest_eq(t.b.max(), 4)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#extensible-types",
    "href": "basics.html#extensible-types",
    "title": "Basic functionality",
    "section": "Extensible Types",
    "text": "Extensible Types\nShowPrint is a base class that defines a show method, which is used primarily for callbacks in fastai that expect this method to be defined.\nInt, Float, and Str extend int, float and str respectively by adding an additional show method by inheriting from ShowPrint.\nThe code for Int is shown below:\nExamples:\n\nInt(0).show()\nFloat(2.0).show()\nStr('Hello').show()\n\n0\n2.0\nHello",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#collection-functions",
    "href": "basics.html#collection-functions",
    "title": "Basic functionality",
    "section": "Collection functions",
    "text": "Collection functions\nFunctions that manipulate popular python collections.\n\nsource\n\npartition\n\n partition (coll, f)\n\nPartition a collection by a predicate\n\nts,fs = partition(range(10), mod(2))\ntest_eq(fs, [0,2,4,6,8])\ntest_eq(ts, [1,3,5,7,9])\n\n\nsource\n\n\nflatten\n\n flatten (o)\n\nConcatenate all collections and items as a generator\n\nsource\n\n\nconcat\n\n concat (colls)\n\nConcatenate all collections and items as a list\n\nconcat([(o for o in range(2)),[2,3,4], 5])\n\n[0, 1, 2, 3, 4, 5]\n\n\n\nconcat([[\"abc\", \"xyz\"], [\"foo\", \"bar\"]])\n\n['abc', 'xyz', 'foo', 'bar']\n\n\n\nsource\n\n\nstrcat\n\n strcat (its, sep:str='')\n\nConcatenate stringified items its\n\ntest_eq(strcat(['a',2]), 'a2')\ntest_eq(strcat(['a',2], ';'), 'a;2')\n\n\nsource\n\n\ndetuplify\n\n detuplify (x)\n\nIf x is a tuple with one thing, extract it\n\ntest_eq(detuplify(()),None)\ntest_eq(detuplify([1]),1)\ntest_eq(detuplify([1,2]), [1,2])\ntest_eq(detuplify(np.array([[1,2]])), np.array([[1,2]]))\n\n\nsource\n\n\nreplicate\n\n replicate (item, match)\n\nCreate tuple of item copied len(match) times\n\nt = [1,1]\ntest_eq(replicate([1,2], t),([1,2],[1,2]))\ntest_eq(replicate(1, t),(1,1))\n\n\nsource\n\n\nsetify\n\n setify (o)\n\nTurn any list like-object into a set.\n\n# test\ntest_eq(setify(None),set())\ntest_eq(setify('abc'),{'abc'})\ntest_eq(setify([1,2,2]),{1,2})\ntest_eq(setify(range(0,3)),{0,1,2})\ntest_eq(setify({1,2}),{1,2})\n\n\nsource\n\n\nmerge\n\n merge (*ds)\n\nMerge all dictionaries in ds\n\ntest_eq(merge(), {})\ntest_eq(merge(dict(a=1,b=2)), dict(a=1,b=2))\ntest_eq(merge(dict(a=1,b=2), dict(b=3,c=4), None), dict(a=1, b=3, c=4))\n\n\nsource\n\n\nrange_of\n\n range_of (x)\n\nAll indices of collection x (i.e. list(range(len(x))))\n\ntest_eq(range_of([1,1,1,1]), [0,1,2,3])\n\n\nsource\n\n\ngroupby\n\n groupby (x, key, val=&lt;function noop&gt;)\n\nLike itertools.groupby but doesn’t need to be sorted, and isn’t lazy, plus some extensions\n\ntest_eq(groupby('aa ab bb'.split(), itemgetter(0)), {'a':['aa','ab'], 'b':['bb']})\n\nYou can use an int as key or val (which uses itemgetter; passing a str will use attrgetter), eg:\n\ntest_eq(groupby('aa ab bb'.split(), 0), {'a':['aa','ab'], 'b':['bb']})\n\n…and you can use a tuple as key or val (which creates a tuple from the provided keys or vals), eg:\n\ntest_eq(groupby('aaa abc bba'.split(), 0, (1,2)), {'a':[('a','a'),('b','c')], 'b':[('b','a')]})\n\nHere’s an example of how to invert a grouping, and using a val function:\n\nd = {0: [1, 3, 7], 2: [3], 3: [5], 4: [8], 5: [4], 7: [5]}\ngroupby(((o,k) for k,v in d.items() for o in v), 0, 1)\n\n{1: [0], 3: [0, 2], 7: [0], 5: [3, 7], 8: [4], 4: [5]}\n\n\n\nsource\n\n\nlast_index\n\n last_index (x, o)\n\nFinds the last index of occurence of x in o (returns -1 if no occurence)\n\ntest_eq(last_index(9, [1, 2, 9, 3, 4, 9, 10]), 5)\ntest_eq(last_index(6, [1, 2, 9, 3, 4, 9, 10]), -1)\n\n\nsource\n\n\nfilter_dict\n\n filter_dict (d, func)\n\nFilter a dict using func, applied to keys and values\n\nletters = {o:chr(o) for o in range(65,73)}\nletters\n\n{65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H'}\n\n\n\nfilter_dict(letters, lambda k,v: k&lt;67 or v in 'FG')\n\n{65: 'A', 66: 'B', 70: 'F', 71: 'G'}\n\n\n\nsource\n\n\nfilter_keys\n\n filter_keys (d, func)\n\nFilter a dict using func, applied to keys\n\nfilter_keys(letters, lt(67))\n\n{65: 'A', 66: 'B'}\n\n\n\nsource\n\n\nfilter_values\n\n filter_values (d, func)\n\nFilter a dict using func, applied to values\n\nfilter_values(letters, in_('FG'))\n\n{70: 'F', 71: 'G'}\n\n\n\nsource\n\n\ncycle\n\n cycle (o)\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\nzip_cycle\n\n zip_cycle (x, *args)\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\nsorted_ex\n\n sorted_ex (iterable, key=None, reverse=False, cmp=None, **kwargs)\n\nLike sorted, but if key is str use attrgetter; if int use itemgetter; use cmp comparator function or key with kwargs\nAttributes can be used for sorting by passing their name as a string:\n\nclass TestObj:\n    def __init__(self, x): self.x = x\nobjs = [TestObj(i) for i in [3,1,2]]\ntest_eq([o.x for o in sorted_ex(objs, 'x')], [1,2,3])\n\nTuple/list items can be sorted by index position:\n\nitems = [(1,'c'), (2,'b'), (3,'a')]\ntest_eq(sorted_ex(items, 1), [(3,'a'), (2,'b'), (1,'c')])\n\nA custom key function transforms values:\n\ntest_eq(sorted_ex([3,1,2], lambda x: -x), [3,2,1])\n\nYou can use a comparison function (returning -1/1/0):\n\ntest_eq(sorted_ex([3,1,2], cmp=lambda a,b: 1 if a&gt;b else -1 if a&lt;b else 0), [1,2,3])\n\nAdditional parameters can be passed to key/cmp functions:\n\ndef key_with_kwargs(x, offset=0): return x + offset\ntest_eq(sorted_ex([3,1,2], key=key_with_kwargs, offset=10), [1,2,3])\n\nReverse sort capability:\n\ntest_eq(sorted_ex([1,2,3], reverse=True), [3,2,1])\n\n\nsource\n\n\nnot_\n\n not_ (f)\n\nCreate new function that negates result of f\n\ndef f(a): return a&gt;0\ntest_eq(f(1),True)\ntest_eq(not_(f)(1),False)\ntest_eq(not_(f)(a=-1),True)\n\n\nsource\n\n\nargwhere\n\n argwhere (iterable, f, negate=False, **kwargs)\n\nLike filter_ex, but return indices for matching items\n\nsource\n\n\nfilter_ex\n\n filter_ex (iterable, f=&lt;function noop&gt;, negate=False, gen=False,\n            **kwargs)\n\nLike filter, but passing kwargs to f, defaulting f to noop, and adding negate and gen\n\nsource\n\n\nrange_of\n\n range_of (a, b=None, step=None)\n\nAll indices of collection a, if a is a collection, otherwise range\n\ntest_eq(range_of([1,1,1,1]), [0,1,2,3])\ntest_eq(range_of(4), [0,1,2,3])\n\n\nsource\n\n\nrenumerate\n\n renumerate (iterable, start=0)\n\nSame as enumerate, but returns index as 2nd element instead of 1st\n\ntest_eq(renumerate('abc'), (('a',0),('b',1),('c',2)))\n\n\nsource\n\n\nfirst\n\n first (x, f=None, negate=False, **kwargs)\n\nFirst element of x, optionally filtered by f, or None if missing\n\ntest_eq(first(['a', 'b', 'c', 'd', 'e']), 'a')\ntest_eq(first([False]), False)\ntest_eq(first([False], noop), None)\n\n\nsource\n\n\nlast\n\n last (x, f=None, negate=False, **kwargs)\n\nLast element of x, optionally filtered by f, or None if missing\n\ntest_eq(last(['a', 'b', 'c', 'd', 'e']), 'e')\ntest_eq(last([False]), False)\ntest_eq(last([False], noop), None)\n\n\nsource\n\n\nonly\n\n only (o)\n\nReturn the only item of o, raise if o doesn’t have exactly one item\n\nsource\n\n\nnested_attr\n\n nested_attr (o, attr, default=None)\n\nSame as getattr, but if attr includes a ., then looks inside nested objects\n\nclass CustomIndexable:\n    def __init__(self): self.data = {'a':1,'b':'v','c':{'d':5}}\n    def __getitem__(self, key): return self.data[key]\n\ncustom_indexable = CustomIndexable()\ntest_eq(nested_attr(custom_indexable,'a'),1)\ntest_eq(nested_attr(custom_indexable,'c.d'),5)\ntest_eq(nested_attr(custom_indexable,'e'),None)\n\nclass TestObj: def init(self): self.nested = {‘key’: [1, 2, {‘inner’: ‘value’}]} test_obj = TestObj()\ntest_eq(nested_attr(test_obj, ‘nested.key.2.inner’),‘value’) test_eq(nested_attr([1, 2, 3], ‘1’),2)\n\nb = {'a':1,'b':'v','c':{'d':5}}\ntest_eq(nested_attr(b,'b'),'v')\ntest_eq(nested_attr(b,'c.d'),5)\n\n\na = SimpleNamespace(b=(SimpleNamespace(c=1)))\ntest_eq(nested_attr(a, 'b.c'), getattr(getattr(a, 'b'), 'c'))\ntest_eq(nested_attr(a, 'b.d'), None)\ntest_eq(nested_attr(b, 'a'), 1)\n\n\nsource\n\n\nnested_setdefault\n\n nested_setdefault (o, attr, default)\n\nSame as setdefault, but if attr includes a ., then looks inside nested objects\n\nsource\n\n\nnested_callable\n\n nested_callable (o, attr)\n\nSame as nested_attr but if not found will return noop\n\na = SimpleNamespace(b=(SimpleNamespace(c=1)))\ntest_eq(nested_callable(a, 'b.c'), getattr(getattr(a, 'b'), 'c'))\ntest_eq(nested_callable(a, 'b.d'), noop)\n\n\nsource\n\n\nnested_idx\n\n nested_idx (coll, *idxs)\n\nIndex into nested collections, dicts, etc, with idxs\n\na = {'b':[1,{'c':2}]}\ntest_eq(nested_idx(a, 'nope'), None)\ntest_eq(nested_idx(a, 'nope', 'nup'), None)\ntest_eq(nested_idx(a, 'b', 3), None)\ntest_eq(nested_idx(a), a)\ntest_eq(nested_idx(a, 'b'), [1,{'c':2}])\ntest_eq(nested_idx(a, 'b', 1), {'c':2})\ntest_eq(nested_idx(a, 'b', 1, 'c'), 2)\n\n\na = SimpleNamespace(b=[1,{'c':2}])\ntest_eq(nested_idx(a, 'nope'), None)\ntest_eq(nested_idx(a, 'nope', 'nup'), None)\ntest_eq(nested_idx(a, 'b', 3), None)\ntest_eq(nested_idx(a), a)\ntest_eq(nested_idx(a, 'b'), [1,{'c':2}])\ntest_eq(nested_idx(a, 'b', 1), {'c':2})\ntest_eq(nested_idx(a, 'b', 1, 'c'), 2)\n\n\nsource\n\n\nset_nested_idx\n\n set_nested_idx (coll, value, *idxs)\n\nSet value indexed like `nested_idx\n\nset_nested_idx(a, 3, 'b', 0)\ntest_eq(nested_idx(a, 'b', 0), 3)\n\n\nsource\n\n\nval2idx\n\n val2idx (x)\n\nDict from value to index\n\ntest_eq(val2idx([1,2,3]), {3:2,1:0,2:1})\n\n\nsource\n\n\nuniqueify\n\n uniqueify (x, sort=False, bidir=False, start=None)\n\nUnique elements in x, optional sort, optional return reverse correspondence, optional prepend with elements.\n\nt = [1,1,0,5,0,3]\ntest_eq(uniqueify(t),[1,0,5,3])\ntest_eq(uniqueify(t, sort=True),[0,1,3,5])\ntest_eq(uniqueify(t, start=[7,8,6]), [7,8,6,1,0,5,3])\nv,o = uniqueify(t, bidir=True)\ntest_eq(v,[1,0,5,3])\ntest_eq(o,{1:0, 0: 1, 5: 2, 3: 3})\nv,o = uniqueify(t, sort=True, bidir=True)\ntest_eq(v,[0,1,3,5])\ntest_eq(o,{0:0, 1: 1, 3: 2, 5: 3})\n\n\nsource\n\n\nloop_first_last\n\n loop_first_last (values)\n\nIterate and generate a tuple with a flag for first and last value.\n\ntest_eq(loop_first_last(range(3)), [(True,False,0), (False,False,1), (False,True,2)])\n\n\nsource\n\n\nloop_first\n\n loop_first (values)\n\nIterate and generate a tuple with a flag for first value.\n\ntest_eq(loop_first(range(3)), [(True,0), (False,1), (False,2)])\n\n\nsource\n\n\nloop_last\n\n loop_last (values)\n\nIterate and generate a tuple with a flag for last value.\n\ntest_eq(loop_last(range(3)), [(False,0), (False,1), (True,2)])\n\n\nsource\n\n\nfirst_match\n\n first_match (lst, f, default=None)\n\nFirst element of lst matching predicate f, or default if none\n\na = [0,2,4,5,6,7,10]\ntest_eq(first_match(a, lambda o:o%2), 3)\n\n\nsource\n\n\nlast_match\n\n last_match (lst, f, default=None)\n\nLast element of lst matching predicate f, or default if none\n\ntest_eq(last_match(a, lambda o:o%2), 5)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#fastuple",
    "href": "basics.html#fastuple",
    "title": "Basic functionality",
    "section": "fastuple",
    "text": "fastuple\nA tuple with extended functionality.\n\nsource\n\nfastuple\n\n fastuple (x=None, *rest)\n\nA tuple with elementwise ops and more friendly init behavior\n\n\nFriendly init behavior\nCommon failure modes when trying to initialize a tuple in python:\ntuple(3)\n&gt; TypeError: 'int' object is not iterable\nor\ntuple(3, 4)\n&gt; TypeError: tuple expected at most 1 arguments, got 2\nHowever, fastuple allows you to define tuples like this and in the usual way:\n\ntest_eq(fastuple(3), (3,))\ntest_eq(fastuple(3,4), (3, 4))\ntest_eq(fastuple((3,4)), (3, 4))\n\n\n\nElementwise operations\n\nsource\n\nfastuple.add\n\n fastuple.add (*args)\n\n+ is already defined in tuple for concat, so use add instead\n\ntest_eq(fastuple.add((1,1),(2,2)), (3,3))\ntest_eq_type(fastuple(1,1).add(2), fastuple(3,3))\ntest_eq(fastuple('1','2').add('2'), fastuple('12','22'))\n\n\nsource\n\n\nfastuple.mul\n\n fastuple.mul (*args)\n\n* is already defined in tuple for replicating, so use mul instead\n\ntest_eq_type(fastuple(1,1).mul(2), fastuple(2,2))\n\n\n\n\nOther Elementwise Operations\nAdditionally, the following elementwise operations are available: - le: less than or equal - eq: equal - gt: greater than - min: minimum of\n\ntest_eq(fastuple(3,1).le(1), (False, True))\ntest_eq(fastuple(3,1).eq(1), (False, True))\ntest_eq(fastuple(3,1).gt(1), (True, False))\ntest_eq(fastuple(3,1).min(2), (2,1))\n\nYou can also do other elementwise operations like negate a fastuple, or subtract two fastuples:\n\ntest_eq(-fastuple(1,2), (-1,-2))\ntest_eq(~fastuple(1,0,1), (False,True,False))\n\ntest_eq(fastuple(1,1)-fastuple(2,2), (-1,-1))\n\n\ntest_eq(type(fastuple(1)), fastuple)\ntest_eq_type(fastuple(1,2), fastuple(1,2))\ntest_ne(fastuple(1,2), fastuple(1,3))\ntest_eq(fastuple(), ())",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#functions-on-functions",
    "href": "basics.html#functions-on-functions",
    "title": "Basic functionality",
    "section": "Functions on Functions",
    "text": "Functions on Functions\nUtilities for functional programming or for defining, modifying, or debugging functions.\n\nsource\n\nbind\n\n bind (func, *pargs, **pkwargs)\n\nSame as partial, except you can use arg0 arg1 etc param placeholders\nbind is the same as partial, but also allows you to reorder positional arguments using variable name(s) arg{i} where i refers to the zero-indexed positional argument. bind as implemented currently only supports reordering of up to the first 5 positional arguments.\nConsider the function myfunc below, which has 3 positional arguments. These arguments can be referenced as arg0, arg1, and arg1, respectively.\n\ndef myfn(a,b,c,d=1,e=2): return(a,b,c,d,e)\n\nIn the below example we bind the positional arguments of myfn as follows:\n\nThe second input 14, referenced by arg1, is substituted for the first positional argument.\nWe supply a default value of 17 for the second positional argument.\nThe first input 19, referenced by arg0, is subsituted for the third positional argument.\n\n\ntest_eq(bind(myfn, arg1, 17, arg0, e=3)(19,14), (14,17,19,1,3))\n\nIn this next example:\n\nWe set the default value to 17 for the first positional argument.\nThe first input 19 refrenced by arg0, becomes the second positional argument.\nThe second input 14 becomes the third positional argument.\nWe override the default the value for named argument e to 3.\n\n\ntest_eq(bind(myfn, 17, arg0, e=3)(19,14), (17,19,14,1,3))\n\nThis is an example of using bind like partial and do not reorder any arguments:\n\ntest_eq(bind(myfn)(17,19,14), (17,19,14,1,2))\n\nbind can also be used to change default values. In the below example, we use the first input 3 to override the default value of the named argument e, and supply default values for the first three positional arguments:\n\ntest_eq(bind(myfn, 17,19,14,e=arg0)(3), (17,19,14,1,3))\n\n\nsource\n\n\nmapt\n\n mapt (func, *iterables)\n\nTuplified map\n\nt = [0,1,2,3]\ntest_eq(mapt(operator.neg, t), (0,-1,-2,-3))\n\n\nsource\n\n\nmap_ex\n\n map_ex (iterable, f, *args, gen=False, **kwargs)\n\nLike map, but use bind, and supports str and indexing\n\ntest_eq(map_ex(t,operator.neg), [0,-1,-2,-3])\n\nIf f is a string then it is treated as a format string to create the mapping:\n\ntest_eq(map_ex(t, '#{}#'), ['#0#','#1#','#2#','#3#'])\n\nIf f is a dictionary (or anything supporting __getitem__) then it is indexed to create the mapping:\n\ntest_eq(map_ex(t, list('abcd')), list('abcd'))\n\nYou can also pass the same arg params that bind accepts:\n\ndef f(a=None,b=None): return b\ntest_eq(map_ex(t, f, b=arg0), range(4))\n\n\nsource\n\n\ncompose\n\n compose (*funcs, order=None)\n\nCreate a function that composes all functions in funcs, passing along remaining *args and **kwargs to all\n\nf1 = lambda o,p=0: (o*2)+p\nf2 = lambda o,p=1: (o+1)/p\ntest_eq(f2(f1(3)), compose(f1,f2)(3))\ntest_eq(f2(f1(3,p=3),p=3), compose(f1,f2)(3,p=3))\ntest_eq(f2(f1(3,  3),  3), compose(f1,f2)(3,  3))\n\nf1.order = 1\ntest_eq(f1(f2(3)), compose(f1,f2, order=\"order\")(3))\n\n\nsource\n\n\nmaps\n\n maps (*args, retain=&lt;function noop&gt;)\n\nLike map, except funcs are composed first\n\ntest_eq(maps([1]), [1])\ntest_eq(maps(operator.neg, [1,2]), [-1,-2])\ntest_eq(maps(operator.neg, operator.neg, [1,2]), [1,2])\n\n\nsource\n\n\npartialler\n\n partialler (f, *args, order=None, **kwargs)\n\nLike functools.partial but also copies over docstring\n\ndef _f(x,a=1):\n    \"test func\"\n    return x-a\n_f.order=1\n\nf = partialler(_f, 2)\ntest_eq(f.order, 1)\ntest_eq(f(3), -1)\nf = partialler(_f, a=2, order=3)\ntest_eq(f.__doc__, \"test func\")\ntest_eq(f.order, 3)\ntest_eq(f(3), _f(3,2))\n\n\nclass partial0:\n    \"Like `partialler`, but args passed to callable are inserted at started, instead of at end\"\n    def __init__(self, f, *args, order=None, **kwargs):\n        self.f,self.args,self.kwargs = f,args,kwargs\n        self.order = ifnone(order, getattr(f,'order',None))\n        self.__doc__ = f.__doc__\n\n    def __call__(self, *args, **kwargs): return self.f(*args, *self.args, **kwargs, **self.kwargs)\n\n\nf = partial0(_f, 2)\ntest_eq(f.order, 1)\ntest_eq(f(3), 1) # NB: different to `partialler` example\n\n\nsource\n\n\ninstantiate\n\n instantiate (t)\n\nInstantiate t if it’s a type, otherwise do nothing\n\ntest_eq_type(instantiate(int), 0)\ntest_eq_type(instantiate(1), 1)\n\n\nsource\n\n\nusing_attr\n\n using_attr (f, attr)\n\nConstruct a function which applies f to the argument’s attribute attr\n\nt = Path('/a/b.txt')\nf = using_attr(str.upper, 'name')\ntest_eq(f(t), 'B.TXT')\n\n\n\nSelf (with an uppercase S)\nA Concise Way To Create Lambdas\nThis is a concise way to create lambdas that are calling methods on an object (note the capitalization!)\nSelf.sum(), for instance, is a shortcut for lambda o: o.sum().\n\nf = Self.sum()\nx = np.array([3.,1])\ntest_eq(f(x), 4.)\n\n# This is equivalent to above\nf = lambda o: o.sum()\nx = np.array([3.,1])\ntest_eq(f(x), 4.)\n\nf = Self.argmin()\narr = np.array([1,2,3,4,5])\ntest_eq(f(arr), arr.argmin())\n\nf = Self.sum().is_integer()\nx = np.array([3.,1])\ntest_eq(f(x), True)\n\nf = Self.sum().real.is_integer()\nx = np.array([3.,1])\ntest_eq(f(x), True)\n\nf = Self.imag()\ntest_eq(f(3), 0)\n\nf = Self[1]\ntest_eq(f(x), 1)\n\nSelf is also callable, which creates a function which calls any function passed to it, using the arguments passed to Self:\n\ndef f(a, b=3): return a+b+2\ndef g(a, b=3): return a*b\nfg = Self(1,b=2)\nlist(map(fg, [f,g]))\n\n[5, 2]",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#patching",
    "href": "basics.html#patching",
    "title": "Basic functionality",
    "section": "Patching",
    "text": "Patching\n\nsource\n\ncopy_func\n\n copy_func (f)\n\nCopy a non-builtin function (NB copy.copy does not work for this)\nSometimes it may be desirable to make a copy of a function that doesn’t point to the original object. When you use Python’s built in copy.copy or copy.deepcopy to copy a function, you get a reference to the original object:\n\nimport copy as cp\n\n\ndef foo(): pass\na = cp.copy(foo)\nb = cp.deepcopy(foo)\n\na.someattr = 'hello' # since a and b point at the same object, updating a will update b\ntest_eq(b.someattr, 'hello')\n\nassert a is foo and b is foo\n\nHowever, with copy_func, you can retrieve a copy of a function without a reference to the original object:\n\nc = copy_func(foo) # c is an indpendent object\nassert c is not foo\n\n\ndef g(x, *, y=3): return x+y\ntest_eq(copy_func(g)(4), 7)\n\n\nsource\n\n\npatch_to\n\n patch_to (cls, as_prop=False, cls_method=False)\n\nDecorator: add f to cls\nThe @patch_to decorator allows you to monkey patch a function into a class as a method:\n\nclass _T3(int): pass  \n\n@patch_to(_T3)\ndef func1(self, a): return self+a\n\nt = _T3(1) # we initialized `t` to a type int = 1\ntest_eq(t.func1(2), 3) # we add 2 to `t`, so 2 + 1 = 3\n\nYou can access instance properties in the usual way via self:\n\nclass _T4():\n    def __init__(self, g): self.g = g\n        \n@patch_to(_T4)\ndef greet(self, x): return self.g + x\n        \nt = _T4('hello ') # this sets self.g = 'hello '\ntest_eq(t.greet('world'), 'hello world') #t.greet('world') will append 'world' to 'hello '\n\nYou can instead specify that the method should be a class method by setting cls_method=True:\n\nclass _T5(int): attr = 3 # attr is a class attribute we will access in a later method\n    \n@patch_to(_T5, cls_method=True)\ndef func(cls, x): return cls.attr + x # you can access class attributes in the normal way\n\ntest_eq(_T5.func(4), 7)\n\nAdditionally you can specify that the function you want to patch should be a class attribute with as_prop=True:\n\n@patch_to(_T5, as_prop=True)\ndef add_ten(self): return self + 10\n\nt = _T5(4)\ntest_eq(t.add_ten, 14)\n\nInstead of passing one class to the @patch_to decorator, you can pass multiple classes in a tuple to simulteanously patch more than one class with the same method:\n\nclass _T6(int): pass\nclass _T7(int): pass\n\n@patch_to((_T6,_T7))\ndef func_mult(self, a): return self*a\n\nt = _T6(2)\ntest_eq(t.func_mult(4), 8)\nt = _T7(2)\ntest_eq(t.func_mult(4), 8)\n\n\nsource\n\n\npatch\n\n patch (f=None, as_prop=False, cls_method=False)\n\nDecorator: add f to the first parameter’s class (based on f’s type annotations)\n@patch is an alternative to @patch_to that allows you similarly monkey patch class(es) by using type annotations:\n\nclass _T8(int): pass  \n\n@patch\ndef func(self:_T8, a): return self+a\n\nt = _T8(1)  # we initilized `t` to a type int = 1\ntest_eq(t.func(3), 4) # we add 3 to `t`, so 3 + 1 = 4\ntest_eq(t.func.__qualname__, '_T8.func')\n\nSimilarly to patch_to, you can supply a union of classes instead of a single class in your type annotations to patch multiple classes:\n\nclass _T9(int): pass \n\n@patch\ndef func2(x:_T8|_T9, a): return x*a # will patch both _T8 and _T9\n\nt = _T8(2)\ntest_eq(t.func2(4), 8)\ntest_eq(t.func2.__qualname__, '_T8.func2')\n\nt = _T9(2)\ntest_eq(t.func2(4), 8)\ntest_eq(t.func2.__qualname__, '_T9.func2')\n\nJust like patch_to decorator you can use as_prop and cls_method parameters with patch decorator:\n\n@patch(as_prop=True)\ndef add_ten(self:_T5): return self + 10\n\nt = _T5(4)\ntest_eq(t.add_ten, 14)\n\n\nclass _T5(int): attr = 3 # attr is a class attribute we will access in a later method\n    \n@patch(cls_method=True)\ndef func(cls:_T5, x): return cls.attr + x # you can access class attributes in the normal way\n\ntest_eq(_T5.func(4), 7)\n\n\nsource\n\n\npatch_property\n\n patch_property (f)\n\nDeprecated; use patch(as_prop=True) instead\nPatching classmethod shouldn’t affect how python’s inheritance works\n\nclass FastParent: pass\n\n@patch(cls_method=True)\ndef type_cls(cls: FastParent): return cls\n\nclass FastChild(FastParent): pass\n\nparent = FastParent()\ntest_eq(parent.type_cls(), FastParent)\n\nchild = FastChild()\ntest_eq(child.type_cls(), FastChild)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#other-helpers",
    "href": "basics.html#other-helpers",
    "title": "Basic functionality",
    "section": "Other Helpers",
    "text": "Other Helpers\n\nsource\n\ncompile_re\n\n compile_re (pat)\n\nCompile pat if it’s not None\n\nassert compile_re(None) is None\nassert compile_re('a').match('ab')\n\n\nsource\n\nImportEnum\n\n ImportEnum (value, names=None, module=None, qualname=None, type=None,\n             start=1)\n\nAn Enum that can have its values imported\n\n_T = ImportEnum('_T', {'foobar':1, 'goobar':2})\n_T.imports()\ntest_eq(foobar, _T.foobar)\ntest_eq(goobar, _T.goobar)\n\n\nsource\n\n\nStrEnum\n\n StrEnum (value, names=None, module=None, qualname=None, type=None,\n          start=1)\n\nAn ImportEnum that behaves like a str\n\nsource\n\n\n\nstr_enum\n\n str_enum (name, *vals)\n\nSimplified creation of StrEnum types\n\nsource\n\nValEnum\n\n ValEnum (value, names=None, module=None, qualname=None, type=None,\n          start=1)\n\nAn ImportEnum that stringifies using values\n\n_T = str_enum('_T', 'a', 'b')\ntest_eq(f'{_T.a}', 'a')\ntest_eq(_T.a, 'a')\ntest_eq(list(_T.__members__), ['a','b'])\nprint(_T.a, _T.a.upper())\n\na A\n\n\n\nsource\n\n\nStateful\n\n Stateful (*args, **kwargs)\n\nA base class/mixin for objects that should not serialize all their state\n\nclass _T(Stateful):\n    def __init__(self):\n        super().__init__()\n        self.a=1\n        self._state['test']=2\n\nt = _T()\nt2 = pickle.loads(pickle.dumps(t))\ntest_eq(t.a,1)\ntest_eq(t._state['test'],2)\ntest_eq(t2.a,1)\ntest_eq(t2._state,{})\n\nOverride _init_state to do any necessary setup steps that are required during __init__ or during deserialization (e.g. pickle.load). Here’s an example of how Stateful simplifies the official Python example for Handling Stateful Objects.\n\nclass TextReader(Stateful):\n    \"\"\"Print and number lines in a text file.\"\"\"\n    _stateattrs=('file',)\n    def __init__(self, filename):\n        self.filename,self.lineno = filename,0\n        super().__init__()\n\n    def readline(self):\n        self.lineno += 1\n        line = self.file.readline()\n        if line: return f\"{self.lineno}: {line.strip()}\"\n\n    def _init_state(self):\n        self.file = open(self.filename)\n        for _ in range(self.lineno): self.file.readline()\n\n\nreader = TextReader(\"00_test.ipynb\")\nprint(reader.readline())\nprint(reader.readline())\n\nnew_reader = pickle.loads(pickle.dumps(reader))\nprint(reader.readline())\n\n1: {\n2: \"cells\": [\n3: {\n\n\n\nsource\n\n\n\nNotStr\n\n NotStr (s)\n\nBehaves like a str, but isn’t an instance of one\n\ns = NotStr(\"hello\")\nassert not isinstance(s, str)\ntest_eq(s, 'hello')\ntest_eq(s*2, 'hellohello')\ntest_eq(len(s), 5)\n\n\nsource\n\nPrettyString\nLittle hack to get strings to show properly in Jupyter.\nAllow strings with special characters to render properly in Jupyter. Without calling print() strings with special characters are displayed like so:\n\nwith_special_chars='a string\\nwith\\nnew\\nlines and\\ttabs'\nwith_special_chars\n\n'a string\\nwith\\nnew\\nlines and\\ttabs'\n\n\nWe can correct this with PrettyString:\n\nPrettyString(with_special_chars)\n\na string\nwith\nnew\nlines and   tabs\n\n\n\nsource\n\n\n\neven_mults\n\n even_mults (start, stop, n)\n\nBuild log-stepped array from start to stop in n steps.\n\ntest_eq(even_mults(2,8,3), [2,4,8])\ntest_eq(even_mults(2,32,5), [2,4,8,16,32])\ntest_eq(even_mults(2,8,1), 8)\n\n\nsource\n\n\nnum_cpus\n\n num_cpus ()\n\nGet number of cpus\n\nnum_cpus()\n\n10\n\n\n\nsource\n\n\nadd_props\n\n add_props (f, g=None, n=2)\n\nCreate properties passing each of range(n) to f\n\nclass _T(): a,b = add_props(lambda i,x:i*2)\n\nt = _T()\ntest_eq(t.a,0)\ntest_eq(t.b,2)\n\n\nclass _T(): \n    def __init__(self, v): self.v=v\n    def _set(i, self, v): self.v[i] = v\n    a,b = add_props(lambda i,x: x.v[i], _set)\n\nt = _T([0,2])\ntest_eq(t.a,0)\ntest_eq(t.b,2)\nt.a = t.a+1\nt.b = 3\ntest_eq(t.a,1)\ntest_eq(t.b,3)\n\n\nsource\n\n\nstr2bool\n\n str2bool (s)\n\nCase-insensitive convert string s too a bool (y,yes,t,true,on,1-&gt;True)\nTrue values are ‘y’, ‘yes’, ‘t’, ‘true’, ‘on’, and ‘1’; false values are ‘n’, ‘no’, ‘f’, ‘false’, ‘off’, and ‘0’. Raises ValueError if ‘val’ is anything else.\n\nfor o in \"y YES t True on 1\".split(): assert str2bool(o)\nfor o in \"n no FALSE off 0\".split(): assert not str2bool(o)\nfor o in 0,None,'',False: assert not str2bool(o)\nfor o in 1,True: assert str2bool(o)\n\n\nsource\n\n\nstr2int\n\n str2int (s)\n\nConvert s to an int\n\nsource\n\n\nstr2float\n\n str2float (s:str)\n\nConvert s to a float\n\nsource\n\n\nstr2list\n\n str2list (s:str)\n\nConvert s to a list\n\nsource\n\n\nstr2date\n\n str2date (s:str)\n\ndate.fromisoformat with empty string handling\n\nsource\n\n\nto_date\n\n to_date (arg)\n\n\nsource\n\n\nto_list\n\n to_list (arg)\n\n\nsource\n\n\nto_float\n\n to_float (arg)\n\n\nsource\n\n\nto_int\n\n to_int (arg)\n\n\nsource\n\n\nto_bool\n\n to_bool (arg)\n\n\nsource\n\n\ntyped\n\n typed (_func=None, cast=False)\n\nDecorator to check param and return types at runtime, with optional casting\ntyped validates argument types at runtime. This is in contrast to MyPy which only offers static type checking.\nFor example, a TypeError will be raised if we try to pass an integer into the first argument of the below function:\n\n@typed\ndef discount(price:int, pct:float) -&gt; float:\n    return (1-pct) * price\n\nwith ExceptionExpected(TypeError): discount(100.0, .1)\n\nYou can have automatic casting based on heuristics by specifying typed(cast=True). If casting is not possible, a TypeError is raised.\n\n@typed(cast=True)\ndef discount(price:int, pct:float) -&gt; float:\n    return (1-pct) * price\n\nassert 90.0 == discount(100.5, .1) # will auto cast 100.5 to the int 100\nassert 90.0 == discount(' 100 ', .1) # will auto cast the str \"100\" to the int 100\nwith ExceptionExpected(TypeError): discount(\"a\", .1)\n\nWe can also optionally allow multiple types by enumarating the types in a tuple as illustrated below:\n\n@typed\ndef discount(price:int|float, pct:float): \n    return (1-pct) * price\n\nassert 90.0 == discount(100.0, .1)\n\n@typed(cast=True)\ndef discount(price:int|None, pct:float):\n    return (1-pct) * price\n\nassert 90.0 == discount(100.0, .1)\n\nWe currently do not support union types when casting.\n\n@typed(cast=True)\ndef discount(price:int|float, pct:float):\n    return (1-pct) * price\n\nwith ExceptionExpected(AssertionError): assert 90.0 == discount(\"100.0\", .1)\n\ntyped works with classes, too:\n\nclass Foo:\n    @typed\n    def __init__(self, a:int, b: int, c:str): pass\n    @typed(cast=True)\n    def test(cls, d:str): return d\n\nwith ExceptionExpected(TypeError): Foo(1, 2, 3) \nassert isinstance(Foo(1,2, 'a string').test(10), str)\n\nIt also works with custom types.\n\n@typed\ndef test_foo(foo: Foo): pass\n\nwith ExceptionExpected(TypeError): test_foo(1)\ntest_foo(Foo(1, 2, 'a string'))\n\n\nclass Bar:\n    @typed\n    def __init__(self, a:int): self.a = a\n@typed(cast=True)\ndef test_bar(bar: Bar): return bar\n\nassert isinstance(test_bar(1), Bar)\ntest_eq(test_bar(1).a, 1)\nwith ExceptionExpected(TypeError): test_bar(\"foobar\")\n\n\nsource\n\n\nexec_new\n\n exec_new (code)\n\nExecute code in a new environment and return it\n\ng = exec_new('a=1')\ntest_eq(g['a'], 1)\n\n\nsource\n\n\nexec_import\n\n exec_import (mod, sym)\n\nImport sym from mod in a new environment",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#notebook-functions",
    "href": "basics.html#notebook-functions",
    "title": "Basic functionality",
    "section": "Notebook functions",
    "text": "Notebook functions\n\n\nipython_shell\n\n ipython_shell ()\n\nSame as get_ipython but returns False if not in IPython\n\n\n\nin_ipython\n\n in_ipython ()\n\nCheck if code is running in some kind of IPython environment\n\n\n\nin_colab\n\n in_colab ()\n\nCheck if the code is running in Google Colaboratory\n\n\n\nin_jupyter\n\n in_jupyter ()\n\nCheck if the code is running in a jupyter notebook\n\n\n\nin_notebook\n\n in_notebook ()\n\nCheck if the code is running in a jupyter notebook\nThese variables are available as booleans in fastcore.basics as IN_IPYTHON, IN_JUPYTER, IN_COLAB and IN_NOTEBOOK.\n\nIN_IPYTHON, IN_JUPYTER, IN_COLAB, IN_NOTEBOOK\n\n(True, True, False, True)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "external.html",
    "href": "external.html",
    "title": "External modules",
    "section": "",
    "text": "fastcore includes functionality from some modules from other projects that have been copied here, in cases where the original is no longer maintained, or where the original includes dependencies that we’d rather avoid.",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "external.html#imghdr",
    "href": "external.html#imghdr",
    "title": "External modules",
    "section": "imghdr",
    "text": "imghdr\nfastcore includes a copy of the Python standard library’s imghdr module, which was deprecated in Python 3.11, and removed in 3.13. However since it’s still widely used (including within fastcore), we are providing it here. We have also added some fixes to the automatic detection.\n\nfrom fastcore.imghdr import what,tests\n\n\nwhat('images/puppy.jpg')\n\n'jpeg'\n\n\nThese are the tests provided:\n\nprint(', '.join(t.__name__ for t in tests))\n\ntest_jpeg, test_png, test_gif, test_tiff, test_rgb, test_pbm, test_pgm, test_ppm, test_rast, test_xbm, test_bmp, test_webp, test_exr",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "external.html#ansi",
    "href": "external.html#ansi",
    "title": "External modules",
    "section": "ansi",
    "text": "ansi\nnbconvert provides handy functionality to convert ansi terminal codes to HTML, which we’ve copied to fastcore so they can be used without nbconvert’s prequisites. Also nbconvert doesn’t document them, so we’re showing some examples here.\n\nfrom fastcore.ansi import ansi2html,strip_ansi\n\n\nansi_test = \"\"\"\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m\n\\x1b[0;31mZeroDivisionError\\x1b[0m                         Traceback (most recent call last)\nFile \\x1b[0;32m&lt;input-1&gt;:1\\x1b[0m\n\\x1b[0;32m----&gt; 1\\x1b[0m \\x1b[38;5;241m1\\x1b[39m\\x1b[38;5;241m/\\x1b[39m\\x1b[38;5;241m0\\x1b[39m\n\n\\x1b[0;31mZeroDivisionError\\x1b[0m: division by zero\"\"\"\n\n\nout = ansi2html(ansi_test)\nprint(out)\n\n&lt;span class=\"ansi-red-fg\"&gt;---------------------------------------------------------------------------&lt;/span&gt;\n&lt;span class=\"ansi-red-fg\"&gt;ZeroDivisionError&lt;/span&gt;                         Traceback (most recent call last)\nFile &lt;span class=\"ansi-green-fg\"&gt;&lt;input-1&gt;:1&lt;/span&gt;\n&lt;span class=\"ansi-green-fg\"&gt;----&gt; 1&lt;/span&gt; &lt;span style=\"color: rgb(98,98,98)\"&gt;1&lt;/span&gt;&lt;span style=\"color: rgb(98,98,98)\"&gt;/&lt;/span&gt;&lt;span style=\"color: rgb(98,98,98)\"&gt;0&lt;/span&gt;\n\n&lt;span class=\"ansi-red-fg\"&gt;ZeroDivisionError&lt;/span&gt;: division by zero\n\n\n\ntest_err = ''.join([f\"&lt;div&gt;{o}&lt;/div&gt;\" for o in out.splitlines()])\nHTML(f'&lt;pre&gt;{test_err}&lt;pre&gt;')\n\n---------------------------------------------------------------------------ZeroDivisionError                         Traceback (most recent call last)File &lt;input-1&gt;:1----&gt; 1 1/0ZeroDivisionError: division by zero\n\n\nprint(strip_ansi(ansi_test))\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nFile &lt;ipython-input-1-9e1622b385b6&gt;:1\n----&gt; 1 1/0\n\nZeroDivisionError: division by zero",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "py2pyi.html#basics",
    "href": "py2pyi.html#basics",
    "title": "Create delegated pyi",
    "section": "Basics",
    "text": "Basics\n\nsource\n\nimp_mod\n\n imp_mod (module_path, package=None)\n\nImport dynamically the module referenced in fn\n\nfn = Path('test_py2pyi.py')\n\n\nmod = imp_mod(fn)\na = mod.A()\na.h()\n\n1\n\n\n\ntree = _get_tree(mod)\n\n\n\n\nAST.__repr__\n\n AST.__repr__ ()\n\n\n# for o in enumerate(tree.body): print(o)\n\n\nnode = tree.body[4]\nnode\n\ndef f(a: int, b: str='a') -&gt; str:\n    \"\"\"I am f\"\"\"\n    return 1\n\n\n\nisinstance(node, functypes)\n\nTrue\n\n\n\nsource\n\n\nhas_deco\n\n has_deco (node:Union[ast.FunctionDef,ast.AsyncFunctionDef], name:str)\n\nCheck if a function node node has a decorator named name\n\nnm = 'delegates'\nhas_deco(node, nm)\n\nFalse\n\n\n\nnode = tree.body[5]\nnode\n\n@delegates(f)\ndef g(c, d: X, **kwargs) -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\nhas_deco(node, nm)\n\nTrue",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#function-processing",
    "href": "py2pyi.html#function-processing",
    "title": "Create delegated pyi",
    "section": "Function processing",
    "text": "Function processing\n\ndef _proc_body   (node, mod): print('_proc_body', type(node))\ndef _proc_func   (node, mod): print('_proc_func', type(node))\ndef _proc_class  (node, mod): print('_proc_class', type(node))\ndef _proc_patched(node, mod): print('_proc_patched', type(node))\n\n\nparent_node = copy.deepcopy(tree.body[7])\npatched_node = copy.deepcopy(tree.body[10])\ntest_is(has_deco(patched_node, \"patch\"), True)\ntest_eq(str(patched_node.args.args[0].annotation), parent_node.name)\n\n_clean_patched_node(patched_node)\ntest_is(has_deco(patched_node, \"patch\"), False)\ntest_eq(patched_node.args.args[0].annotation, None)\n\n\nempty_cls1, empty_cls2, empty_cls3 = ast.parse('''\nclass A: \n    \"\"\"An empty class.\"\"\"\nclass B: \n    pass\nclass C: \n    ...\n''').body\n\ntest_is(_is_empty_class(empty_cls1), True)\ntest_is(_is_empty_class(empty_cls2), True)\ntest_is(_is_empty_class(empty_cls3), True)\n\nnon_empty_cls, empty_func = ast.parse('''\nclass A: \n    a = 1\ndef f():\n    ...\n''').body\ntest_is(_is_empty_class(non_empty_cls), False)\ntest_is(_is_empty_class(empty_func), False)\n\n\n# we could have reused `parent_node` and `patched_node` from the previous cells.\n# copying them here allows us to run this cell multiple times which makes it a little easier to write tests.\n\nparent_node = copy.deepcopy(tree.body[7])\npatched_node = copy.deepcopy(tree.body[11])\ntest_eq(len(parent_node.body),1)\n_add_patched_node_to_parent(patched_node, parent_node)\ntest_eq(len(parent_node.body),2)\ntest_eq(parent_node.body[-1], patched_node)\n\n# patched node replaces an existing class method (A.h)\npatched_h_node = ast.parse(\"\"\"\n@patch\ndef h(self: A, *args, **kwargs):\n    ...\n\"\"\", mode='single').body[0]\n\n_add_patched_node_to_parent(patched_h_node, parent_node)\ntest_eq(len(parent_node.body), 2)\ntest_eq(parent_node.body[0], patched_h_node)\n\n# patched node is added to an empty class\nempty_cls, patched_node = ast.parse('''\nclass Z: \n    \"\"\"An empty class.\"\"\"\n\n@patch\ndef a(self: Z, *args, **kwargs):\n    ...\n''').body\n\ntest_eq(len(empty_cls.body), 1)\ntest_ne(empty_cls.body[0], patched_node)\n_add_patched_node_to_parent(patched_node, empty_cls)\ntest_eq(len(empty_cls.body), 1)\ntest_eq(empty_cls.body[0], patched_node)\n\n\nraw_tree = _get_tree(mod)\nprocessed_tree = _proc_mod(mod)\nn_raw_tree_nodes = len(raw_tree.body)\n# mod contains 3 patch methods so our processed_tree should have 3 less nodes \ntest_eq(len(processed_tree.body), n_raw_tree_nodes-3)\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_func &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n\n\n\n_proc_mod(mod);\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_func &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n\n\n\nnode.name\n\n'g'\n\n\n\nsym = getattr(mod, node.name)\nsym\n\n&lt;function test_py2pyi.g(c, d: test_py2pyi.X, *, b: str = 'a') -&gt; str&gt;\n\n\n\nsig = signature(sym)\nprint(sig)\n\n(c, d: test_py2pyi.X, *, b: str = 'a') -&gt; str\n\n\n\nsource\n\nsig2str\n\n sig2str (sig)\n\n\nsource\n\n\nast_args\n\n ast_args (func)\n\n\nnewargs = ast_args(sym)\nnewargs\n\nc, d: test_py2pyi.X, *, b: str='a'\n\n\n\nnode.args\n\nc, d: X, **kwargs\n\n\n\nnode.args = newargs\nnode\n\n@delegates(f)\ndef g(c, d: test_py2pyi.X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\n_body_ellip(node)\nnode\n\n@delegates(f)\ndef g(c, d: test_py2pyi.X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...\n\n\n\ntree = _get_tree(mod)\nnode = tree.body[5]\nnode\n\n@delegates(f)\ndef g(c, d: X, **kwargs) -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\n_update_func(node, sym)\nnode\n\ndef g(c, d: X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...\n\n\n\ntree = _proc_mod(mod)\ntree.body[5]\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n\n\ndef g(c, d: X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#patch",
    "href": "py2pyi.html#patch",
    "title": "Create delegated pyi",
    "section": "Patch",
    "text": "Patch\n\ntree = _get_tree(mod)\nnode = tree.body[9]\nnode\n\n@patch\n@delegates(j)\ndef k(self: (A, B), b: bool=False, **kwargs):\n    return 1\n\n\n\nann = node.args.args[0].annotation\n\n\nif hasattr(ann, 'elts'): ann = ann.elts[0]\n\n\nnm = ann.id\nnm\n\n'A'\n\n\n\ncls = getattr(mod, nm)\nsym = getattr(cls, node.name)\n\n\nsig2str(signature(sym))\n\n\"(self: (test_py2pyi.A, test_py2pyi.B), b: bool = False, *, d: str = 'a')\"\n\n\n\n_update_func(node, sym)\n\n\nnode\n\n@patch\ndef k(self: (A, B), b: bool=False, *, d: str='a'):\n    ...\n\n\n\ntree = _get_tree(mod)\ntree.body[9]\n\n@patch\n@delegates(j)\ndef k(self: (A, B), b: bool=False, **kwargs):\n    return 1",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#class-and-file",
    "href": "py2pyi.html#class-and-file",
    "title": "Create delegated pyi",
    "section": "Class and file",
    "text": "Class and file\n\ntree = _get_tree(mod)\nnode = tree.body[7]\nnode\n\nclass A:\n\n    @delegates(j)\n    def h(self, b: bool=False, **kwargs):\n        a = 1\n        return a\n\n\n\nnode.body\n\n[@delegates(j)\n def h(self, b: bool=False, **kwargs):\n     a = 1\n     return a]\n\n\n\ntree = _proc_mod(mod)\ntree.body[7]\n\nclass A:\n\n    def h(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def k(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def m(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def n(self, b: bool=False, **kwargs):\n        \"\"\"No delegates here mmm'k?\"\"\"\n        ...\n\n\n\nsource\n\ncreate_pyi\n\n create_pyi (fn, package=None)\n\nConvert fname.py to fname.pyi by removing function bodies and expanding delegates kwargs\n\ncreate_pyi(fn)\n\n\n# fn = Path('/Users/jhoward/git/fastcore/fastcore/docments.py')\n# create_pyi(fn, 'fastcore')",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#script",
    "href": "py2pyi.html#script",
    "title": "Create delegated pyi",
    "section": "Script",
    "text": "Script\n\nsource\n\npy2pyi\n\n py2pyi (fname:str, package:str=None)\n\nConvert fname.py to fname.pyi by removing function bodies and expanding delegates kwargs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\n\nThe file name to convert\n\n\npackage\nstr\nNone\nThe parent package\n\n\n\n\nsource\n\n\nreplace_wildcards\n\n replace_wildcards (path:str)\n\nExpand wildcard imports in the specified Python file.\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr\nPath to the Python file to process",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test",
    "section": "",
    "text": "We can check that code raises an exception when that’s expected (test_fail).\nTo test for equality or inequality (with different types of things) we define a simple function test that compares two objects with a given cmp operator.\n\nsource\n\n\n\n test_fail (f, msg='', contains='', args=None, kwargs=None)\n\nFails with msg unless f() raises an exception and (optionally) has contains in e.args\n\ndef _fail(): raise Exception(\"foobar\")\ntest_fail(_fail, contains=\"foo\")\n\ndef _fail(): raise Exception()\ntest_fail(_fail)\n\nWe can also pass args and kwargs to function to check if it fails with special inputs.\n\ndef _fail_args(a):\n    if a == 5:\n        raise ValueError\ntest_fail(_fail_args, args=(5,))\ntest_fail(_fail_args, kwargs=dict(a=5))\n\n\nsource\n\n\n\n\n test (a, b, cmp, cname=None)\n\nassert that cmp(a,b); display inputs and cname or cmp.__name__ if it fails\n\ntest([1,2],[1,2], operator.eq)\ntest_fail(lambda: test([1,2],[1], operator.eq))\ntest([1,2],[1],   operator.ne)\ntest_fail(lambda: test([1,2],[1,2], operator.ne))\n\n\n\n\n\n\n all_equal (a, b)\n\nCompares whether a and b are the same length and have the same contents\n\ntest(['abc'], ['abc'], all_equal)\ntest_fail(lambda: test(['abc'],['cab'], all_equal))\n\n\n\n\n\n\n equals (a, b)\n\nCompares a and b for equality; supports sublists, tensors and arrays too\n\ntest([['abc'],['a']], [['abc'],['a']],  equals)\ntest([['abc'],['a'],'b', [['x']]], [['abc'],['a'],'b', [['x']]],  equals) # supports any depth and nested structure\n\n\nsource\n\n\n\n\n nequals (a, b)\n\nCompares a and b for not equals\n\ntest(['abc'], ['ab' ], nequals)",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "test.html#simple-test-functions",
    "href": "test.html#simple-test-functions",
    "title": "Test",
    "section": "",
    "text": "We can check that code raises an exception when that’s expected (test_fail).\nTo test for equality or inequality (with different types of things) we define a simple function test that compares two objects with a given cmp operator.\n\nsource\n\n\n\n test_fail (f, msg='', contains='', args=None, kwargs=None)\n\nFails with msg unless f() raises an exception and (optionally) has contains in e.args\n\ndef _fail(): raise Exception(\"foobar\")\ntest_fail(_fail, contains=\"foo\")\n\ndef _fail(): raise Exception()\ntest_fail(_fail)\n\nWe can also pass args and kwargs to function to check if it fails with special inputs.\n\ndef _fail_args(a):\n    if a == 5:\n        raise ValueError\ntest_fail(_fail_args, args=(5,))\ntest_fail(_fail_args, kwargs=dict(a=5))\n\n\nsource\n\n\n\n\n test (a, b, cmp, cname=None)\n\nassert that cmp(a,b); display inputs and cname or cmp.__name__ if it fails\n\ntest([1,2],[1,2], operator.eq)\ntest_fail(lambda: test([1,2],[1], operator.eq))\ntest([1,2],[1],   operator.ne)\ntest_fail(lambda: test([1,2],[1,2], operator.ne))\n\n\n\n\n\n\n all_equal (a, b)\n\nCompares whether a and b are the same length and have the same contents\n\ntest(['abc'], ['abc'], all_equal)\ntest_fail(lambda: test(['abc'],['cab'], all_equal))\n\n\n\n\n\n\n equals (a, b)\n\nCompares a and b for equality; supports sublists, tensors and arrays too\n\ntest([['abc'],['a']], [['abc'],['a']],  equals)\ntest([['abc'],['a'],'b', [['x']]], [['abc'],['a'],'b', [['x']]],  equals) # supports any depth and nested structure\n\n\nsource\n\n\n\n\n nequals (a, b)\n\nCompares a and b for not equals\n\ntest(['abc'], ['ab' ], nequals)",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "test.html#test_eq-test_ne-etc",
    "href": "test.html#test_eq-test_ne-etc",
    "title": "Test",
    "section": "test_eq test_ne, etc…",
    "text": "test_eq test_ne, etc…\nJust use test_eq/test_ne to test for ==/!=. test_eq_type checks things are equal and of the same type. We define them using test:\n\nsource\n\ntest_eq\n\n test_eq (a, b)\n\ntest that a==b\n\ntest_eq([1,2],[1,2])\ntest_eq([1,2],map(int,[1,2]))\ntest_eq(array([1,2]),array([1,2]))\ntest_eq(array([1,2]),array([1,2]))\ntest_eq([array([1,2]),3],[array([1,2]),3])\ntest_eq(dict(a=1,b=2), dict(b=2,a=1))\ntest_fail(lambda: test_eq([1,2], 1), contains=\"==\")\ntest_fail(lambda: test_eq(None, np.array([1,2])), contains=\"==\")\ntest_eq({'a', 'b', 'c'}, {'c', 'a', 'b'})\n\n\ndf1 = pd.DataFrame(dict(a=[1,2],b=['a','b']))\ndf2 = pd.DataFrame(dict(a=[1,2],b=['a','b']))\ndf3 = pd.DataFrame(dict(a=[1,2],b=['a','c']))\n\ntest_eq(df1,df2)\ntest_eq(df1.a,df2.a)\ntest_fail(lambda: test_eq(df1,df3), contains='==')\nclass T(pd.Series): pass\ntest_eq(df1.iloc[0], T(df2.iloc[0])) # works with subclasses\n\n\ntest_eq(torch.zeros(10), torch.zeros(10, dtype=torch.float64))\ntest_eq(torch.zeros(10), torch.ones(10)-1)\ntest_fail(lambda:test_eq(torch.zeros(10), torch.ones(1, 10)), contains='==')\ntest_eq(torch.zeros(3), [0,0,0])\n\n\nsource\n\n\ntest_eq_type\n\n test_eq_type (a, b)\n\ntest that a==b and are same type\n\ntest_eq_type(1,1)\ntest_fail(lambda: test_eq_type(1,1.))\ntest_eq_type([1,1],[1,1])\ntest_fail(lambda: test_eq_type([1,1],(1,1)))\ntest_fail(lambda: test_eq_type([1,1],[1,1.]))\n\n\nsource\n\n\ntest_ne\n\n test_ne (a, b)\n\ntest that a!=b\n\ntest_ne([1,2],[1])\ntest_ne([1,2],[1,3])\ntest_ne(array([1,2]),array([1,1]))\ntest_ne(array([1,2]),array([1,1]))\ntest_ne([array([1,2]),3],[array([1,2])])\ntest_ne([3,4],array([3]))\ntest_ne([3,4],array([3,5]))\ntest_ne(dict(a=1,b=2), ['a', 'b'])\ntest_ne(['a', 'b'], dict(a=1,b=2))\n\n\nsource\n\n\nis_close\n\n is_close (a, b, eps=1e-05)\n\nIs a within eps of b\n\nsource\n\n\ntest_close\n\n test_close (a, b, eps=1e-05)\n\ntest that a is within eps of b\n\ntest_close(1,1.001,eps=1e-2)\ntest_fail(lambda: test_close(1,1.001))\ntest_close([-0.001,1.001], [0.,1.], eps=1e-2)\ntest_close(np.array([-0.001,1.001]), np.array([0.,1.]), eps=1e-2)\ntest_close(array([-0.001,1.001]), array([0.,1.]), eps=1e-2)\n\n\nsource\n\n\ntest_is\n\n test_is (a, b)\n\ntest that a is b\n\ntest_fail(lambda: test_is([1], [1]))\na = [1]\ntest_is(a, a)\nb = [2]; test_fail(lambda: test_is(a, b))\n\n\nsource\n\n\ntest_shuffled\n\n test_shuffled (a, b)\n\ntest that a and b are shuffled versions of the same sequence of items\n\na = list(range(50))\nb = copy(a)\nrandom.shuffle(b)\ntest_shuffled(a,b)\ntest_fail(lambda:test_shuffled(a,a))\n\n\na = 'abc'\nb = 'abcabc'\ntest_fail(lambda:test_shuffled(a,b))\n\n\na = ['a', 42, True] \nb = [42, True, 'a']\ntest_shuffled(a,b)\n\n\nsource\n\n\ntest_stdout\n\n test_stdout (f, exp, regex=False)\n\nTest that f prints exp to stdout, optionally checking as regex\n\ntest_stdout(lambda: print('hi'), 'hi')\ntest_fail(lambda: test_stdout(lambda: print('hi'), 'ho'))\ntest_stdout(lambda: 1+1, '')\ntest_stdout(lambda: print('hi there!'), r'^hi.*!$', regex=True)\n\n\nsource\n\n\ntest_warns\n\n test_warns (f, show=False)\n\n\ntest_warns(lambda: warnings.warn(\"Oh no!\"))\ntest_fail(lambda: test_warns(lambda: 2+2), contains='No warnings raised')\n\n\ntest_warns(lambda: warnings.warn(\"Oh no!\"), show=True)\n\n&lt;class 'UserWarning'&gt;: Oh no!\n\n\n\nim = Image.open(TEST_IMAGE).resize((128,128)); im\n\n\n\n\n\n\n\n\n\nim = Image.open(TEST_IMAGE_BW).resize((128,128)); im\n\n\n\n\n\n\n\n\n\nsource\n\n\ntest_fig_exists\n\n test_fig_exists (ax)\n\nTest there is a figure displayed in ax\n\nfig,ax = plt.subplots()\nax.imshow(array(im));\n\n\n\n\n\n\n\n\n\ntest_fig_exists(ax)\n\n\nsource\n\n\nExceptionExpected\n\n ExceptionExpected (ex=&lt;class 'Exception'&gt;, regex='')\n\nContext manager that tests if an exception is raised\n\ndef _tst_1(): assert False, \"This is a test\"\ndef _tst_2(): raise SyntaxError\n\nwith ExceptionExpected(): _tst_1()\nwith ExceptionExpected(ex=AssertionError, regex=\"This is a test\"): _tst_1()\nwith ExceptionExpected(ex=SyntaxError): _tst_2()\n\nexception is an abbreviation for ExceptionExpected().\n\nwith exception: _tst_1()",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "script.html",
    "href": "script.html",
    "title": "Script - CLI",
    "section": "",
    "text": "Part of fast.ai’s toolkit for delightful developer experiences.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#overview",
    "href": "script.html#overview",
    "title": "Script - CLI",
    "section": "Overview",
    "text": "Overview\nSometimes, you want to create a quick script, either for yourself, or for others. But in Python, that involves a whole lot of boilerplate and ceremony, especially if you want to support command line arguments, provide help, and other niceties. You can use argparse for this purpose, which comes with Python, but it’s complex and verbose.\nfastcore.script makes life easier. There are much fancier modules to help you write scripts (we recommend Python Fire, and Click is also popular), but fastcore.script is very fast and very simple. In fact, it’s &lt;50 lines of code! Basically, it’s just a little wrapper around argparse that uses modern Python features and some thoughtful defaults to get rid of the boilerplate.\nFor full details, see the docs for core.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#example",
    "href": "script.html#example",
    "title": "Script - CLI",
    "section": "Example",
    "text": "Example\nHere’s a complete example (available in examples/test_fastcore.py):\nfrom fastcore.script import *\n@call_parse\ndef main(msg:str,     # The message\n         upper:bool): # Convert to uppercase?\n    \"Print `msg`, optionally converting to uppercase\"\n    print(msg.upper() if upper else msg)\nIf you copy that info a file and run it, you’ll see:\n$ examples/test_fastcore.py --help\nusage: test_fastcore.py [-h] [--upper] msg\n\nPrint `msg`, optionally converting to uppercase\n\npositional arguments:\n  msg          The message\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --upper      Convert to uppercase? (default: False)\nAs you see, we didn’t need any if __name__ == \"__main__\", we didn’t have to parse arguments, we just wrote a function, added a decorator to it, and added some annotations to our function’s parameters. As a bonus, we can also use this function directly from a REPL such as Jupyter Notebook - it’s not just for command line scripts!\nYou should provide a default (after the =) for any optional parameters. If you don’t provide a default for a parameter, then it will be a positional parameter.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#param-annotations",
    "href": "script.html#param-annotations",
    "title": "Script - CLI",
    "section": "Param annotations",
    "text": "Param annotations\nIf you want to use the full power of argparse, you can do so by using Param annotations instead of type annotations and docments, like so:\nfrom fastcore.script import *\n@call_parse\ndef main(msg:Param(\"The message\", str),\n         upper:Param(\"Convert to uppercase?\", store_true)):\n    \"Print `msg`, optionally converting to uppercase\"\n    print(msg.upper() if upper else msg)\nIf you use this approach, then each parameter in your function should have an annotation Param(...) (as in the example above). You can pass the following when calling Param: help,type,opt,action,nargs,const,choices,required . Except for opt, all of these are just passed directly to argparse, so you have all the power of that module at your disposal. Generally you’ll want to pass at least help (since this is provided as the help string for that parameter) and type (to ensure that you get the type of data you expect). opt is a bool that defines whether a param is optional or required (positional) - but you’ll generally not need to set this manually, because fastcore.script will set it for you automatically based on default values.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#setuptools-scripts",
    "href": "script.html#setuptools-scripts",
    "title": "Script - CLI",
    "section": "setuptools scripts",
    "text": "setuptools scripts\nThere’s a really nice feature of pip/setuptools that lets you create commandline scripts directly from functions, makes them available in the PATH, and even makes your scripts cross-platform (e.g. in Windows it creates an exe). fastcore.script supports this feature too. The trick to making a function available as a script is to add a console_scripts section to your setup file, of the form: script_name=module:function_name. E.g. in this case we use: test_fastcore.script=fastcore.script.test_cli:main. With this, you can then just type test_fastcore.script at any time, from any directory, and your script will be called (once it’s installed using one of the methods below).\nYou don’t actually have to write a setup.py yourself. Instead, just use nbdev. Then modify settings.ini as appropriate for your module/script. To install your script directly, you can type pip install -e .. Your script, when installed this way (it’s called an editable install), will automatically be up to date even if you edit it - there’s no need to reinstall it after editing. With nbdev you can even make your module and script available for installation directly from pip and conda by running make release.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#api-details",
    "href": "script.html#api-details",
    "title": "Script - CLI",
    "section": "API details",
    "text": "API details\n\nsource\n\nstore_true\n\n store_true ()\n\nPlaceholder to pass to Param for store_true action\n\nsource\n\n\nstore_false\n\n store_false ()\n\nPlaceholder to pass to Param for store_false action\n\nsource\n\n\nbool_arg\n\n bool_arg (v)\n\nUse as type for Param to get bool behavior\n\nsource\n\n\nclean_type_str\n\n clean_type_str (x:str)\n\n\nclass Test: pass\n\ntest_eq(clean_type_str(argparse.ArgumentParser), 'argparse.ArgumentParser')\ntest_eq(clean_type_str(Test), 'Test')\ntest_eq(clean_type_str(int), 'int')\ntest_eq(clean_type_str(float), 'float')\ntest_eq(clean_type_str(store_false), 'store_false')\n\n\nsource\n\n\nParam\n\n Param (help='', type=None, opt=True, action=None, nargs=None, const=None,\n        choices=None, required=None, default=None)\n\nA parameter in a function used in anno_parser or call_parse\n\ntest_eq(repr(Param(\"Help goes here\")), '&lt;Help goes here&gt;')\ntest_eq(repr(Param(\"Help\", int)), 'int &lt;Help&gt;')\ntest_eq(repr(Param(help=None, type=int)), 'int')\ntest_eq(repr(Param(help=None, type=None)), '')\n\nEach parameter in your function should have an annotation Param(...). You can pass the following when calling Param: help,type,opt,action,nargs,const,choices,required (i.e. it takes the same parameters as argparse.ArgumentParser.add_argument, plus opt). Except for opt, all of these are just passed directly to argparse, so you have all the power of that module at your disposal. Generally you’ll want to pass at least help (since this is provided as the help string for that parameter) and type (to ensure that you get the type of data you expect).\nopt is a bool that defines whether a param is optional or required (positional) - but you’ll generally not need to set this manually, because fastcore.script will set it for you automatically based on default values. You should provide a default (after the =) for any optional parameters. If you don’t provide a default for a parameter, then it will be a positional parameter.\nParam’s __repr__ also allows for more informative function annotation when looking up the function’s doc using shift+tab. You see the type annotation (if there is one) and the accompanying help documentation with it.\n\ndef f(required:Param(\"Required param\", int),\n      a:Param(\"param 1\", bool_arg),\n      b:Param(\"param 2\", str)=\"test\"):\n    \"my docs\"\n    ...\n\n\nhelp(f)\n\nHelp on function f in module __main__:\n\nf(required: int &lt;Required param&gt;, a: bool_arg &lt;param 1&gt;, b: str &lt;param 2&gt; = 'test')\n    my docs\n\n\n\n\np = Param(help=\"help\", type=int)\np.set_default(1)\ntest_eq(p.kwargs, {'help': 'help (default: 1)', 'type': int, 'default': 1})\n\n\nsource\n\n\nanno_parser\n\n anno_parser (func, prog:str=None)\n\nLook at params (annotated with Param) in func and return an ArgumentParser\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfunc\n\n\nFunction to get arguments from\n\n\nprog\nstr\nNone\nThe name of the program\n\n\n\nThis converts a function with parameter annotations of type Param into an argparse.ArgumentParser object. Function arguments with a default provided are optional, and other arguments are positional.\n\n_en = str_enum('_en', 'aa','bb','cc')\ndef f(required:Param(\"Required param\", int),\n      a:Param(\"param 1\", bool_arg),\n      b:Param(\"param 2\", str)=\"test\",\n      c:Param(\"param 3\", _en)=_en.aa):\n    \"my docs\"\n    ...\n\np = anno_parser(f, 'progname')\np.print_help()\n\nusage: progname [-h] [--b B] [--c {aa,bb,cc}] required a\n\nmy docs\n\npositional arguments:\n  required        Required param\n  a               param 1\n\noptional arguments:\n  -h, --help      show this help message and exit\n  --b B           param 2 (default: test)\n  --c {aa,bb,cc}  param 3 (default: aa)\n\n\nIt also works with type annotations and docments:\n\ndef g(required:int,  # Required param\n      a:bool_arg,    # param 1\n      b=\"test\",      # param 2\n      c:_en=_en.aa): # param 3\n    \"my docs\"\n    ...\n\np = anno_parser(g, 'progname')\np.print_help()\n\nusage: progname [-h] [--b B] [--c {aa,bb,cc}] required a\n\nmy docs\n\npositional arguments:\n  required        Required param\n  a               param 1\n\noptional arguments:\n  -h, --help      show this help message and exit\n  --b B           param 2 (default: test)\n  --c {aa,bb,cc}  param 3 (default: aa)\n\n\n\nsource\n\n\nargs_from_prog\n\n args_from_prog (func, prog)\n\nExtract args from prog\nSometimes it’s convenient to extract arguments from the actual name of the called program. args_from_prog will do this, assuming that names and values of the params are separated by a #. Optionally there can also be a prefix separated by ## (double underscore).\n\nexp = {'a': False, 'b': 'baa'}\ntest_eq(args_from_prog(f, 'foo##a#0#b#baa'), exp)\ntest_eq(args_from_prog(f, 'a#0#b#baa'), exp)\n\n\nsource\n\n\ncall_parse\n\n call_parse (func=None, nested=False)\n\nDecorator to create a simple CLI from func using anno_parser\n\n@call_parse\ndef test_add(\n    a:int=0,  # param a\n    b:int=0  # param 1\n):\n    \"Add up `a` and `b`\"\n    return a + b\n\ncall_parse decorated functions work as regular functions and also as command-line interface functions.\n\ntest_eq(test_add(1,2), 3)\n\nThis is the main way to use fastcore.script; decorate your function with call_parse, add Param annotations (as shown above) or type annotations and docments, and it can then be used as a script.\nUse the nested keyword argument to create nested parsers, where earlier parsers consume only their known args from sys.argv before later parsers are used. This is useful to create one command line application that executes another. For example:\nmyrunner --keyword 1 script.py -- &lt;script.py args&gt;\nA separating -- after the first application’s args is recommended though not always required, otherwise args may be parsed in unexpected ways. For example:\nmyrunner script.py -h\nwould display myrunner’s help and not script.py’s.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "xdg.html",
    "href": "xdg.html",
    "title": "XDG",
    "section": "",
    "text": "See the XDG Base Directory Specification for more information.",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "xdg.html#overview",
    "href": "xdg.html#overview",
    "title": "XDG",
    "section": "Overview",
    "text": "Overview\nxdg_cache_home, xdg_config_home, xdg_data_home, and xdg_state_home return pathlib.Path objects containing the value of the environment variable named XDG_CACHE_HOME, XDG_CONFIG_HOME, XDG_DATA_HOME, and XDG_STATE_HOME respectively, or the default defined in the specification if the environment variable is unset, empty, or contains a relative path rather than absolute path.\nxdg_config_dirs and xdg_data_dirs return a list of pathlib.Path objects containing the value, split on colons, of the environment variable named XDG_CONFIG_DIRS and XDG_DATA_DIRS respectively, or the default defined in the specification if the environment variable is unset or empty. Relative paths are ignored, as per the specification.\nxdg_runtime_dir returns a pathlib.Path object containing the value of the XDG_RUNTIME_DIR environment variable, or None if the environment variable is not set, or contains a relative path rather than absolute path.",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "xdg.html#helpers",
    "href": "xdg.html#helpers",
    "title": "XDG",
    "section": "Helpers",
    "text": "Helpers\nWe’ll start by defining a context manager that temporarily sets an environment variable to demonstrate the behaviour of each helper function:\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef env(variable, value):\n    old = os.environ.get(variable, None)\n    try:\n        os.environ[variable] = value\n        yield\n    finally:\n        if old is None: del os.environ[variable]\n        else: os.environ[variable] = old\n\n\nsource\n\nxdg_cache_home\n\n xdg_cache_home ()\n\nPath corresponding to XDG_CACHE_HOME\n\nfrom fastcore.test import *\n\n\ntest_eq(xdg_cache_home(), Path.home()/'.cache')\nwith env('XDG_CACHE_HOME', '/home/fastai/.cache'):\n    test_eq(xdg_cache_home(), Path('/home/fastai/.cache'))\n\n\nsource\n\n\nxdg_config_dirs\n\n xdg_config_dirs ()\n\nPaths corresponding to XDG_CONFIG_DIRS\n\ntest_eq(xdg_config_dirs(), [Path('/etc/xdg')])\nwith env('XDG_CONFIG_DIRS', '/home/fastai/.xdg:/home/fastai/.config'):\n    test_eq(xdg_config_dirs(), [Path('/home/fastai/.xdg'), Path('/home/fastai/.config')])\n\n\nsource\n\n\nxdg_config_home\n\n xdg_config_home ()\n\nPath corresponding to XDG_CONFIG_HOME\n\ntest_eq(xdg_config_home(), Path.home()/'.config')\nwith env('XDG_CONFIG_HOME', '/home/fastai/.config'):\n    test_eq(xdg_config_home(), Path('/home/fastai/.config'))\n\n\nsource\n\n\nxdg_data_dirs\n\n xdg_data_dirs ()\n\nPaths corresponding to XDG_DATA_DIRS`\n\nsource\n\n\nxdg_data_home\n\n xdg_data_home ()\n\nPath corresponding to XDG_DATA_HOME\n\ntest_eq(xdg_data_home(), Path.home()/'.local/share')\nwith env('XDG_DATA_HOME', '/home/fastai/.data'):\n    test_eq(xdg_data_home(), Path('/home/fastai/.data'))\n\n\nsource\n\n\nxdg_runtime_dir\n\n xdg_runtime_dir ()\n\nPath corresponding to XDG_RUNTIME_DIR\n\nsource\n\n\nxdg_state_home\n\n xdg_state_home ()\n\nPath corresponding to XDG_STATE_HOME\n\ntest_eq(xdg_state_home(), Path.home()/'.local/state')\nwith env('XDG_STATE_HOME', '/home/fastai/.state'):\n    test_eq(xdg_state_home(), Path('/home/fastai/.state'))\n\n\nCopyright © 2016-2021 Scott Stevenson scott@stevenson.io\nModifications copyright © 2022 onwards Jeremy Howard",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "docments.html",
    "href": "docments.html",
    "title": "Docments",
    "section": "",
    "text": "docments provides programmatic access to comments in function parameters and return types. It can be used to create more developer-friendly documentation, CLI, etc tools.",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#why",
    "href": "docments.html#why",
    "title": "Docments",
    "section": "Why?",
    "text": "Why?\nWithout docments, if you want to document your parameters, you have to repeat param names in docstrings, since they’re already in the function signature. The parameters have to be kept synchronized in the two places as you change your code. Readers of your code have to look back and forth between two places to understand what’s happening. So it’s more work for you, and for your users.\nFurthermore, to have parameter documentation formatted nicely without docments, you have to use special magic docstring formatting, often with odd quirks, which is a pain to create and maintain, and awkward to read in code. For instance, using numpy-style documentation:\n\ndef add_np(a:int, b:int=0)-&gt;int:\n    \"\"\"The sum of two numbers.\n    \n    Used to demonstrate numpy-style docstrings.\n\nParameters\n----------\na : int\n    the 1st number to add\nb : int\n    the 2nd number to add (default: 0)\n\nReturns\n-------\nint\n    the result of adding `a` to `b`\"\"\"\n    return a+b\n\nBy comparison, here’s the same thing using docments:\n\ndef add(\n    a:int, # the 1st number to add\n    b=0,   # the 2nd number to add\n)-&gt;int:    # the result of adding `a` to `b`\n    \"The sum of two numbers.\"\n    return a+b",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#numpy-docstring-helper-functions",
    "href": "docments.html#numpy-docstring-helper-functions",
    "title": "Docments",
    "section": "Numpy docstring helper functions",
    "text": "Numpy docstring helper functions\ndocments also supports numpy-style docstrings, or a mix or numpy-style and docments parameter documentation. The functions in this section help get and parse this information.\n\nsource\n\ndocstring\n\n docstring (sym)\n\nGet docstring for sym for functions ad classes\n\ntest_eq(docstring(add), \"The sum of two numbers.\")\n\n\nsource\n\n\nparse_docstring\n\n parse_docstring (sym)\n\nParse a numpy-style docstring in sym\n\n# parse_docstring(add_np)\n\n\nsource\n\n\nisdataclass\n\n isdataclass (s)\n\nCheck if s is a dataclass but not a dataclass’ instance\n\nsource\n\n\nget_dataclass_source\n\n get_dataclass_source (s)\n\nGet source code for dataclass s\n\nsource\n\n\nget_source\n\n get_source (s)\n\nGet source code for string, function object or dataclass s\n\nsource\n\n\nget_name\n\n get_name (obj)\n\nGet the name of obj\n\ntest_eq(get_name(in_ipython), 'in_ipython')\ntest_eq(get_name(L.map), 'map')\n\n\nsource\n\n\nqual_name\n\n qual_name (obj)\n\nGet the qualified name of obj\n\nassert qual_name(docscrape) == 'fastcore.docscrape'",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#docments",
    "href": "docments.html#docments",
    "title": "Docments",
    "section": "Docments",
    "text": "Docments\n\nsource\n\ndocments\n\n docments (elt, full=False, returns=True, eval_str=False)\n\nGenerates a docment\nThe returned dict has parameter names as keys, docments as values. The return value comment appears in the return, unless returns=False. Using the add definition above, we get:\n\ndef add(\n    a:int, # the 1st number to add\n    b=0,   # the 2nd number to add\n)-&gt;int:    # the result of adding `a` to `b`\n    \"The sum of two numbers.\"\n    return a+b\n\ndocments(add)\n\n{ 'a': 'the 1st number to add',\n  'b': 'the 2nd number to add',\n  'return': 'the result of adding `a` to `b`'}\n\n\nIf you pass full=True, the values are dict of defaults, types, and docments as values. Note that the type annotation is inferred from the default value, if the annotation is empty and a default is supplied.\n\ndocments(add, full=True)\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the 1st number to add'},\n  'b': { 'anno': &lt;class 'int'&gt;,\n         'default': 0,\n         'docment': 'the 2nd number to add'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'the result of adding `a` to `b`'}}\n\n\nTo evaluate stringified annotations (from python 3.10), use eval_str:\n\ndocments(add, full=True, eval_str=True)['a']\n\n{ 'anno': &lt;class 'int'&gt;,\n  'default': &lt;class 'inspect._empty'&gt;,\n  'docment': 'the 1st number to add'}\n\n\nIf you need more space to document a parameter, place one or more lines of comments above the parameter, or above the return type. You can mix-and-match these docment styles:\n\ndef add(\n    # The first operand\n    a:int,\n    # This is the second of the operands to the *addition* operator.\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\n    b:int,\n)-&gt;int: # The result is calculated using Python's builtin `+` operator.\n    \"Add `a` to `b`\"\n    return a+b\n\n\ndocments(add)\n\n{ 'a': 'The first operand',\n  'b': 'This is the second of the operands to the *addition* operator.\\n'\n       'Note that passing a negative value here is the equivalent of the '\n       '*subtraction* operator.',\n  'return': \"The result is calculated using Python's builtin `+` operator.\"}\n\n\nDocments works with async functions, too:\n\nasync def add_async(\n    # The first operand\n    a:int,\n    # This is the second of the operands to the *addition* operator.\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\n    b:int,\n)-&gt;int: # The result is calculated using Python's builtin `+` operator.\n    \"Add `a` to `b`\"\n    return a+b\n\n\ntest_eq(docments(add_async), docments(add))\n\nYou can also use docments with classes and methods:\n\nclass Adder:\n    \"An addition calculator\"\n    def __init__(self,\n        a:int, # First operand\n        b:int, # 2nd operand\n    ): self.a,self.b = a,b\n    \n    def calculate(self\n                 )-&gt;int: # Integral result of addition operator\n        \"Add `a` to `b`\"\n        return a+b\n\n\ndocments(Adder)\n\n{'a': 'First operand', 'b': '2nd operand', 'return': None}\n\n\n\ndocments(Adder.calculate)\n\n{'return': 'Integral result of addition operator', 'self': None}\n\n\ndocments can also be extracted from numpy-style docstrings:\n\nprint(add_np.__doc__)\n\nThe sum of two numbers.\n    \n    Used to demonstrate numpy-style docstrings.\n\nParameters\n----------\na : int\n    the 1st number to add\nb : int\n    the 2nd number to add (default: 0)\n\nReturns\n-------\nint\n    the result of adding `a` to `b`\n\n\n\ndocments(add_np)\n\n{ 'a': 'the 1st number to add',\n  'b': 'the 2nd number to add (default: 0)',\n  'return': 'the result of adding `a` to `b`'}\n\n\nYou can even mix and match docments and numpy parameters:\n\ndef add_mixed(a:int, # the first number to add\n              b\n             )-&gt;int: # the result\n    \"\"\"The sum of two numbers.\n\nParameters\n----------\nb : int\n    the 2nd number to add (default: 0)\"\"\"\n    return a+b\n\n\ndocments(add_mixed, full=True)\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the first number to add'},\n  'b': { 'anno': 'int',\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the 2nd number to add (default: 0)'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'the result'}}\n\n\nYou can use docments with dataclasses, however if the class was defined in online notebook, docments will not contain parameters’ comments. This is because the source code is not available in the notebook. After converting the notebook to a module, the docments will be available. Thus, documentation will have correct parameters’ comments.\nDocments even works with delegates:\n\nfrom fastcore.meta import delegates\n\n\ndef _a(a:int=2): return a # First\n\n@delegates(_a)\ndef _b(b:str, **kwargs): return b, (_a(**kwargs)) # Second\n\ndocments(_b)\n\n{'a': 'First', 'b': 'Second', 'return': None}",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#extract-docstrings",
    "href": "docments.html#extract-docstrings",
    "title": "Docments",
    "section": "Extract docstrings",
    "text": "Extract docstrings\n\nsource\n\nextract_docstrings\n\n extract_docstrings (code)\n\nCreate a dict from function/class/method names to tuples of docstrings and param lists\n\nsample_code = \"\"\"\n\"This is a module.\"\n\ndef top_func(a, b, *args, **kw):\n    \"This is top-level.\"\n    pass\n\nclass SampleClass:\n    \"This is a class.\"\n\n    def __init__(self, x, y):\n        \"Constructor for SampleClass.\"\n        pass\n\n    def method1(self, param1):\n        \"This is method1.\"\n        pass\n\n    def _private_method(self):\n        \"This should not be included.\"\n        pass\n\nclass AnotherClass:\n    def __init__(self, a, b):\n        \"This class has no separate docstring.\"\n        pass\"\"\"\n\nexp = {'_module': ('This is a module.', ''),\n       'top_func': ('This is top-level.', 'a, b, *args, **kw'),\n       'SampleClass': ('This is a class.', 'self, x, y'),\n       'SampleClass.method1': ('This is method1.', 'self, param1'),\n       'AnotherClass': ('This class has no separate docstring.', 'self, a, b')}\ntest_eq(extract_docstrings(sample_code), exp)",
    "crumbs": [
      "Docments"
    ]
  }
]