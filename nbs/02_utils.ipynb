{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "> Utility functions used in the fastai library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ifnone(a, b):\n",
    "    \"`b` if `a` is None else `a`\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `b if a is None else a` is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate *both* `a` and `b` when calling `ifnone` (which it doesn't do if using the `if` version directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ifnone(None,1), 1)\n",
    "test_eq(ifnone(2   ,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maybe_attr(o, attr):\n",
    "    \"`getattr(o,attr,o)`\"\n",
    "    return getattr(o,attr,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def basic_repr(flds=None):\n",
    "    flds = L(flds)\n",
    "    def _f(self): \n",
    "        sig = ', '.join(f'{o}={maybe_attr(getattr(self,o), \"__name__\")}' for o in flds)\n",
    "        return f'{self.__class__.__name__}({sig})'\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds):\n",
    "    \"Dynamically create a class, optionally inheriting from `sup`, containing `fld_names`\"\n",
    "    attrs = {}\n",
    "    for f in fld_names: attrs[f] = None\n",
    "    for f in L(funcs): attrs[f.__name__] = f\n",
    "    for k,v in flds.items(): attrs[k] = v\n",
    "    sup = ifnone(sup, ())\n",
    "    if not isinstance(sup, tuple): sup=(sup,)\n",
    "\n",
    "    def _init(self, *args, **kwargs):\n",
    "        for i,v in enumerate(args): setattr(self, list(attrs.keys())[i], v)\n",
    "        for k,v in kwargs.items(): setattr(self,k,v)\n",
    "\n",
    "    all_flds = [*fld_names,*flds.keys()]\n",
    "    def _eq(self,b):\n",
    "        return all([getattr(self,k)==getattr(b,k) for k in all_flds])\n",
    "\n",
    "    if not sup: attrs['__repr__'] = basic_repr(all_flds)\n",
    "    attrs['__init__'] = _init\n",
    "    attrs['__eq__'] = _eq\n",
    "    res = type(nm, sup, attrs)\n",
    "    if doc is not None: res.__doc__ = doc\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t = get_class('_t', 'a', b=2)\n",
    "t = _t()\n",
    "test_eq(t.a, None)\n",
    "test_eq(t.b, 2)\n",
    "t = _t(1, b=3)\n",
    "test_eq(t.a, 1)\n",
    "test_eq(t.b, 3)\n",
    "t = _t(1, 3)\n",
    "test_eq(t.a, 1)\n",
    "test_eq(t.b, 3)\n",
    "test_eq(repr(t), '_t(a=1, b=3)')\n",
    "test_eq(t, pickle.loads(pickle.dumps(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most often you'll want to call `mk_class`, since it adds the class to your module. See `mk_class` for more details and examples of use (which also apply to `get_class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds):\n",
    "    \"Create a class using `get_class` and add to the caller's module\"\n",
    "    if mod is None: mod = inspect.currentframe().f_back.f_locals\n",
    "    res = get_class(nm, *fld_names, sup=sup, doc=doc, funcs=funcs, **flds)\n",
    "    mod[nm] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any `kwargs` will be added as class attributes, and `sup` is an optional (tuple of) base classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('_t', a=1, sup=GetAttr)\n",
    "t = _t()\n",
    "test_eq(t.a, 1)\n",
    "assert(isinstance(t,GetAttr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `__init__` is provided that sets attrs for any `kwargs`, and for any `args` (matching by position to fields), along with a `__repr__` which prints all attrs. The docstring is set to `doc`. You can pass `funcs` which will be added as attrs with the function names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__._t at 0x7f554ad6db90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(self): return 1\n",
    "mk_class('_t', 'a', sup=GetAttr, doc='test doc', funcs=foo)\n",
    "\n",
    "t = _t(3, b=2)\n",
    "test_eq(t.a, 3)\n",
    "test_eq(t.b, 2)\n",
    "test_eq(t.foo(), 1)\n",
    "test_eq(t.__doc__, 'test doc')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds):\n",
    "    \"Decorator: makes function a method of a new class `nm` passing parameters to `mk_class`\"\n",
    "    def _inner(f):\n",
    "        mk_class(nm, *fld_names, sup=sup, doc=doc, funcs=L(funcs)+f, mod=f.__globals__, **flds)\n",
    "        return f\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_class('_t', a=2)\n",
    "def bar(self,x): return x+1\n",
    "\n",
    "t = _t()\n",
    "test_eq(t.a, 2)\n",
    "test_eq(t.bar(3), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ignore_exceptions:\n",
    "    \"Context manager to ignore exceptions\"\n",
    "    def __enter__(self): pass\n",
    "    def __exit__(self, *args): return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ignore_exceptions(): unknown_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"noop\" class=\"doc_header\"><code>noop</code><a href=\"https://github.com/fastai/fastcore/tree/master/fastcore/imports.py#L52\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>noop</code>(**`x`**=*`None`*, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Do nothing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noop()\n",
    "test_eq(noop(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"noops\" class=\"doc_header\"><code>noops</code><a href=\"https://github.com/fastai/fastcore/tree/master/fastcore/imports.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>noops</code>(**`x`**=*`None`*, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Do nothing (method)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(noops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('_t', foo=noops)\n",
    "test_eq(_t().foo(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _find_in_stack(fr, nm):\n",
    "    if fr is None: raise Exception(f\"Failed to find {nm}\")\n",
    "    try: return fr.f_locals[nm]\n",
    "    except KeyError: return _find_in_stack(fr.f_back, nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_attr(self, nms=None):\n",
    "    \"Store params named in comma-separated `nms` from calling context into attrs in `self`\"\n",
    "    if nms is None: nms = self.store_attrs\n",
    "    fr = inspect.currentframe().f_back\n",
    "    for n in re.split(', *', nms): setattr(self,n,_find_in_stack(fr, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T:\n",
    "    def __init__(self, a,b,c): store_attr(self, 'a,b,c')\n",
    "\n",
    "t = T(1,c=2,b=3)\n",
    "assert t.a==1 and t.b==3 and t.c==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T2(T):\n",
    "    def __init__(self, d, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr(self, 'd')\n",
    "\n",
    "t = T2(d=1,a=2,b=3,c=4)\n",
    "assert t.a==2 and t.b==3 and t.c==4 and t.d==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def attrdict(o, *ks):\n",
    "    \"Dict from each `k` in `ks` to `getattr(o,k)`\"\n",
    "    return {k:getattr(o,k) for k in ks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = T(1,c=2,b=3)\n",
    "test_eq(attrdict(t,'b','c'), {'b':3, 'c':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def properties(cls, *ps):\n",
    "    \"Change attrs in `cls` with names in `ps` to properties\"\n",
    "    for p in ps: setattr(cls,p,property(getattr(cls,p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T:\n",
    "    def a(self): return 1\n",
    "    def b(self): return 2\n",
    "properties(T,'a')\n",
    "\n",
    "test_eq(T().a,1)\n",
    "test_eq(T().b(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def camel2snake(name):\n",
    "    \"Convert CamelCase to snake_case\"\n",
    "    s1   = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(camel2snake('ClassAreCamel'), 'class_are_camel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def snake2camel(s):\n",
    "    \"Convert snake_case to CamelCase\"\n",
    "    return ''.join(s.title().split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(snake2camel('a_b_cc'), 'ABCc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def class2attr(self, cls_name):\n",
    "    return camel2snake(re.sub(rf'{cls_name}$', '', self.__class__.__name__) or cls_name.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hasattrs(o,attrs):\n",
    "    \"Test whether `o` contains all `attrs`\"\n",
    "    return all(hasattr(o,attr) for attr in attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattrs(1,('imag','real'))\n",
    "assert not hasattrs(1,('imag','foo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ShowPrint:\n",
    "    \"Base class that prints for `show`\"\n",
    "    def show(self, *args, **kwargs): print(str(self))\n",
    "\n",
    "class Int(int,ShowPrint): pass\n",
    "class Float(float,ShowPrint): pass\n",
    "class Str(str,ShowPrint): pass\n",
    "add_docs(Int, \"An extensible `int`\"); add_docs(Str, \"An extensible `str`\"); add_docs(Float, \"An extensible `float`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def last_index(x, o):\n",
    "    \"Finds the last index of occurence of `x` in `o` (returns -1 if no occurence)\"\n",
    "    try: return next(i for i in reversed(range(len(o))) if o[i] == x)\n",
    "    except StopIteration: return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tuplify(o, use_list=False, match=None):\n",
    "    \"Make `o` a tuple\"\n",
    "    return tuple(L(o, use_list=use_list, match=match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tuplify(None),())\n",
    "test_eq(tuplify([1,2,3]),(1,2,3))\n",
    "test_eq(tuplify(1,match=[1,2,3]),(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def detuplify(x):\n",
    "    \"If `x` is a tuple with one thing, extract it\"\n",
    "    return None if len(x)==0 else x[0] if len(x)==1 and getattr(x, 'ndim', 1)==1 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(detuplify(()),None)\n",
    "test_eq(detuplify([1]),1)\n",
    "test_eq(detuplify([1,2]), [1,2])\n",
    "test_eq(detuplify(np.array([[1,2]])), np.array([[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replicate(item,match):\n",
    "    \"Create tuple of `item` copied `len(match)` times\"\n",
    "    return (item,)*len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1,1]\n",
    "test_eq(replicate([1,2], t),([1,2],[1,2]))\n",
    "test_eq(replicate(1, t),(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniqueify(x, sort=False, bidir=False, start=None):\n",
    "    \"Return the unique elements in `x`, optionally `sort`-ed, optionally return the reverse correspondence.\"\n",
    "    res = L(x).unique()\n",
    "    if start is not None: res = start+res\n",
    "    if sort: res.sort()\n",
    "    if bidir: return res, res.val2idx()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(set(uniqueify([1,1,0,5,0,3])),{0,1,3,5})\n",
    "test_eq(uniqueify([1,1,0,5,0,3], sort=True),[0,1,3,5])\n",
    "v,o = uniqueify([1,1,0,5,0,3], bidir=True)\n",
    "test_eq(v,[1,0,5,3])\n",
    "test_eq(o,{1:0, 0: 1, 5: 2, 3: 3})\n",
    "v,o = uniqueify([1,1,0,5,0,3], sort=True, bidir=True)\n",
    "test_eq(v,[0,1,3,5])\n",
    "test_eq(o,{0:0, 1: 1, 3: 2, 5: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setify(o): return o if isinstance(o,set) else set(L(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(setify(None),set())\n",
    "test_eq(setify('abc'),{'abc'})\n",
    "test_eq(setify([1,2,2]),{1,2})\n",
    "test_eq(setify(range(0,3)),{0,1,2})\n",
    "test_eq(setify({1,2}),{1,2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge(*ds):\n",
    "    \"Merge all dictionaries in `ds`\"\n",
    "    return {k:v for d in ds if d is not None for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(merge(), {})\n",
    "test_eq(merge(dict(a=1,b=2)), dict(a=1,b=2))\n",
    "test_eq(merge(dict(a=1,b=2), dict(b=3,c=4), None), dict(a=1, b=3, c=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_listy(x):\n",
    "    \"`isinstance(x, (tuple,list,L))`\"\n",
    "    return isinstance(x, (tuple,list,L,slice,Generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_listy([1])\n",
    "assert is_listy(L([1]))\n",
    "assert is_listy(slice(2))\n",
    "assert not is_listy(array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def range_of(x):\n",
    "    \"All indices of collection `x` (i.e. `list(range(len(x)))`)\"\n",
    "    return list(range(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(range_of([1,1,1,1]), [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def groupby(x, key):\n",
    "    \"Like `itertools.groupby` but doesn't need to be sorted, and isn't lazy\"\n",
    "    res = {}\n",
    "    for o in x: res.setdefault(key(o), []).append(o)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(groupby('aa ab bb'.split(), itemgetter(0)), {'a':['aa','ab'], 'b':['bb']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def first(x):\n",
    "    \"First element of `x`, or None if missing\"\n",
    "    try: return next(iter(x))\n",
    "    except StopIteration: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def shufflish(x, pct=0.04):\n",
    "    \"Randomly relocate items of `x` up to `pct` of `len(x)` from their starting location\"\n",
    "    n = len(x)\n",
    "    return L(x[i] for i in sorted(range_of(x), key=lambda o: o+n*(1+random.random()*pct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(100))\n",
    "l2 = array(shufflish(l))\n",
    "test_close(l2[:50 ].mean(), 25, eps=5)\n",
    "test_close(l2[-50:].mean(), 75, eps=5)\n",
    "test_ne(l,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IterLen:\n",
    "    \"Base class to add iteration to anything supporting `len` and `__getitem__`\"\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class ReindexCollection(GetAttr, IterLen):\n",
    "    \"Reindexes collection `coll` with indices `idxs` and optional LRU cache of size `cache`\"\n",
    "    _default='coll'\n",
    "    def __init__(self, coll, idxs=None, cache=None, tfm=noop):\n",
    "        store_attr(self, 'coll,cache,tfm')\n",
    "        self.idxs = L.range(coll) if idxs is None else idxs\n",
    "        if cache is not None: self._get = functools.lru_cache(maxsize=cache)(self._get)\n",
    "    \n",
    "    def _get(self, i): return self.tfm(self.coll[i])\n",
    "    def __getitem__(self, i): return self._get(self.idxs[i])\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def reindex(self, idxs): self.idxs = idxs\n",
    "    def shuffle(self): random.shuffle(self.idxs)\n",
    "    def cache_clear(self): self._get.cache_clear()\n",
    "    def __getstate__(self): return {'coll': self.coll, 'idxs': self.idxs, 'cache': self.cache, 'tfm': self.tfm}\n",
    "    def __setstate__(self, s): self.coll,self.idxs,self.cache,self.tfm = s['coll'],s['idxs'],s['cache'],s['tfm']\n",
    "\n",
    "    _docs = dict(reindex=\"Replace `self.idxs` with idxs\",\n",
    "                shuffle=\"Randomly shuffle indices\",\n",
    "                cache_clear=\"Clear LRU cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 50\n",
    "t = ReindexCollection(L.range(sz), cache=2)\n",
    "test_eq(list(t), range(sz))\n",
    "test_eq(t[sz-1], sz-1)\n",
    "test_eq(t._get.cache_info().hits, 1)\n",
    "t.shuffle()\n",
    "test_eq(t._get.cache_info().hits, 1)\n",
    "test_ne(list(t), range(sz))\n",
    "test_eq(set(t), set(range(sz)))\n",
    "t.cache_clear()\n",
    "test_eq(t._get.cache_info().hits, 0)\n",
    "test_eq(t.count(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test ReindexCollection pickles\n",
    "t1 = pickle.loads(pickle.dumps(t))\n",
    "test_eq(list(t), list(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def in_(x, a):\n",
    "    \"`True` if `x in a`\"\n",
    "    return x in a\n",
    "\n",
    "operator.in_ = in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _oper(op,a,b=np.nan): return (lambda o:op(o,a)) if b!=b else op(a,b)\n",
    "\n",
    "def _mk_op(nm, mod=None):\n",
    "    \"Create an operator using `oper` and add to the caller's module\"\n",
    "    if mod is None: mod = inspect.currentframe().f_back.f_locals\n",
    "    op = getattr(operator,nm)\n",
    "    def _inner(a,b=np.nan): return _oper(op, a,b)\n",
    "    _inner.__name__ = _inner.__qualname__ = nm\n",
    "    _inner.__doc__ = f'Same as `operator.{nm}`, or returns partial if 1 arg'\n",
    "    mod[nm] = _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['lt','gt','le','ge','eq','ne','add','sub','mul','truediv','is_','is_not','in_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "for op in ['lt','gt','le','ge','eq','ne','add','sub','mul','truediv','is_','is_not','in_']: _mk_op(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are provided matching the behavior of the equivalent versions in `operator`: *lt gt le ge eq ne add sub mul truediv is_ is_not*. In addition one method is added to `operator`, which is `in_(x,a)`, which is the same as `x in a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, True, False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt(3,5),gt(3,5),is_(None,None),in_(0,[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, they also have additional functionality: if you only pass one param, they return a partial function that passes that param as the second positional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, True, False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt(5)(3),gt(5)(3),is_(None)(None),in_([1,2])(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _InfMeta(type):\n",
    "    @property\n",
    "    def count(self): return itertools.count()\n",
    "    @property\n",
    "    def zeros(self): return itertools.cycle([0])\n",
    "    @property\n",
    "    def ones(self):  return itertools.cycle([1])\n",
    "    @property\n",
    "    def nones(self): return itertools.cycle([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Inf(metaclass=_InfMeta):\n",
    "    \"Infinite lists\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inf` defines the following properties:\n",
    "    \n",
    "- `count: itertools.count()`\n",
    "- `zeros: itertools.cycle([0])`\n",
    "- `ones : itertools.cycle([1])`\n",
    "- `nones: itertools.cycle([None])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq([o for i,o in zip(range(5), Inf.count)],\n",
    "        [0, 1, 2, 3, 4])\n",
    "\n",
    "test_eq([o for i,o in zip(range(5), Inf.zeros)],\n",
    "        [0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def true(*args, **kwargs):\n",
    "    \"Predicate: always `True`\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stop(e=StopIteration):\n",
    "    \"Raises exception `e` (by default `StopException`) even if in an expression\"\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen(func, seq, cond=true):\n",
    "    \"Like `(func(o) for o in seq if cond(func(o)))` but handles `StopIteration`\"\n",
    "    return itertools.takewhile(cond, map(func,seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(gen(noop, Inf.count, lt(5)),\n",
    "        range(5))\n",
    "test_eq(gen(operator.neg, Inf.count, gt(-5)),\n",
    "        [0,-1,-2,-3,-4])\n",
    "test_eq(gen(lambda o:o if o<5 else stop(), Inf.count),\n",
    "        range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def chunked(it, cs, drop_last=False):\n",
    "#     if not isinstance(it, Iterator): it = iter(it)\n",
    "#     while True:\n",
    "#         res = list(itertools.islice(it, cs))\n",
    "#         if res and (len(res)==cs or not drop_last): yield res\n",
    "#         if len(res)<cs: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def chunked(it, chunk_sz=None, drop_last=False, n_chunks=None):\n",
    "    \"Return batches from iterator `it` of size `chunk_sz` (or return `n_chunks` total)\"\n",
    "    assert bool(chunk_sz) ^ bool(n_chunks)\n",
    "    if n_chunks: chunk_sz = math.ceil(len(it)/n_chunks)\n",
    "    if not isinstance(it, Iterator): it = iter(it)\n",
    "    while True:\n",
    "        res = list(itertools.islice(it, chunk_sz))\n",
    "        if res and (len(res)==chunk_sz or not drop_last): yield res\n",
    "        if len(res)<chunk_sz: return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you must pass either `chunk_sz`, or `n_chunks`, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L.range(10)\n",
    "test_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\n",
    "test_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n",
    "\n",
    "t = map(lambda o:stop() if o==6 else o, Inf.count)\n",
    "test_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5]])\n",
    "t = map(lambda o:stop() if o==7 else o, Inf.count)\n",
    "test_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5], [6]])\n",
    "\n",
    "t = np.arange(10)\n",
    "test_eq(chunked(t,3),      L([0,1,2], [3,4,5], [6,7,8], [9]))\n",
    "test_eq(chunked(t,3,True), L([0,1,2], [3,4,5], [6,7,8],    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "num_methods = \"\"\"\n",
    "    __add__ __sub__ __mul__ __matmul__ __truediv__ __floordiv__ __mod__ __divmod__ __pow__\n",
    "    __lshift__ __rshift__ __and__ __xor__ __or__ __neg__ __pos__ __abs__\n",
    "\"\"\".split()\n",
    "rnum_methods = \"\"\"\n",
    "    __radd__ __rsub__ __rmul__ __rmatmul__ __rtruediv__ __rfloordiv__ __rmod__ __rdivmod__\n",
    "    __rpow__ __rlshift__ __rrshift__ __rand__ __rxor__ __ror__\n",
    "\"\"\".split()\n",
    "inum_methods = \"\"\"\n",
    "    __iadd__ __isub__ __imul__ __imatmul__ __itruediv__\n",
    "    __ifloordiv__ __imod__ __ipow__ __ilshift__ __irshift__ __iand__ __ixor__ __ior__\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tuple(tuple):\n",
    "    \"A `tuple` with elementwise ops and more friendly __init__ behavior\"\n",
    "    def __new__(cls, x=None, *rest):\n",
    "        if x is None: x = ()\n",
    "        if not isinstance(x,tuple):\n",
    "            if len(rest): x = (x,)\n",
    "            else:\n",
    "                try: x = tuple(iter(x))\n",
    "                except TypeError: x = (x,)\n",
    "        return super().__new__(cls, x+rest if rest else x)\n",
    "\n",
    "    def _op(self,op,*args):\n",
    "        if not isinstance(self,Tuple): self = Tuple(self)\n",
    "        return type(self)(map(op,self,*map(cycle, args)))\n",
    "\n",
    "    def mul(self,*args):\n",
    "        \"`*` is already defined in `tuple` for replicating, so use `mul` instead\"\n",
    "        return Tuple._op(self, operator.mul,*args)\n",
    "\n",
    "    def add(self,*args):\n",
    "        \"`+` is already defined in `tuple` for concat, so use `add` instead\"\n",
    "        return Tuple._op(self, operator.add,*args)\n",
    "\n",
    "def _get_op(op):\n",
    "    if isinstance(op,str): op = getattr(operator,op)\n",
    "    def _f(self,*args): return self._op(op,*args)\n",
    "    return _f\n",
    "\n",
    "for n in num_methods:\n",
    "    if not hasattr(Tuple, n) and hasattr(operator,n): setattr(Tuple,n,_get_op(n))\n",
    "\n",
    "for n in 'eq ne lt le gt ge'.split(): setattr(Tuple,n,_get_op(n))\n",
    "setattr(Tuple,'__invert__',_get_op('__not__'))\n",
    "setattr(Tuple,'max',_get_op(max))\n",
    "setattr(Tuple,'min',_get_op(min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Tuple(1), (1,))\n",
    "test_eq(type(Tuple(1)), Tuple)\n",
    "test_eq_type(Tuple(1,2), Tuple(1,2))\n",
    "test_ne(Tuple(1,2), Tuple(1,3))\n",
    "test_eq(Tuple(), ())\n",
    "test_eq(Tuple((1,2)), (1,2))\n",
    "test_eq(-Tuple(1,2), (-1,-2))\n",
    "test_eq(Tuple(1,1)-Tuple(2,2), (-1,-1))\n",
    "test_eq(Tuple.add((1,1),(2,2)), (3,3))\n",
    "test_eq(Tuple(1,1).add((2,2)), Tuple(3,3))\n",
    "test_eq(Tuple('1','2').add('2'), Tuple('12','22'))\n",
    "test_eq_type(Tuple(1,1).add(2), Tuple(3,3))\n",
    "test_eq_type(Tuple(1,1).mul(2), Tuple(2,2))\n",
    "test_eq(Tuple(3,1).le(1), (False, True))\n",
    "test_eq(Tuple(3,1).eq(1), (False, True))\n",
    "test_eq(Tuple(3,1).gt(1), (True, False))\n",
    "test_eq(Tuple(3,1).min(2), (2,1))\n",
    "test_eq(~Tuple(1,0,1), (False,True,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def trace(f):\n",
    "    \"Add `set_trace` to an existing function `f`\"\n",
    "    def _inner(*args,**kwargs):\n",
    "        set_trace()\n",
    "        return f(*args,**kwargs)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compose(*funcs, order=None):\n",
    "    \"Create a function that composes all functions in `funcs`, passing along remaining `*args` and `**kwargs` to all\"\n",
    "    funcs = L(funcs)\n",
    "    if len(funcs)==0: return noop\n",
    "    if len(funcs)==1: return funcs[0]\n",
    "    if order is not None: funcs = funcs.sorted(order)\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in L(funcs): x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda o,p=0: (o*2)+p\n",
    "f2 = lambda o,p=1: (o+1)/p\n",
    "test_eq(f2(f1(3)), compose(f1,f2)(3))\n",
    "test_eq(f2(f1(3,p=3),p=3), compose(f1,f2)(3,p=3))\n",
    "test_eq(f2(f1(3,  3),  3), compose(f1,f2)(3,  3))\n",
    "\n",
    "f1.order = 1\n",
    "test_eq(f1(f2(3)), compose(f1,f2, order=\"order\")(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maps(*args, retain=noop):\n",
    "    \"Like `map`, except funcs are composed first\"\n",
    "    f = compose(*args[:-1])\n",
    "    def _f(b): return retain(f(b), b)\n",
    "    return map(_f, args[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(maps([1]), [1])\n",
    "test_eq(maps(operator.neg, [1,2]), [-1,-2])\n",
    "test_eq(maps(operator.neg, operator.neg, [1,2]), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def partialler(f, *args, order=None, **kwargs):\n",
    "    \"Like `functools.partial` but also copies over docstring\"\n",
    "    fnew = partial(f,*args,**kwargs)\n",
    "    fnew.__doc__ = f.__doc__\n",
    "    if order is not None: fnew.order=order\n",
    "    elif hasattr(f,'order'): fnew.order=f.order\n",
    "    return fnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f(x,a=1):\n",
    "    \"test func\"\n",
    "    return x+a\n",
    "_f.order=1\n",
    "\n",
    "f = partialler(_f, a=2)\n",
    "test_eq(f.order, 1)\n",
    "f = partialler(_f, a=2, order=3)\n",
    "test_eq(f.__doc__, \"test func\")\n",
    "test_eq(f.order, 3)\n",
    "test_eq(f(3), _f(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mapped(f, it):\n",
    "    \"map `f` over `it`, unless it's not listy, in which case return `f(it)`\"\n",
    "    return L(it).map(f) if is_listy(it) else f(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(mapped(_f,1),2)\n",
    "test_eq(mapped(_f,[1,2]),[2,3])\n",
    "test_eq(mapped(_f,(1,)),(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def instantiate(t):\n",
    "    \"Instantiate `t` if it's a type, otherwise do nothing\"\n",
    "    return t() if isinstance(t, type) else t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(instantiate(int), 0)\n",
    "test_eq_type(instantiate(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _using_attr(f, attr, x):\n",
    "    return f(getattr(x,attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def using_attr(f, attr):\n",
    "    \"Change function `f` to operate on `attr`\"\n",
    "    return partial(_using_attr, f, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Path('/a/b.txt')\n",
    "f = using_attr(str.upper, 'name')\n",
    "test_eq(f(t), 'B.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sleep(func=None, *, seconds=None, msg=None):\n",
    "    if func is None:\n",
    "        return partial(_sleep, seconds=seconds, msg=msg)\n",
    "\n",
    "    seconds = seconds if seconds else 1\n",
    "    msg = msg if msg else 'Sleeping for {} seconds'.format(seconds)\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(msg)\n",
    "        time.sleep(seconds)\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_args(f=None, *, to_return=False, but=None, but_as=None):\n",
    "    \"Decorator to log function args in 'to.init_args'\"\n",
    "    if f is None: return partial(log_args, to_return=to_return, but=but, but_as=but_as)\n",
    "    \n",
    "    if inspect.isclass(f):\n",
    "        f.__init__ = log_args(f.__init__, to_return=to_return, but=but, but_as=but_as)\n",
    "        return f\n",
    "    \n",
    "    but_as_args = L(getattr(b, '_log_args_but', None) for b in L(but_as)).concat()\n",
    "    but = (L(but.split(',') if but else None) + but_as_args + L('self')).unique()\n",
    "    but_not_found = L(b for b in L(but_as) if not hasattr(b, '_log_args_but'))    \n",
    "    if but_not_found: print(f'@log_args did not find args from but_as while wrapping {f.__qualname__} in {\", \".join(b.__qualname__ for b in but_not_found)}')\n",
    "    setattr(f, '_log_args_but', but)\n",
    "    \n",
    "    @wraps(f)  # maintain original signature\n",
    "    def _f(*args, **kwargs):\n",
    "        f_insp,args_insp = f,args\n",
    "        xtra_kwargs = {}\n",
    "        # some functions don't have correct signature (e.g. functions with @delegates such as Datasets.__init__) so we get the one from the class\n",
    "        if '__init__' in f.__qualname__:\n",
    "            # from https://stackoverflow.com/a/25959545/3474490\n",
    "            cls = getattr(inspect.getmodule(f), f.__qualname__.split('.<locals>', 1)[0].rsplit('.', 1)[0]) # args[0].__class__ would not consider inheritance\n",
    "            f_insp, args_insp = cls, args[1:]\n",
    "        try:\n",
    "            func_args = inspect.signature(f_insp).bind(*args_insp, **kwargs)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                # sometimes it happens because the signature does not reference some kwargs                \n",
    "                sigp = dict(inspect.signature(f_insp).parameters)\n",
    "                key_no_sig = set(kwargs.keys())-set(sigp.keys())\n",
    "                xtra_kwargs={k:kwargs.pop(k) for k in key_no_sig}\n",
    "                func_args = inspect.signature(f_insp).bind(*args_insp, **kwargs)\n",
    "            except:\n",
    "                print(f'@log_args had an issue on {f.__qualname__} -> {e}')\n",
    "                return f(*args, **kwargs)\n",
    "        func_args.apply_defaults()\n",
    "        log_dict = {**func_args.arguments, **{f'{k} (not in signature)':v for k,v in xtra_kwargs.items()}}\n",
    "        log = {f'{f.__qualname__}.{k}':v for k,v in log_dict.items() if k not in but}\n",
    "        inst = f(*args, **kwargs) if to_return else args[0]\n",
    "        init_args = getattr(inst, 'init_args', {})\n",
    "        init_args.update(log)\n",
    "        setattr(inst, 'init_args', init_args)\n",
    "        return inst if to_return else f(*args, **kwargs)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tst:\n",
    "    @log_args\n",
    "    def __init__(self, a, b, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst(1,2).init_args, {f'tst.__init__.{k}':v for k,v in dict(a=1,b=2,c=3,d=4).items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `log_args` to save function args in `to.init_args`. Optional args are:\n",
    "\n",
    "* `to_return`: applies to return value if True (for functions), otherwise to `self` (for class instances)\n",
    "* `but`: args that we do not want to save separated by ','\n",
    "* `but_as`: pull `but` arg from another `log_args` (which cannot have used `to_return=True`)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* `@log_args` needs to be placed below `@patch` and above `@funcs_kwargs` or `@delegates`\n",
    "* when wrapping a class, it will wrap its `__init__` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tst:\n",
    "    @log_args\n",
    "    def __init__(self, a, b, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst(1,2).init_args, {f'tst.__init__.{k}':v for k,v in dict(a=1,b=2,c=3,d=4).items()})\n",
    "\n",
    "@log_args\n",
    "class tst:\n",
    "    def __init__(self, a, b, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst(1,2).init_args, {f'tst.__init__.{k}':v for k,v in dict(a=1,b=2,c=3,d=4).items()})\n",
    "\n",
    "@log_args(but='a,c')\n",
    "class tst:\n",
    "    def __init__(self, a, b, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst(1,2).init_args, {f'tst.__init__.{k}':v for k,v in dict(b=2,d=4).items()})\n",
    "\n",
    "class tst:\n",
    "    pass\n",
    "@log_args(to_return=True)\n",
    "def tst_f(a,b): return tst\n",
    "test_eq(tst_f(1,2).init_args, {f'tst_f.{k}':v for k,v in dict(a=1,b=2).items()})\n",
    "\n",
    "@log_args\n",
    "@funcs_kwargs\n",
    "class tst:\n",
    "    _methods='a'.split()    \n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "test_eq(tst(a=noop).init_args['tst.__init__.a'], noop)\n",
    "\n",
    "class tst_base:\n",
    "    def __init__(self, a=None):\n",
    "        pass\n",
    "@log_args\n",
    "@delegates(tst_base)\n",
    "class tst:\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "test_eq(tst(a=1).init_args['tst.__init__.a'], 1)\n",
    "\n",
    "@log_args\n",
    "class tst_parent:\n",
    "    def __init__(self, a):\n",
    "        pass\n",
    "@log_args\n",
    "class tst(tst_parent):\n",
    "    def __init__(self, b):\n",
    "        super().__init__(a=b)\n",
    "test_eq(tst(1).init_args, {'tst_parent.__init__.a': 1, 'tst.__init__.b': 1})\n",
    "\n",
    "class tst_ref:\n",
    "    def __init__(self, a, b, c, d):\n",
    "        pass\n",
    "class tst:\n",
    "    def __init__(self, a=1, b=2, c=3, d=4):\n",
    "        pass\n",
    "test_stdout(lambda: log_args(tst, but_as=tst_ref.__init__), '@log_args did not find args from but_as while wrapping tst.__init__ in tst_ref.__init__')\n",
    "\n",
    "@log_args(but='a,b')\n",
    "class tst_ref:\n",
    "    def __init__(self, a, b, c, d):\n",
    "        pass\n",
    "@log_args(but_as=tst_ref.__init__)\n",
    "class tst:\n",
    "    def __init__(self, a=1, b=2, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst().init_args, {'tst.__init__.c': 3, 'tst.__init__.d': 4})\n",
    "\n",
    "@log_args(but='a,b')\n",
    "class tst_ref:\n",
    "    def __init__(self, a, b, c, d):\n",
    "        pass\n",
    "@log_args(but='c', but_as=tst_ref.__init__)\n",
    "class tst:\n",
    "    def __init__(self, a=1, b=2, c=3, d=4):\n",
    "        pass\n",
    "test_eq(tst().init_args, {'tst.__init__.d': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Self:\n",
    "    \"An alternative to `lambda` for calling methods on passed object.\"\n",
    "    def __init__(self): self.nms,self.args,self.kwargs,self.ready = [],[],[],True\n",
    "    def __repr__(self): return f'self: {self.nms}({self.args}, {self.kwargs})'\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self.ready:\n",
    "            x = args[0]\n",
    "            for n,a,k in zip(self.nms,self.args,self.kwargs):\n",
    "                x = getattr(x,n)\n",
    "                if callable(x) and a is not None: x = x(*a, **k)\n",
    "            return x\n",
    "        else:\n",
    "            self.args.append(args)\n",
    "            self.kwargs.append(kwargs)\n",
    "            self.ready = True\n",
    "            return self\n",
    "\n",
    "    def __getattr__(self,k):\n",
    "        if not self.ready:\n",
    "            self.args.append(None)\n",
    "            self.kwargs.append(None)\n",
    "        self.nms.append(k)\n",
    "        self.ready = False\n",
    "        return self\n",
    "\n",
    "class _SelfCls:\n",
    "    def __getattr__(self,k): return getattr(_Self(),k)\n",
    "    def __getitem__(self,i): return self.__getattr__('__getitem__')(i)\n",
    "\n",
    "Self = _SelfCls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['Self']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai provides a concise way to create lambdas that are calling methods on an object, which is to use `Self` (note the capitalization!) `Self.sum()`, for instance, is a shortcut for `lambda o: o.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sum()\n",
    "x = array([3.,1])\n",
    "test_eq(f(x), 4.)\n",
    "\n",
    "# This is equivalent to above\n",
    "f = lambda o: o.sum()\n",
    "x = array([3.,1])\n",
    "test_eq(f(x), 4.)\n",
    "\n",
    "f = Self.sum().is_integer()\n",
    "x = array([3.,1])\n",
    "test_eq(f(x), True)\n",
    "\n",
    "f = Self.sum().real.is_integer()\n",
    "x = array([3.,1])\n",
    "test_eq(f(x), True)\n",
    "\n",
    "f = Self.imag()\n",
    "test_eq(f(3), 0)\n",
    "\n",
    "f = Self[1]\n",
    "test_eq(f(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def readlines(self:Path, hint=-1, encoding='utf8'):\n",
    "    \"Read the content of `fname`\"\n",
    "    with self.open(encoding=encoding) as f: return f.readlines(hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def read(self:Path, size=-1, encoding='utf8'):\n",
    "    \"Read the content of `fname`\"\n",
    "    with self.open(encoding=encoding) as f: return f.read(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def write(self:Path, txt, encoding='utf8'):\n",
    "    \"Write `txt` to `self`, creating directories as needed\"\n",
    "    self.parent.mkdir(parents=True,exist_ok=True)\n",
    "    with self.open('w', encoding=encoding) as f: f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as f:\n",
    "    fn = Path(f.name)\n",
    "    fn.write('t')\n",
    "    t = fn.read()\n",
    "    test_eq(t,'t')\n",
    "    t = fn.readlines()\n",
    "    test_eq(t,['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def save(fn:Path, o):\n",
    "    \"Save a pickle file, to a file name or opened file\"\n",
    "    if not isinstance(fn, io.IOBase): fn = open(fn,'wb')\n",
    "    try: pickle.dump(o, fn)\n",
    "    finally: fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def load(fn:Path):\n",
    "    \"Load a pickle file from a file name or opened file\"\n",
    "    if not isinstance(fn, io.IOBase): fn = open(fn,'rb')\n",
    "    try: return pickle.load(fn)\n",
    "    finally: fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as f:\n",
    "    fn = Path(f.name)\n",
    "    fn.save('t')\n",
    "    t = fn.load()\n",
    "test_eq(t,'t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def ls(self:Path, n_max=None, file_type=None, file_exts=None):\n",
    "    \"Contents of path as a list\"\n",
    "    extns=L(file_exts)\n",
    "    if file_type: extns += L(k for k,v in mimetypes.types_map.items() if v.startswith(file_type+'/'))\n",
    "    has_extns = len(extns)==0\n",
    "    res = (o for o in self.iterdir() if has_extns or o.suffix in extns)\n",
    "    if n_max is not None: res = itertools.islice(res, n_max)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an `ls()` method to `pathlib.Path` which is simply defined as `list(Path.iterdir())`, mainly for convenience in REPL environments such as notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.ipynb_checkpoints')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path()\n",
    "t = path.ls()\n",
    "assert len(t)>0\n",
    "t1 = path.ls(10)\n",
    "test_eq(len(t1), 10)\n",
    "t2 = path.ls(file_exts='.ipynb')\n",
    "assert len(t)>len(t2)\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass an optional `file_type` MIME prefix and/or a list of file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('../fastcore/utils.py'), Path('04_transform.ipynb'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_path = (path/'../fastcore')\n",
    "txt_files=lib_path.ls(file_type='text')\n",
    "assert len(txt_files) > 0 and txt_files[0].suffix=='.py'\n",
    "ipy_files=path.ls(file_exts=['.ipynb'])\n",
    "assert len(ipy_files) > 0 and ipy_files[0].suffix=='.ipynb'\n",
    "txt_files[0],ipy_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pkl = pickle.dumps(path)\n",
    "p2 =pickle.loads(pkl)\n",
    "test_eq(path.ls()[0], p2.ls()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def __repr__(self:Path):\n",
    "    b = getattr(Path, 'BASE_PATH', None)\n",
    "    if b:\n",
    "        try: self = self.relative_to(b)\n",
    "        except: pass\n",
    "    return f\"Path({self.as_posix()!r})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai also updates the `repr` of `Path` such that, if `Path.BASE_PATH` is defined, all paths are printed relative to that path (as long as they are contained in `Path.BASE_PATH`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ipy_files[0].absolute()\n",
    "try:\n",
    "    Path.BASE_PATH = t.parent.parent\n",
    "    test_eq(repr(t), f\"Path('nbs/{t.name}')\")\n",
    "finally: Path.BASE_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bunzip(fn):\n",
    "    \"bunzip `fn`, raising exception if output already exists\"\n",
    "    fn = Path(fn)\n",
    "    assert fn.exists(), f\"{fn} doesn't exist\"\n",
    "    out_fn = fn.with_suffix('')\n",
    "    assert not out_fn.exists(), f\"{out_fn} already exists\"\n",
    "    with bz2.BZ2File(fn, 'rb') as src, out_fn.open('wb') as dst:\n",
    "        for d in iter(lambda: src.read(1024*1024), b''): dst.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Path('files/test.txt')\n",
    "if f.exists(): f.unlink()\n",
    "bunzip('files/test.txt.bz2')\n",
    "t = f.open().readlines()\n",
    "test_eq(len(t),1)\n",
    "test_eq(t[0], 'test\\n')\n",
    "f.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_path_file(file, path, ext=''):\n",
    "    \"Return `path/file` if file is a string or a `Path`, file otherwise\"\n",
    "    if not isinstance(file, (str, Path)): return file\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    return path/f'{file}{ext}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'_tmp'/'tst'\n",
    "f = join_path_file('tst.txt', path)\n",
    "assert path.exists()\n",
    "test_eq(f, path/'tst.txt')\n",
    "with open(f, 'w') as f_: assert join_path_file(f_, path) == f_\n",
    "shutil.rmtree(Path.cwd()/'_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_patched = ['read', 'readlines', 'write', 'save', 'load', 'ls']\n",
    "\n",
    "@contextmanager\n",
    "def remove_patches_path():\n",
    "    patches = L(getattr(Path, n) for n in _patched)\n",
    "    try:\n",
    "        for n in _patched: delattr(Path, n)\n",
    "        yield\n",
    "    finally: \n",
    "        for (n, f) in zip(_patched, patches): setattr(Path, n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with remove_patches_path():\n",
    "    assert not hasattr(Path, 'write')\n",
    "assert hasattr(Path, 'write')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting objects from before/after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms and callbacks will have run_after/run_before attributes, this function will sort them to respect those requirements (if it's possible). Also, sometimes we want a tranform/callback to be run at the end, but still be able to use run_after/run_before behaviors. For those, the function checks for a toward_end attribute (that needs to be True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _is_instance(f, gs):\n",
    "    tst = [g if type(g) in [type, 'function'] else g.__class__ for g in gs]\n",
    "    for g in tst:\n",
    "        if isinstance(f, g) or f==g: return True\n",
    "    return False\n",
    "\n",
    "def _is_first(f, gs):\n",
    "    for o in L(getattr(f, 'run_after', None)):\n",
    "        if _is_instance(o, gs): return False\n",
    "    for g in gs:\n",
    "        if _is_instance(f, L(getattr(g, 'run_before', None))): return False\n",
    "    return True\n",
    "\n",
    "def sort_by_run(fs):\n",
    "    end = L(fs).attrgot('toward_end')\n",
    "    inp,res = L(fs)[~end] + L(fs)[end], L()\n",
    "    while len(inp):\n",
    "        for i,o in enumerate(inp):\n",
    "            if _is_first(o, inp):\n",
    "                res.append(inp.pop(i))\n",
    "                break\n",
    "        else: raise Exception(\"Impossible to sort\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tst(): pass    \n",
    "class Tst1():\n",
    "    run_before=[Tst]\n",
    "class Tst2():\n",
    "    run_before=Tst\n",
    "    run_after=Tst1\n",
    "    \n",
    "tsts = [Tst(), Tst1(), Tst2()]\n",
    "test_eq(sort_by_run(tsts), [tsts[1], tsts[2], tsts[0]])\n",
    "\n",
    "Tst2.run_before,Tst2.run_after = Tst1,Tst\n",
    "test_fail(lambda: sort_by_run([Tst(), Tst1(), Tst2()]))\n",
    "\n",
    "def tst1(x): return x\n",
    "tst1.run_before = Tst\n",
    "test_eq(sort_by_run([tsts[0], tst1]), [tst1, tsts[0]])\n",
    "    \n",
    "class Tst1():\n",
    "    toward_end=True\n",
    "class Tst2():\n",
    "    toward_end=True\n",
    "    run_before=Tst1\n",
    "tsts = [Tst(), Tst1(), Tst2()]\n",
    "test_eq(sort_by_run(tsts), [tsts[0], tsts[2], tsts[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrettyString(str):\n",
    "    \"Little hack to get strings to show properly in Jupyter.\"\n",
    "    def __repr__(self): return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def round_multiple(x, mult, round_down=False):\n",
    "    \"Round `x` to nearest multiple of `mult`\"\n",
    "    def _f(x_): return (int if round_down else round)(x_/mult)*mult\n",
    "    res = L(x).map(_f)\n",
    "    return res if is_listy(x) else res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(round_multiple(63,32), 64)\n",
    "test_eq(round_multiple(50,32), 64)\n",
    "test_eq(round_multiple(40,32), 32)\n",
    "test_eq(round_multiple( 0,32),  0)\n",
    "test_eq(round_multiple(63,32, round_down=True), 32)\n",
    "test_eq(round_multiple((63,40),32), (64,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def even_mults(start, stop, n):\n",
    "    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n",
    "    if n==1: return stop\n",
    "    mult = stop/start\n",
    "    step = mult**(1/(n-1))\n",
    "    return np.array([start*(step**i) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(even_mults(2,8,3), [2,4,8])\n",
    "test_eq(even_mults(2,32,5), [2,4,8,16,32])\n",
    "test_eq(even_mults(2,8,1), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_cpus():\n",
    "    \"Get number of cpus\"\n",
    "    try:                   return len(os.sched_getaffinity(0))\n",
    "    except AttributeError: return os.cpu_count()\n",
    "\n",
    "defaults.cpus = num_cpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_props(f, g=None, n=2):\n",
    "    \"Create properties passing each of `range(n)` to f\"\n",
    "    if g is None: return (property(partial(f,i)) for i in range(n))\n",
    "    return (property(partial(f,i), partial(g,i)) for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(): a,b = add_props(lambda i,x:i*2)\n",
    "\n",
    "t = _T()\n",
    "test_eq(t.a,0)\n",
    "test_eq(t.b,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(): \n",
    "    def __init__(self, v): self.v=v\n",
    "    def _set(i, self, v): self.v[i] = v\n",
    "    a,b = add_props(lambda i,x: x.v[i], _set)\n",
    "\n",
    "t = _T([0,2])\n",
    "test_eq(t.a,0)\n",
    "test_eq(t.b,2)\n",
    "t.a = t.a+1\n",
    "t.b = 3\n",
    "test_eq(t.a,1)\n",
    "test_eq(t.b,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def change_attr(o, name, new_val):\n",
    "    \"Change the attr `name` in `o` with `new_val` if it exists and return the old value\"\n",
    "    old = getattr(o, name, None)\n",
    "    if hasattr(o, 'name'): setattr(o, name, new_val)\n",
    "    return o,old,hasattr(o, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def change_attrs(o, names, new_vals, do=None):\n",
    "    \"Change the attr `names` in `o` with `new_vals` if it exists and return the old values\"\n",
    "    olds,has = L(),L()\n",
    "    if do is None: do = L(True) * len(names)\n",
    "    for n,v,d in zip(names, new_vals, do):\n",
    "        if d: \n",
    "            o,old,h = change_attr(o, n, v)\n",
    "            olds.append(old); has.append(h)\n",
    "    return o,olds,has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from multiprocessing import Process, Queue\n",
    "import concurrent.futures\n",
    "import time\n",
    "from multiprocessing import Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_num_threads(nt):\n",
    "    \"Get numpy (and others) to use `nt` threads\"\n",
    "    try: import mkl; mkl.set_num_threads(nt)\n",
    "    except: pass\n",
    "    try: import torch; torch.set_num_threads(nt)\n",
    "    except: pass\n",
    "    os.environ['IPC_ENABLE']='1'\n",
    "    for o in ['OPENBLAS_NUM_THREADS','NUMEXPR_NUM_THREADS','OMP_NUM_THREADS','MKL_NUM_THREADS']:\n",
    "        os.environ[o] = str(nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C():\n",
    "    def __init__(self, min_time=0): self.lock,self.min_time = Manager().Lock(),min_time\n",
    "\n",
    "    def f(self, i):\n",
    "        if self.min_time:\n",
    "            with self.lock: time.sleep(self.min_time)\n",
    "        print(datetime.now())\n",
    "\n",
    "    def __call__(self):\n",
    "        with ProcessPoolExecutor(5) as p:\n",
    "            p.map(self.f, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _call(lock, pause, n, g, item):\n",
    "    l = False\n",
    "    if pause:\n",
    "        try:\n",
    "            l = lock.acquire(timeout=pause*(n+2))\n",
    "            time.sleep(pause)\n",
    "        finally:\n",
    "            if l: lock.release()\n",
    "    return g(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(concurrent.futures.ProcessPoolExecutor)\n",
    "class ProcessPoolExecutor(concurrent.futures.ProcessPoolExecutor):\n",
    "    \"Same as Python's ProcessPoolExecutor, except can pass `max_workers==0` for serial execution\"\n",
    "    def __init__(self, max_workers=None, on_exc=print, pause=0, **kwargs):\n",
    "        self.not_parallel = max_workers==0\n",
    "        store_attr(self, 'on_exc,pause,max_workers')\n",
    "        if self.not_parallel: max_workers=1\n",
    "        super().__init__(max_workers, **kwargs)\n",
    "    \n",
    "    def map(self, f, items, *args, **kwargs):\n",
    "        self.lock = Manager().Lock()\n",
    "        g = partial(f, *args, **kwargs)\n",
    "        if self.not_parallel: return map(g, items)\n",
    "        try: return super().map(partial(_call, self.lock, self.pause, self.max_workers, g), items)\n",
    "        except Exception as e: self.on_exc(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: from fastprogress import progress_bar\n",
    "except: progress_bar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def parallel(f, items, *args, n_workers=defaults.cpus, total=None, progress=None, pause=0, **kwargs):\n",
    "    \"Applies `func` in parallel to `items`, using `n_workers`\"\n",
    "    if progress is None: progress = progress_bar is not None\n",
    "    with ProcessPoolExecutor(n_workers, pause=pause) as ex:\n",
    "        r = ex.map(f,items, *args, **kwargs)\n",
    "        if progress:\n",
    "            if total is None: total = len(items)\n",
    "            r = progress_bar(r, total=total, leave=False)\n",
    "        return L(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_one(x, a=1): \n",
    "    time.sleep(random.random()/80)\n",
    "    return x+a\n",
    "\n",
    "inp,exp = range(50),range(1,51)\n",
    "test_eq(parallel(add_one, inp, n_workers=2), exp)\n",
    "test_eq(parallel(add_one, inp, n_workers=0), exp)\n",
    "test_eq(parallel(add_one, inp, n_workers=1, a=2), range(2,52))\n",
    "test_eq(parallel(add_one, inp, n_workers=0, a=2), range(2,52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pause` parameter to ensure a pause of `pause` seconds between processes starting. This is in case there are race conditions in starting some process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2020-08-10 15:05:50.372126\n",
      "1 2020-08-10 15:05:50.620418\n",
      "2 2020-08-10 15:05:50.868061\n",
      "3 2020-08-10 15:05:51.122114\n",
      "4 2020-08-10 15:05:51.372033\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def print_time(i): \n",
    "    time.sleep(random.random()/80)\n",
    "    print(i, datetime.now())\n",
    "\n",
    "parallel(print_time, range(5), n_workers=2, pause=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(parallel)\n",
    "def parallel_chunks(f, items, n_workers=0, **kwargs):\n",
    "    \"Calls `parallel` after first creating `n_workers` batches from `items`\"\n",
    "    nc = 1 if n_workers==0 else n_workers\n",
    "    chunks = list(chunked(items, n_chunks=nc))\n",
    "    res = parallel(f, chunks, n_workers= n_workers, **kwargs)\n",
    "    return res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_one_b(x, a=1): \n",
    "    time.sleep(random.random()/100)\n",
    "    return [o+a for o in x]\n",
    "\n",
    "inp,exp = range(50),range(1,51)\n",
    "test_eq(parallel_chunks(add_one_b, inp, n_workers=2), exp)\n",
    "test_eq(parallel_chunks(add_one_b, inp, n_workers=0), exp)\n",
    "test_eq(parallel_chunks(add_one_b, inp, n_workers=1, a=2), range(2,52))\n",
    "test_eq(parallel_chunks(add_one_b, inp, n_workers=0, a=2), range(2,52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `f` should accept a collection of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_procs(f, f_done, args):\n",
    "    \"Call `f` for each item in `args` in parallel, yielding `f_done`\"\n",
    "    processes = L(args).map(Process, args=arg0, target=f)\n",
    "    for o in processes: o.start()\n",
    "    yield from f_done()\n",
    "    processes.map(Self.join())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def parallel_gen(cls, items, n_workers=defaults.cpus, **kwargs):\n",
    "    \"Instantiate `cls` in `n_workers` procs & call each on a subset of `items` in parallel.\"\n",
    "    if n_workers==0:\n",
    "        yield from enumerate(list(cls(**kwargs)(items)))\n",
    "        return\n",
    "    batches = np.array_split(items, n_workers)\n",
    "    idx = np.cumsum(0 + L(batches).map(len))\n",
    "    queue = Queue()\n",
    "    def f(batch, start_idx):\n",
    "        obj = cls(**kwargs)\n",
    "        res = obj(batch)\n",
    "        for i,b in enumerate(res): queue.put((start_idx+i,b))\n",
    "    def done(): return (queue.get() for _ in progress_bar(items, leave=False))\n",
    "    yield from run_procs(f, done, L(batches,idx).zip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class _C:\n",
    "    def __call__(self, o): return ((i+1) for i in o)\n",
    "\n",
    "items = range(5)\n",
    "\n",
    "res = L(parallel_gen(_C, items, n_workers=3))\n",
    "idxs,dat1 = zip(*res.sorted(itemgetter(0)))\n",
    "test_eq(dat1, range(1,6))\n",
    "\n",
    "res = L(parallel_gen(_C, items, n_workers=0))\n",
    "idxs,dat2 = zip(*res.sorted(itemgetter(0)))\n",
    "test_eq(dat2, dat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cls` is any class with `__call__`. It will be passed `args` and `kwargs` when initialized. Note that `n_workers` instances of `cls` are created, one in each process. `items` are then split in `n_workers` batches and one is sent to each `cls`. The function then returns a generator of tuples of item indices and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SleepyBatchFunc:\n",
    "    def __init__(self): self.a=1\n",
    "    def __call__(self, batch):\n",
    "        for k in batch:\n",
    "            time.sleep(random.random()/4)\n",
    "            yield k+self.a\n",
    "\n",
    "x = np.linspace(0,0.99,20)\n",
    "res = L(parallel_gen(SleepyBatchFunc, x, n_workers=2))\n",
    "test_eq(res.sorted().itemgot(1), x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def in_ipython():\n",
    "    \"Check if the code is running in the ipython environment (jupyter including)\"\n",
    "    try: get_ipython(); return True\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def in_colab():\n",
    "    \"Check if the code is running in Google Colaboratory\"\n",
    "    try:\n",
    "        from google import colab\n",
    "        return True\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def in_notebook():\n",
    "    \"Check if the code is running in a jupyter notebook\"\n",
    "    if in_colab(): return True\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell': return True   # Jupyter notebook, Spyder or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell': return False  # Terminal running IPython\n",
    "        else: return False  # Other type (?)\n",
    "    except NameError: return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "IN_IPYTHON,IN_COLAB,IN_NOTEBOOK = in_ipython(),in_colab(),in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['IN_NOTEBOOK', 'IN_COLAB', 'IN_IPYTHON']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_foundation.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_dispatch.ipynb.\n",
      "Converted 04_transform.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
